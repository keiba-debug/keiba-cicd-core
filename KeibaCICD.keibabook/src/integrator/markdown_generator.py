"""
Markdownå½¢å¼ã®çµ±åˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional


class MarkdownGenerator:
    """
    ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿
    """
    
    def __init__(self, output_dir: str = None, use_organized_dir: bool = True):
        """
        åˆæœŸåŒ–

        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: data/markdownï¼‰
            use_organized_dir: organizedãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã«å‡ºåŠ›ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰
        """
        self.data_root = os.getenv('KEIBA_DATA_ROOT_DIR', './data')  # keibabookãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½¿ã‚ãªã„
        self.use_new_structure = os.getenv('USE_NEW_DATA_STRUCTURE', 'false').lower() == 'true'
        self.use_organized_dir = use_organized_dir
        if use_organized_dir:
            self.output_dir = None  # å‹•çš„ã«æ±ºå®š
        else:
            self.output_dir = output_dir or self.data_root + '/markdown'
            # ãƒ•ã‚©ãƒ«ãƒ€ã¯å®Ÿéš›ã«ä¿å­˜ã™ã‚‹æ™‚ã«ä½œæˆã™ã‚‹ï¼ˆä¸è¦ãªãƒ•ã‚©ãƒ«ãƒ€ä½œæˆã‚’é¿ã‘ã‚‹ï¼‰
        
        # race_idã¨å®Ÿéš›ã®é–‹å‚¬æ—¥ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.actual_date_map = {}
        self.venue_name_map = {}  # å®Ÿéš›ã®ç«¶é¦¬å ´åã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.start_time_map = {}  # ç™ºèµ°æ™‚åˆ»ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.race_info_map = {}  # ãƒ¬ãƒ¼ã‚¹åã¨ã‚³ãƒ¼ã‚¹æƒ…å ±ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.load_actual_dates()
    
    def generate_race_markdown(self, race_data: Dict[str, Any], save: bool = True) -> str:
        """
        ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Markdownã‚’ç”Ÿæˆ
        
        Args:
            race_data: çµ±åˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
            save: ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã‹
            
        Returns:
            Markdownå½¢å¼ã®æ–‡å­—åˆ—
        """
        md_content = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        md_content.append(self._generate_header(race_data))
        
        # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        md_content.append(self._generate_race_info(race_data))
        
        # æœ¬ç´™ã®è¦‹è§£ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        race_comment_section = self._generate_race_comment_section(race_data)
        if race_comment_section:
            md_content.append(race_comment_section)
        
        # å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«
        md_content.append(self._generate_entry_table(race_data))
        
        # èª¿æ•™ãƒ»å©èˆè«‡è©±æƒ…å ±
        md_content.append(self._generate_training_comments(race_data))

        # å±•é–‹äºˆæƒ³ï¼ˆå±•é–‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        tenkai_section = self._generate_tenkai_section(race_data)
        if tenkai_section:
            md_content.append(tenkai_section)

        # ãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
        paddock_section = self._generate_paddock_section(race_data)
        if paddock_section:
            md_content.append(paddock_section)
        
        # ãƒ¬ãƒ¼ã‚¹çµæœï¼ˆæˆç¸¾ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        if self._has_results(race_data):
            md_content.append(self._generate_results_table(race_data))
            md_content.append(self._generate_race_flow_mermaid(race_data))
            md_content.append(self._generate_results_summary(race_data))
            md_content.append(self._generate_payouts_section(race_data))
            md_content.append(self._generate_laps_section(race_data))

        # åˆ†ææƒ…å ±
        ##md_content.append(self._generate_analysis(race_data))
        
        # å¤–éƒ¨ãƒªãƒ³ã‚¯
        md_content.append(self._generate_links(race_data))
        
        # ãƒ¡ã‚¿æƒ…å ±
        md_content.append(self._generate_footer(race_data))
        
        markdown_text = '\n\n'.join(filter(None, md_content))
        
        # æ—¢å­˜ã®è¿½è¨˜ã‚¨ãƒªã‚¢ã‚’ä¿æŒã€ã¾ãŸã¯æ–°è¦è¿½è¨˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        output_path = self._get_output_path(race_data)
        additional_content = self._extract_additional_content(output_path)
        if additional_content:
            markdown_text += '\n\n' + additional_content
        else:
            # æ—¢å­˜ã®è¿½è¨˜ã‚¨ãƒªã‚¢ãŒãªã„å ´åˆã¯æ–°è¦ã«è¿½åŠ 
            markdown_text += '\n\n' + self._generate_additional_section()
        
        if save:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown_text)
        
        return markdown_text
    
    def _generate_header(self, race_data: Dict[str, Any]) -> str:
        """ãƒ¬ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ç”Ÿæˆï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
        race_info = race_data.get('race_info', {})
        race_id = race_data.get('meta', {}).get('race_id', '')
        
        # ç«¶é¦¬å ´åã‚’å–å¾—ï¼ˆvenue_name_mapã‚’æœ€å„ªå…ˆï¼‰
        venue = ''
        if race_id in self.venue_name_map:
            venue = self.venue_name_map[race_id]
        elif race_info.get('venue'):
            venue = race_info.get('venue', '')
        elif race_id and len(race_id) >= 10:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: race_idã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰æ¨æ¸¬
            venue_code = race_id[8:10]
            venue_map = {
                '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ',
                '05': 'æ±äº¬', '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½',
                '09': 'é˜ªç¥', '10': 'å°å€‰'
            }
            venue = venue_map.get(venue_code, '')
        
        # ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’å–å¾—
        race_num = race_info.get('race_number', 0)
        if not race_num and race_id and len(race_id) >= 12:
            race_num = int(race_id[10:12])
        
        # ã‚³ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
        track = race_info.get('track', '')
        distance = race_info.get('distance', 0)
        
        # ãƒ¬ãƒ¼ã‚¹åã‚’å–å¾—ï¼ˆrace_info_mapã‹ã‚‰å„ªå…ˆçš„ã«å–å¾—ï¼‰
        race_name = ''
        course_info = ''
        if race_id in self.race_info_map:
            race_name = self.race_info_map[race_id].get('race_name', '')
            course_info = self.race_info_map[race_id].get('course', '')

        # race_info_mapã«ãªã‘ã‚Œã°race_infoã‹ã‚‰å–å¾—
        if not race_name:
            race_name = race_info.get('race_name', '')

        # ãã‚Œã§ã‚‚ãªã‘ã‚Œã°race_conditionã‹ã‚‰ç‰¹åˆ¥æˆ¦åã‚’æŠ½å‡º
        if not race_name and 'race_condition' in race_info:
            condition = race_info['race_condition']
            import re
            # ç‰¹åˆ¥æˆ¦åã®æŠ½å‡ºï¼ˆä¾‹: "å‹æµ¦ç‰¹åˆ¥(3æ­³ä»¥ä¸Š2å‹ã‚¯ãƒ©ã‚¹ )" -> "å‹æµ¦ç‰¹åˆ¥"ï¼‰
            special_match = re.match(r'^([^(]+(?:ç‰¹åˆ¥|ï¼³|ã‚¹ãƒ†ãƒ¼ã‚¯ã‚¹))', condition)
            if special_match:
                race_name = special_match.group(1).strip()

        if not race_name:
            race_name = f"{race_num}R"
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒ»ã‚¯ãƒ©ã‚¹æƒ…å ±
        grade = race_info.get('grade', '')
        race_class = race_info.get('race_class', '')
        
        # ã‚°ãƒ¬ãƒ¼ãƒ‰ã¾ãŸã¯ã‚¯ãƒ©ã‚¹æƒ…å ±ã‚’æ‹¬å¼§å†…ã«è¡¨ç¤º
        class_info = ''
        if grade and grade != 'OP':
            class_info = f"({grade})"
        elif race_class:
            class_info = f"({race_class})"
        elif 'race_condition' in race_info:
            # race_conditionã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            condition = race_info['race_condition']
            if 'æ–°é¦¬' in condition:
                class_info = '(æ–°é¦¬)'
            elif 'æœªå‹åˆ©' in condition:
                class_info = '(æœªå‹åˆ©)'
            elif '1å‹ã‚¯ãƒ©ã‚¹' in condition:
                class_info = '(1å‹ã‚¯ãƒ©ã‚¹)'
            elif '2å‹ã‚¯ãƒ©ã‚¹' in condition:
                class_info = '(2å‹ã‚¯ãƒ©ã‚¹)'
            elif '3å‹ã‚¯ãƒ©ã‚¹' in condition:
                class_info = '(3å‹ã‚¯ãƒ©ã‚¹)'
            elif 'ã‚ªãƒ¼ãƒ—ãƒ³' in condition:
                class_info = '(ã‚ªãƒ¼ãƒ—ãƒ³)'
        
        # ç™ºèµ°æ™‚åˆ»ã‚’å–å¾—ï¼ˆrace_idsã®start_timeã‚’æœ€å„ªå…ˆã€æ¬¡ã«race_infoã€æœ€å¾Œã«post_timeï¼‰
        race_id = race_data.get('race_id', '')
        start_time = self.start_time_map.get(race_id, '')
        if not start_time:
            start_time = race_info.get('start_time', '')
        if not start_time:
            post_time = race_info.get('post_time', '')
            start_time = post_time
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ§‹ç¯‰
        header_parts = []

        # ç«¶é¦¬å ´ã¨ãƒ¬ãƒ¼ã‚¹ç•ªå·
        if venue and race_num:
            header_parts.append(f"{venue}{race_num}R")
        elif race_num:
            header_parts.append(f"{race_num}R")

        # ã‚¯ãƒ©ã‚¹æƒ…å ±
        if class_info:
            header_parts.append(class_info)

        # ãƒ¬ãƒ¼ã‚¹åï¼ˆç‰¹åˆ¥æˆ¦åãªã©ï¼‰
        if race_name and race_name != f"{race_num}R":
            header_parts.append(race_name)

        # ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§çµåˆ
        return f"# {' '.join(header_parts)}"
    
    def _generate_race_info(self, race_data: Dict[str, Any]) -> str:
        """ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ç”Ÿæˆ"""
        race_info = race_data.get('race_info', {})
        race_id = race_data.get('meta', {}).get('race_id', '')

        lines = ["## ğŸ“‹ ãƒ¬ãƒ¼ã‚¹æƒ…å ±"]

        # æ—¥ä»˜ã‚’æ•´å½¢
        date_str = self._format_date(race_id)
        venue = self._get_venue_name(race_id)

        info_items = []
        if date_str:
            info_items.append(f"- **æ—¥ä»˜**: {date_str}")

        # ç™ºèµ°äºˆå®šæ™‚åˆ»
        start_time = self.start_time_map.get(race_id, '')
        if not start_time:
            start_time = race_info.get('start_time', '')
        if not start_time:
            start_time = race_info.get('post_time', '')
        if not start_time and race_info.get('start_at'):
            # ISO8601å½¢å¼ã‹ã‚‰æ™‚åˆ»éƒ¨åˆ†ã‚’æŠ½å‡º
            start_at = race_info.get('start_at', '')
            if 'T' in start_at:
                time_part = start_at.split('T')[1]
                if ':' in time_part:
                    start_time = ':'.join(time_part.split(':')[:2])

        if start_time:
            info_items.append(f"- **ç™ºèµ°äºˆå®š**: {start_time}")

        # ç«¶é¦¬å ´ã¨ã‚³ãƒ¼ã‚¹æƒ…å ±
        if venue:
            course_display = venue
            # race_info_mapã‹ã‚‰ã‚³ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
            if race_id in self.race_info_map:
                course_info = self.race_info_map[race_id].get('course', '')
                if course_info:
                    course_display = f"{venue} {course_info}"
            elif race_info.get('distance', 0):
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—¢å­˜ã®æ–¹æ³•ã§ã‚³ãƒ¼ã‚¹æƒ…å ±ã‚’æ§‹ç¯‰
                distance = race_info.get('distance', 0)
                track = race_info.get('track', '')
                track_jp = 'èŠ' if track == 'èŠ' else 'ãƒ€ãƒ¼ãƒˆ' if track in ['ãƒ€', 'ãƒ€ãƒ¼ãƒˆ'] else track
                if track_jp and distance:
                    course_display = f"{venue} {track_jp}{distance}m"

            info_items.append(f"- **ç«¶é¦¬å ´**: {course_display}")
        
        
        weather = race_info.get('weather', '')
        if weather:
            info_items.append(f"- **å¤©å€™**: {weather}")
        
        track_condition = race_info.get('track_condition', '')
        if track_condition:
            info_items.append(f"- **é¦¬å ´çŠ¶æ…‹**: {track_condition}")
        
        lines.extend(info_items)
        return '\n'.join(lines)
    
    def _generate_race_comment_section(self, race_data: Dict[str, Any]) -> str:
        """æœ¬ç´™ã®è¦‹è§£ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        race_comment = race_data.get('race_comment', '')
        if not race_comment or race_comment.strip() == '':
            return ""
        
        lines = ["## ğŸ“° æœ¬ç´™ã®è¦‹è§£"]
        lines.append("")
        lines.append(f"> {race_comment}")
        
        return '\n'.join(lines)
    
    def _generate_entry_table(self, race_data: Dict[str, Any]) -> str:
        """å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆï¼ˆè©³ç´°ç‰ˆï¼‰"""
        entries = race_data.get('entries', [])
        if not entries:
            return ""
        
        lines = ["## ğŸ å‡ºèµ°è¡¨"]
        lines.append("")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±ã¨é©æ€§/å‰²å®‰ã‚’è¿½åŠ ï¼‰
        lines.append("| æ  | é¦¬ç•ª | é¦¬å | æ€§é½¢ | é¨æ‰‹ | æ–¤é‡ | ã‚ªãƒƒã‚º | AIæŒ‡æ•° | ãƒ¬ãƒ¼ãƒˆ | æœ¬èªŒ | ç·åˆP | çŸ­è©• | èª¿æ•™ | èª¿æ•™çŸ­è©• | ãƒ‘è©•ä¾¡ | ãƒ‘ã‚³ãƒ¡ãƒ³ãƒˆ | é©æ€§/å‰²å®‰ |")
        lines.append("|:---:|:---:|------|:---:|------|:---:|------:|:------:|:-----:|:---:|:---:|------|:----:|:------:|:------:|:----------:|:---------:|")
        
        # é¦¬ç•ªé †ã«ã‚½ãƒ¼ãƒˆ
        sorted_entries = sorted(entries, key=lambda x: x.get('horse_number', 999))
        
        for entry in sorted_entries:
            entry_data = entry.get('entry_data', {})
            training_data = entry.get('training_data', {})
            # ãƒ‘ãƒ‰ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’paddock_infoã‹paddock_dataã‹ã‚‰å–å¾—
            paddock_data = entry.get('paddock_data', entry.get('paddock_info', {}))
            
            waku = entry_data.get('waku', '')
            horse_num = entry['horse_number']
            horse_name = entry['horse_name']
            age = entry_data.get('age', '')
            jockey = entry_data.get('jockey', '-')
            jockey_id = entry_data.get('jockey_id', '')  # é¨æ‰‹IDã‚’å–å¾—
            weight = entry_data.get('weight', '')
            odds = entry_data.get('odds', '-')
            ai_index = entry_data.get('ai_index', '-')
            rating = entry_data.get('rating', '-')  # ãƒ¬ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã‚’å–å¾—
            honshi_mark = entry_data.get('honshi_mark', '-')
            # ç·åˆãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ï¼ˆãƒã‚¤ãƒŠã‚¹å€¤ã¯0ã«ä¿®æ­£ï¼‰
            raw_point = entry_data.get('aggregate_mark_point', entry_data.get('mark_point', 0))
            mark_point = max(0, raw_point) if isinstance(raw_point, (int, float)) else 0
            
            # èª¿æ•™è©•ä¾¡ï¼ˆçŸ¢å°ä»˜ãï¼‰
            training_eval = '-'
            if training_data:
                eval_mark = training_data.get('evaluation', '')
                arrow_mark = training_data.get('training_arrow', '')  # çŸ¢å°ã‚’å–å¾—
                if arrow_mark:
                    training_eval = arrow_mark
                elif eval_mark:
                    training_eval = eval_mark
            
            # ãƒ‘ãƒ‰ãƒƒã‚¯è©•ä¾¡ã¨ã‚³ãƒ¡ãƒ³ãƒˆ
            paddock_eval = '-'
            paddock_comment = '-'
            if paddock_data and paddock_data != {}:
                # è©•ä¾¡ã¯evaluationã¾ãŸã¯markãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å–å¾—
                p_eval = paddock_data.get('evaluation', paddock_data.get('mark', ''))
                p_comment = paddock_data.get('comment', '')
                if p_eval and p_eval != '':
                    paddock_eval = p_eval
                if p_comment and p_comment != '':
                    paddock_comment = p_comment
            
            short_comment = entry_data.get('short_comment', '')  # çŸ­è©•ã‚’å–å¾—

            # èª¿æ•™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ”»ã‚è§£èª¬ã¨çŸ­è©•ã‚’å–å¾—
            training_short = '-'
            training_explanation = '-'
            if training_data:
                # çŸ­è©•ã‚’å–å¾—
                t_short = training_data.get('short_review', '')
                if t_short:
                    training_short = t_short[:20] + '...' if len(t_short) > 20 else t_short
                else:
                    training_short = '-'

                # æ”»ã‚è§£èª¬ã‚’å–å¾—
                t_attack = training_data.get('attack_explanation', '')
                if t_attack:
                    # æ”»ã‚è§£èª¬ã¯50æ–‡å­—ã¾ã§è¡¨ç¤ºï¼ˆè¡¨ç¤ºã‚’å¢—ã‚„ã™ï¼‰
                    if len(t_attack) > 50:
                        training_explanation = t_attack[:47] + '...'
                    else:
                        training_explanation = t_attack
                else:
                    training_explanation = '-'
            
            # å±¥æ­´ç‰¹å¾´é‡ã‹ã‚‰é©æ€§/å‰²å®‰æƒ…å ±ã‚’ç”Ÿæˆ
            suitability_value = '-'
            history_features = entry.get('history_features', {})
            if history_features:
                passing_style = history_features.get('passing_style', '')
                value_flag = history_features.get('value_flag', '')
                if passing_style or value_flag:
                    # è„šè³ªã¨å‰²å®‰åº¦ã‚’çµ„ã¿åˆã‚ã›ã¦è¡¨ç¤ºï¼ˆçŸ­ç¸®ç‰ˆï¼‰
                    style_short = {'é€ƒã’': 'é€ƒ', 'å…ˆè¡Œ': 'å…ˆ', 'å·®ã—': 'å·®', 'è¿½è¾¼': 'è¿½', 'ä¸­å›£': 'ä¸­'}.get(passing_style, passing_style[:2] if passing_style else '')
                    value_short = {'å‰²å®‰': 'â—', 'ã‚„ã‚„å‰²å®‰': 'â—‹', 'å¦¥å½“': 'â–³', 'å‰²é«˜': 'Ã—'}.get(value_flag, value_flag[:2] if value_flag else '')
                    if style_short and value_short:
                        suitability_value = f"{style_short}/{value_short}"
                    elif style_short:
                        suitability_value = style_short
                    elif value_short:
                        suitability_value = value_short
            
            # é¦¬åã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ï¼ˆé¦¬ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«MDã¸ã®ãƒªãƒ³ã‚¯ï¼‰
            horse_id = entry.get('horse_id', '')
            if horse_id:
                # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
                data_root = os.getenv('KEIBA_DATA_ROOT_DIR', 'Z:/KEIBA-CICD/data')
                # çµ¶å¯¾ãƒ‘ã‚¹ã§é¦¬ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¸ãƒªãƒ³ã‚¯
                profile_path = f"{data_root}/horses/profiles/{horse_id}_{horse_name}.md"
                # Windowsãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›ï¼‰
                if os.name == 'nt':
                    profile_path = profile_path.replace('\\', '/')
                # file:///ã‚’ä»˜ã‘ãªã„é€šå¸¸ã®ãƒ‘ã‚¹å½¢å¼
                horse_name = f"[{horse_name}]({profile_path})"

            # é¨æ‰‹åã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ï¼ˆé¨æ‰‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«MDã¸ã®ãƒªãƒ³ã‚¯ï¼‰
            jockey_id = entry_data.get('jockey_id', '')
            if jockey_id and jockey != '-':
                # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
                data_root = os.getenv('KEIBA_DATA_ROOT_DIR', 'Z:/KEIBA-CICD/data')
                # çµ¶å¯¾ãƒ‘ã‚¹ã§é¨æ‰‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¸ãƒªãƒ³ã‚¯
                jockey_profile_path = f"{data_root}/jockeys/profiles/{jockey_id}_{jockey}.md"
                # Windowsãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›ï¼‰
                if os.name == 'nt':
                    jockey_profile_path = jockey_profile_path.replace('\\', '/')
                # file:///ã‚’ä»˜ã‘ãªã„é€šå¸¸ã®ãƒ‘ã‚¹å½¢å¼
                jockey = f"[{jockey}]({jockey_profile_path})"

            lines.append(f"| {waku} | {horse_num} | {horse_name} | {age} | {jockey} | {weight} | {odds} | {ai_index} | {rating} | {honshi_mark} | {mark_point} | {short_comment} | {training_eval} | {training_short} | {paddock_eval} | {paddock_comment} | {suitability_value} |")
               
        return '\n'.join(lines)
    
    def _generate_results_table(self, race_data: Dict[str, Any]) -> str:
        """ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
        entries = race_data.get('entries', [])
        race_info = race_data.get('race_info', {})
        
        # çµæœãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é¦¬ã®ã¿æŠ½å‡ºã—ã¦ã‚½ãƒ¼ãƒˆ
        results = []
        for entry in entries:
            result = entry.get('result', {})
            if result and result.get('finish_position'):
                # é€šéé †ä½ã®å‡¦ç†
                passing_orders = result.get('passing_orders', [])
                if isinstance(passing_orders, list):
                    passing_str = '-'.join(str(p) for p in passing_orders) if passing_orders else ''
                else:
                    passing_str = str(passing_orders) if passing_orders else ''
                
                results.append({
                    'position': result.get('finish_position', ''),
                    'horse_num': entry['horse_number'],
                    'horse_name': entry['horse_name'],
                    'time': result.get('time', ''),
                    'margin': result.get('margin', ''),
                    'last_3f': result.get('last_3f', ''),
                    'passing': passing_str,
                    'corner_4': result.get('last_corner_position', ''),
                    'jockey': entry.get('entry_data', {}).get('jockey', ''),
                    'odds': entry.get('entry_data', {}).get('odds', ''),
                    'comment': result.get('raw_data', {}).get('interview', '')
                })
        
        if not results:
            return ""
        
        # ç€é †ã§ã‚½ãƒ¼ãƒˆ
        try:
            results.sort(key=lambda x: int(x['position']) if x['position'].isdigit() else 999)
        except:
            pass
        
        lines = ["## ğŸ ãƒ¬ãƒ¼ã‚¹çµæœ"]
        lines.append("")
        
        # ãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—è¦ç´„ã‚’è¿½åŠ 
        race_pace = race_info.get('race_pace', {})
        if race_pace:
            first_3f = race_pace.get('first3f', '')
            last_3f = race_pace.get('last3f', '')
            pace_label = race_pace.get('pace_label', '')
            
            if first_3f or last_3f or pace_label:
                lines.append("### ãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—è¦ç´„")
                pace_parts = []
                if first_3f:
                    pace_parts.append(f"å‰åŠ3F: {first_3f}")
                if last_3f:
                    pace_parts.append(f"å¾ŒåŠ3F: {last_3f}")
                if pace_label:
                    pace_parts.append(f"ãƒšãƒ¼ã‚¹: {pace_label}")
                if pace_parts:
                    lines.append("- " + " / ".join(pace_parts))
                lines.append("")
        
        # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ‹¡å¼µç‰ˆï¼‰
        lines.append("| ç€é † | é¦¬ç•ª | é¦¬å | ã‚¿ã‚¤ãƒ  | ç€å·® | ä¸Šã‚Š3F | é€šé | 4è§’ | é¨æ‰‹ | ã‚ªãƒƒã‚º |")
        lines.append("|:---:|:---:|------|--------|------:|------:|------|:---:|------|------:|")
        
        for result in results[:10]:  # ä¸Šä½10é ­ã®ã¿è¡¨ç¤º
            lines.append(f"| {result['position']} | {result['horse_num']} | {result['horse_name']} | "
                        f"{result['time']} | {result['margin']} | {result['last_3f']} | "
                        f"{result['passing']} | {result['corner_4']} | "
                        f"{result['jockey']} | {result['odds']} |")
        
        # æ‰•æˆ»æƒ…å ±ã‚’è¿½åŠ 
        payouts_section = self._generate_payouts_table(race_data)
        if payouts_section:
            lines.append("")
            lines.append(payouts_section)
        
        # é¨æ‰‹ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Œã°è¿½åŠ 
        comments_with_text = [r for r in results if r.get('comment')]
        if comments_with_text:
            lines.append("")
            lines.append("### ğŸ’¬ é¨æ‰‹ã‚³ãƒ¡ãƒ³ãƒˆ")
            lines.append("")
            for result in comments_with_text[:3]:  # ä¸Šä½3é ­ã®ã‚³ãƒ¡ãƒ³ãƒˆ
                lines.append(f"**{result['position']}ç€ {result['horse_name']}**")
                lines.append(f"> {result['comment']}")
                lines.append("")
        
        return '\n'.join(lines)
    
    def _generate_payouts_table(self, race_data: Dict[str, Any]) -> str:
        """æ‰•æˆ»æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ"""
        payouts = race_data.get('payouts', [])
        
        if not payouts:
            return ""
        
        # åˆ¸ç¨®ã®æ—¥æœ¬èªãƒãƒƒãƒ”ãƒ³ã‚°
        payout_type_mapping = {
            'tansho': 'å˜å‹',
            'fukusho': 'è¤‡å‹',
            'wakuren': 'æ é€£',
            'umaren': 'é¦¬é€£',
            'wide': 'ãƒ¯ã‚¤ãƒ‰',
            'umatan': 'é¦¬å˜',
            'sanrenpuku': '3é€£è¤‡',
            'sanrentan': '3é€£å˜'
        }
        
        # åˆ¸ç¨®ã®é †åº
        payout_order = ['tansho', 'fukusho', 'wakuren', 'umaren', 'wide', 'umatan', 'sanrenpuku', 'sanrentan']
        
        # åˆ¸ç¨®ã”ã¨ã«æ•´ç†
        organized_payouts = {}
        for payout in payouts:
            payout_type = payout.get('type', '')
            if payout_type in payout_type_mapping:
                if payout_type not in organized_payouts:
                    organized_payouts[payout_type] = []
                organized_payouts[payout_type].append(payout)
        
        if not organized_payouts:
            return ""
        
        lines = ["### æ‰•æˆ»"]
        lines.append("| åˆ¸ç¨® | çµ„ç•ª | é‡‘é¡ | äººæ°— |")
        lines.append("|------|------|-----:|----:|")
        
        # é †åºé€šã‚Šã«å‡ºåŠ›
        for payout_type in payout_order:
            if payout_type in organized_payouts:
                type_name = payout_type_mapping[payout_type]
                for payout in organized_payouts[payout_type]:
                    combination = payout.get('combination', '')
                    amount = payout.get('amount', 0)
                    popularity = payout.get('popularity', '')
                    
                    # é‡‘é¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
                    if isinstance(amount, (int, float)):
                        amount_str = f"{amount:,}"
                    else:
                        amount_str = str(amount)
                    
                    lines.append(f"| {type_name} | {combination} | {amount_str} | {popularity} |")
        
        return '\n'.join(lines)
    
    def _generate_race_flow_mermaid(self, race_data: Dict[str, Any]) -> str:
        """ãƒ¬ãƒ¼ã‚¹å±•é–‹ã®Mermaidã‚°ãƒ©ãƒ•ç”Ÿæˆ"""
        entries = race_data.get('entries', [])
        
        # ä¸Šä½5é ­ã®çµæœã‚’å–å¾—
        top_horses = []
        for entry in entries:
            result = entry.get('result', {})
            if result and result.get('finish_position'):
                try:
                    position = int(result['finish_position'])
                    if position <= 5:
                        top_horses.append({
                            'position': position,
                            'name': entry['horse_name'],
                            'passing': result.get('raw_data', {}).get('é€šéé †ä½', '')
                        })
                except:
                    pass
        
        if not top_horses:
            return ""
        
        top_horses.sort(key=lambda x: x['position'])
        
        lines = ["## ğŸ“Š ãƒ¬ãƒ¼ã‚¹å±•é–‹"]
        lines.append("")
        lines.append("```mermaid")
        lines.append("graph LR")
        lines.append("    subgraph ã‚´ãƒ¼ãƒ«")
        
        for i, horse in enumerate(top_horses):
            if i == 0:
                lines.append(f"        A[1ç€: {horse['name']}]")
            else:
                prev_label = chr(ord('A') + i - 1)
                curr_label = chr(ord('A') + i)
                lines.append(f"        {prev_label} --> {curr_label}[{horse['position']}ç€: {horse['name']}]")
        
        lines.append("    end")
        lines.append("```")
        
        return '\n'.join(lines)

    def _generate_results_summary(self, race_data: Dict[str, Any]) -> str:
        """æˆç¸¾ã‚µãƒãƒªãƒ¼ï¼ˆä¸Šä½ãƒ»ä¸ŠãŒã‚Šæœ€é€Ÿãªã©ï¼‰"""
        entries = race_data.get('entries', [])
        results = []
        for entry in entries:
            res = entry.get('result') or {}
            if res and res.get('finish_position'):
                try:
                    pos = int(res.get('finish_position'))
                except Exception:
                    continue
                results.append({
                    'position': pos,
                    'num': entry['horse_number'],
                    'name': entry['horse_name'],
                    'time': res.get('time', ''),
                    'margin': res.get('margin', ''),
                    'last_3f': res.get('last_3f', ''),
                    'jockey': entry.get('entry_data', {}).get('jockey', ''),
                    'odds': entry.get('entry_data', {}).get('odds', ''),
                    'odds_rank': entry.get('entry_data', {}).get('odds_rank', '')
                })
        if not results:
            return ""
        results.sort(key=lambda x: x['position'])
        lines = ["## ğŸ§¾ æˆç¸¾ã‚µãƒãƒªãƒ¼", ""]
        # ä¸Šä½3é ­
        lines.append("### ä¸Šä½3é ­")
        for r in results[:3]:
            lines.append(f"- {r['position']}ç€ {r['num']}ç•ª {r['name']}ï¼ˆ{r['jockey']}ï¼‰ ã‚ªãƒƒã‚º:{r['odds']} äººæ°—:{r['odds_rank']} ã‚¿ã‚¤ãƒ :{r['time']} ç€å·®:{r['margin']}")
        # ä¸ŠãŒã‚Šæœ€é€Ÿ
        try:
            with_last = [r for r in results if r.get('last_3f')]
            def last_to_float(s: str) -> float:
                # ä¾‹: 34.5 â†’ 34.5 / '34.5' / '34ç§’5' ãªã©ã«ç°¡æ˜“å¯¾å¿œ
                import re
                m = re.findall(r"\d+\.?\d*", s)
                return float(m[0]) if m else 999.9
            if with_last:
                fastest = sorted(with_last, key=lambda x: last_to_float(x['last_3f']))[0]
                lines.append("")
                lines.append(f"- ä¸ŠãŒã‚Šæœ€é€Ÿ: {fastest['num']}ç•ª {fastest['name']} {fastest['last_3f']}")
        except Exception:
            pass
        return '\n'.join(lines)
    
    def _generate_training_comments(self, race_data: Dict[str, Any]) -> str:
        """èª¿æ•™ãƒ»å©èˆè«‡è©±æƒ…å ±ç”Ÿæˆï¼ˆçµ±åˆãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ï¼‰"""
        import re
        entries = race_data.get('entries', [])

        # é¦¬ç•ªé †ã«ã‚½ãƒ¼ãƒˆ
        sorted_entries = sorted(entries, key=lambda x: x.get('horse_number', 999))

        # ãƒ‡ãƒ¼ã‚¿ã‚’æŒã¤ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚‹ã‹ç¢ºèª
        has_data = False
        for entry in sorted_entries:
            training = entry.get('training_data', {})
            stable = entry.get('stable_comment', {})
            result = entry.get('result', {})

            if (training.get('evaluation') or training.get('short_review') or
                training.get('attack_explanation') or stable.get('comment') or
                result.get('raw_data', {}).get('ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼') or
                result.get('raw_data', {}).get('æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢')):
                has_data = True
                break

        if not has_data:
            return ""

        lines = ["## ğŸ“ èª¿æ•™ãƒ»å©èˆæƒ…å ±"]
        lines.append("")
        lines.append("| æ  | é¦¬ç•ª | é¦¬å | æ€§é½¢ | é¨æ‰‹ | æ–¤é‡ | ã‚ªãƒƒã‚º | èª¿æ•™ | èª¿æ•™çŸ­è©• | æ”»ã‚é¦¬è§£èª¬ | å©èˆè«‡è©± | å‰èµ° ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ | å‰èµ° æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢ |")
        lines.append("|:---:|:---:|------|:---:|------|:---:|------:|:----:|:------:|----------|----------|-----------------|-----------------|")

        for entry in sorted_entries:
            entry_data = entry.get('entry_data', {})
            training = entry.get('training_data', {})
            stable = entry.get('stable_comment', {})
            result = entry.get('result', {})

            # åŸºæœ¬æƒ…å ±
            frame = entry_data.get('waku', entry_data.get('frame_number', '-'))
            horse_num = entry.get('horse_number', '-')
            horse_name = entry.get('horse_name', '-')
            horse_profile_id = entry.get('horse_profile_id', '')
            sex_age = entry_data.get('age', entry_data.get('sex_age', '-'))
            jockey = entry_data.get('jockey', '-')
            weight = entry_data.get('weight', '-')
            odds = entry_data.get('odds', '-')

            # é¦¬åã«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
            if horse_profile_id:
                profile_path = f"Z:/KEIBA-CICD/data2/horses/profiles/{horse_profile_id}_{horse_name}.md"
                horse_name_link = f"[{horse_name}]({profile_path})"
            else:
                horse_name_link = horse_name

            # èª¿æ•™æƒ…å ±
            training_eval = training.get('evaluation', training.get('training_arrow', '-'))
            if training_eval == '':
                training_eval = '-'

            short_review = training.get('short_review', '-')
            if short_review == '':
                short_review = '-'
            # æ”¹è¡Œã‚’é™¤å»
            if short_review != '-':
                short_review = short_review.replace('\n', ' ').replace('\r', ' ')
                short_review = re.sub(r'\s+', ' ', short_review).strip()

            attack_explanation = training.get('attack_explanation', '-')
            if attack_explanation == '':
                attack_explanation = '-'
            # æ”¹è¡Œã‚’é™¤å»
            if attack_explanation != '-':
                attack_explanation = attack_explanation.replace('\n', ' ').replace('\r', ' ')
                attack_explanation = re.sub(r'\s+', ' ', attack_explanation).strip()

            # å©èˆè«‡è©±ï¼ˆæ”¹è¡Œã‚’é™¤å»ï¼‰
            stable_comment = stable.get('comment', '-')
            if stable_comment == '':
                stable_comment = '-'
            # æ”¹è¡Œã‚’ç©ºç™½ã«ç½®æ›
            if stable_comment != '-':
                stable_comment = stable_comment.replace('\n', ' ').replace('\r', ' ')
                # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
                stable_comment = re.sub(r'\s+', ' ', stable_comment).strip()

            # å‰èµ°æƒ…å ±ï¼ˆprevious_race_interviewã‹ã‚‰å„ªå…ˆçš„ã«å–å¾—ï¼‰
            interview = '-'
            memo = '-'

            # previous_race_interviewã‚’ãƒã‚§ãƒƒã‚¯
            previous_interview = entry.get('previous_race_interview', {})
            if previous_interview:
                # ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å–å¾—
                interview_text = previous_interview.get('interview', '')
                if interview_text:
                    # æ”¹è¡Œã‚’é™¤å»ã—ã¦çŸ­ç¸®
                    interview_text = interview_text.replace('\n', ' ').replace('\r', ' ')
                    interview_text = re.sub(r'\s+', ' ', interview_text).strip()
                    interview = interview_text

                # æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å–å¾—
                next_memo = previous_interview.get('next_race_memo', '')
                if next_memo:
                    # æ”¹è¡Œã‚’é™¤å»ã—ã¦çŸ­ç¸®
                    next_memo = next_memo.replace('\n', ' ').replace('\r', ' ')
                    next_memo = re.sub(r'\s+', ' ', next_memo).strip()
                    memo = next_memo

            # previous_race_interviewãŒãªã„å ´åˆã¯result.raw_dataã‹ã‚‰å–å¾—
            if interview == '-' and result:
                raw_data = result.get('raw_data', {})
                interview_text = raw_data.get('ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼', '')
                if interview_text:
                    # æ”¹è¡Œã‚’é™¤å»ã—ã¦çŸ­ç¸®
                    interview_text = interview_text.replace('\n', ' ').replace('\r', ' ')
                    interview_text = re.sub(r'\s+', ' ', interview_text).strip()
                    if len(interview_text) > 40:
                        interview = interview_text[:40] + '...'
                    else:
                        interview = interview_text

                memo_text = raw_data.get('æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢', '')
                if memo_text:
                    # æ”¹è¡Œã‚’é™¤å»ã—ã¦çŸ­ç¸®
                    memo_text = memo_text.replace('\n', ' ').replace('\r', ' ')
                    memo_text = re.sub(r'\s+', ' ', memo_text).strip()
                    if len(memo_text) > 30:
                        memo = memo_text[:30] + '...'
                    else:
                        memo = memo_text

            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’è¿½åŠ 
            lines.append(f"| {frame} | {horse_num} | {horse_name_link} | {sex_age} | {jockey} | {weight} | {odds} | {training_eval} | {short_review} | {attack_explanation} | {stable_comment} | {interview} | {memo} |")

        return '\n'.join(lines)
    
    def _generate_analysis(self, race_data: Dict[str, Any]) -> str:
        """åˆ†ææƒ…å ±ç”Ÿæˆ"""
        analysis = race_data.get('analysis', {})
        if not analysis:
            return ""
        
        lines = ["## ğŸ“ˆ ãƒ¬ãƒ¼ã‚¹åˆ†æ"]
        lines.append("")
        
        # ãƒšãƒ¼ã‚¹äºˆæƒ³
        pace = analysis.get('expected_pace', '')
        if pace:
            lines.append(f"- **äºˆæƒ³ãƒšãƒ¼ã‚¹**: {pace}")
        
        # äººæ°—é¦¬
        favorites = analysis.get('favorites', [])
        if favorites:
            lines.append("- **ä¸Šä½äººæ°—é¦¬**:")
            for fav in favorites[:3]:
                lines.append(f"  - {fav['odds_rank']}ç•ªäººæ°—: {fav['horse_name']}")
        
        # æ³¨ç›®ã®èª¿æ•™é¦¬
        highlights = analysis.get('training_highlights', [])
        if highlights:
            lines.append("- **èª¿æ•™å¥½èª¿é¦¬**:")
            for highlight in highlights[:3]:
                lines.append(f"  - {highlight}")
        
        # å±¥æ­´ç‰¹å¾´é‡ã‹ã‚‰æ³¨ç›®é¦¬ã‚’è¿½åŠ 
        entries = race_data.get('entries', [])
        history_highlights = []
        for entry in entries:
            history_features = entry.get('history_features', {})
            if history_features:
                horse_name = entry.get('horse_name', '')
                horse_num = entry.get('horse_number', '')
                passing_style = history_features.get('passing_style', '')
                last3f_mean = history_features.get('last3f_mean_3', 0)
                value_flag = history_features.get('value_flag', '')
                
                # å‰²å®‰é¦¬ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—
                if value_flag in ['å‰²å®‰', 'ã‚„ã‚„å‰²å®‰']:
                    summary = f"{horse_num}ç•ª {horse_name}: "
                    parts = []
                    if passing_style:
                        parts.append(f"è„šè³ª={passing_style}")
                    if last3f_mean:
                        parts.append(f"ç›´è¿‘ä¸Šã‚Š3F={last3f_mean}")
                    parts.append(f"è©•ä¾¡={value_flag}")
                    summary += " | ".join(parts)
                    history_highlights.append(summary)
        
        if history_highlights:
            lines.append("- **å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ³¨ç›®é¦¬**:")
            for highlight in history_highlights[:3]:
                lines.append(f"  - {highlight}")
        
        return '\n'.join(lines)

    def _generate_payouts_section(self, race_data: Dict[str, Any]) -> str:
        payouts = race_data.get('payouts')
        
        # æ–°å½¢å¼ï¼ˆãƒªã‚¹ãƒˆï¼‰ã®å ´åˆã¯_generate_payouts_tableã‚’ä½¿ç”¨
        if isinstance(payouts, list):
            return ""  # æ–°å½¢å¼ã¯_generate_results_tableã§å‡¦ç†ã•ã‚Œã‚‹
        
        # æ—§å½¢å¼ï¼ˆè¾æ›¸ï¼‰ã®å‡¦ç†
        if not payouts or not isinstance(payouts, dict) or all(v in (None, [], {}) for v in payouts.values()):
            return ""
        lines = ["## ğŸ’´ é…å½“æƒ…å ±", ""]
        def fmt(v):
            if v is None:
                return '-'
            if isinstance(v, list):
                return ', '.join(str(x) for x in v) if v else '-'
            return str(v)
        lines.append(f"- å˜å‹: {fmt(payouts.get('win'))}")
        lines.append(f"- è¤‡å‹: {fmt(payouts.get('place'))}")
        lines.append(f"- é¦¬é€£: {fmt(payouts.get('quinella'))}")
        lines.append(f"- é¦¬å˜: {fmt(payouts.get('exacta'))}")
        lines.append(f"- ãƒ¯ã‚¤ãƒ‰: {fmt(payouts.get('wide'))}")
        lines.append(f"- 3é€£è¤‡: {fmt(payouts.get('trio'))}")
        lines.append(f"- 3é€£å˜: {fmt(payouts.get('trifecta'))}")
        return '\n'.join(lines)

    def _generate_laps_section(self, race_data: Dict[str, Any]) -> str:
        laps = race_data.get('laps') or {}
        if not laps:
            return ""
        lines = ["## â± ãƒ©ãƒƒãƒ—/ãƒšãƒ¼ã‚¹", ""]
        if laps.get('lap_times'):
            lap_text = ' - '.join(laps['lap_times'][:12])  # é•·ã™ãå›é¿
            lines.append(f"- ãƒ©ãƒƒãƒ—: {lap_text}")
        if laps.get('first_1000m'):
            lines.append(f"- 1000mé€šé: {laps['first_1000m']}")
        if laps.get('pace'):
            pace_map = {'H': 'ãƒã‚¤', 'M': 'ãƒŸãƒ‰ãƒ«', 'S': 'ã‚¹ãƒ­ãƒ¼'}
            lines.append(f"- ãºãƒ¼ã‚¹: {pace_map.get(laps['pace'], laps['pace'])}")
        return '\n'.join(lines)
    
    def _generate_links(self, race_data: Dict[str, Any]) -> str:
        """å¤–éƒ¨ãƒªãƒ³ã‚¯ç”Ÿæˆ"""
        race_id = race_data.get('meta', {}).get('race_id', '')
        if not race_id:
            return ""
        
        lines = ["## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯"]
        lines.append("")
        
        # ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®ãƒ¬ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ï¼ˆæ¨å®šURLï¼‰
        date_part = race_id[:8]
        lines.append(f"- [ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒ¬ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸](https://p.keibabook.co.jp/cyuou/race/{date_part}/{race_id})")
        
        # å„é¦¬ã®è©³ç´°ãƒšãƒ¼ã‚¸ï¼ˆé¦¬ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«MDã¸ã®ãƒªãƒ³ã‚¯ï¼‰
        entries = race_data.get('entries', [])
        if entries:
            lines.append("")
            lines.append("### å‡ºèµ°é¦¬è©³ç´°")
            for entry in entries[:5]:  # ä¸Šä½5é ­
                horse_id = entry.get('horse_id', '')
                if horse_id:
                    horse_name = entry['horse_name']
                    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ«ãƒ¼ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼‰
                    data_root = os.getenv('KEIBA_DATA_ROOT_DIR', 'Z:/KEIBA-CICD/data')
                    # çµ¶å¯¾ãƒ‘ã‚¹ã§é¦¬ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¸ãƒªãƒ³ã‚¯
                    profile_path = f"{data_root}/horses/profiles/{horse_id}_{horse_name}.md"
                    # Windowsãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚’ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã«å¤‰æ›ï¼‰
                    if os.name == 'nt':
                        profile_path = profile_path.replace('\\', '/')
                    lines.append(f"- [{horse_name}]({profile_path})")
        
        return '\n'.join(lines)
    
    def _extract_additional_content(self, file_path) -> str:
        """æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¿½è¨˜ã‚¨ãƒªã‚¢ã‚’æŠ½å‡º"""
        if not Path(file_path).exists():
            return ""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # "# è¿½è¨˜"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
            lines = content.split('\n')
            additional_start = -1
            
            for i, line in enumerate(lines):
                if line.strip() == '# è¿½è¨˜' or line.strip() == '# è¿½è¨˜æ¬„':
                    additional_start = i
                    break
            
            if additional_start >= 0:
                # è¿½è¨˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ€å¾Œã¾ã§å–å¾—
                additional_lines = lines[additional_start:]
                return '\n'.join(additional_lines)
        except Exception as e:
            print(f"è¿½è¨˜ã‚¨ãƒªã‚¢æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return ""
    
    def _generate_additional_section(self) -> str:
        """æ–°è¦è¿½è¨˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        lines = [
            "---",
            "# è¿½è¨˜",
            ""
        ]
        return '\n'.join(lines)
    
    def _generate_footer(self, race_data: Dict[str, Any]) -> str:
        """ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±ç”Ÿæˆ"""
        meta = race_data.get('meta', {})
        
        lines = ["---"]
        lines.append("")
        lines.append("### ãƒ‡ãƒ¼ã‚¿æƒ…å ±")
        lines.append(f"- **ç”Ÿæˆæ—¥æ™‚**: {meta.get('created_at', '')}")
        lines.append(f"- **æ›´æ–°æ—¥æ™‚**: {meta.get('updated_at', '')}")
        lines.append(f"- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: ç«¶é¦¬ãƒ–ãƒƒã‚¯")
       
        return '\n'.join(lines)
    
    def _generate_tenkai_section(self, race_data: Dict[str, Any]) -> str:
        """å±•é–‹äºˆæƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        tenkai_data = race_data.get('tenkai_data', {})
        if not tenkai_data:
            return ""
        
        lines = ["## ğŸƒ å±•é–‹äºˆæƒ³"]
        lines.append("")
        
        # ãƒšãƒ¼ã‚¹äºˆæƒ³
        pace = tenkai_data.get('pace', 'M')
        pace_emoji = {
            'H': 'ğŸ”¥',  # ãƒã‚¤ãƒšãƒ¼ã‚¹
            'M-H': 'âš¡',  # ã‚„ã‚„ãƒã‚¤
            'M': 'âš–ï¸',  # å¹³å‡
            'M-S': 'ğŸ¢',  # ã‚„ã‚„ã‚¹ãƒ­ãƒ¼
            'S': 'ğŸŒ'  # ã‚¹ãƒ­ãƒ¼
        }.get(pace, 'âš–ï¸')
        
        lines.append(f"### {pace_emoji} ãƒšãƒ¼ã‚¹äºˆæƒ³: {pace}")
        lines.append("")
        
        # å±•é–‹ãƒã‚¸ã‚·ãƒ§ãƒ³è¡¨ï¼ˆæ¨ªæŒã¡: ãƒã‚¸ã‚·ãƒ§ãƒ³=åˆ—, é¦¬ç•ª=ã‚»ãƒ«ï¼‰
        positions = tenkai_data.get('positions', {})
        if positions:
            lines.append("### ğŸ“Š äºˆæƒ³å±•é–‹ï¼ˆãƒã‚¸ã‚·ãƒ§ãƒ³æ¨ªé…ç½®ï¼‰")
            lines.append("")
            # ãƒã‚¸ã‚·ãƒ§ãƒ³é †åºã‚’å®šç¾©
            position_order = ['é€ƒã’', 'å¥½ä½', 'ä¸­ä½', 'å¾Œæ–¹']
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
            header = "| " + " | ".join(position_order) + " |"
            align = "|" + "|".join([":---:"] * len(position_order)) + "|"
            lines.append(header)
            lines.append(align)
            # ã€‡æ•°å­—ï¼ˆâ‘ â‘¡â€¦ï¼‰ã¸ã®å¤‰æ›ãƒãƒƒãƒ—ï¼ˆ1ã€œ20ã‚’æƒ³å®šã€ç«¶èµ°ã¯æœ€å¤§18é ­æƒ³å®šï¼‰
            circled_map = {
                0: 'â“ª', 1: 'â‘ ', 2: 'â‘¡', 3: 'â‘¢', 4: 'â‘£', 5: 'â‘¤', 6: 'â‘¥', 7: 'â‘¦', 8: 'â‘§', 9: 'â‘¨',
                10: 'â‘©', 11: 'â‘ª', 12: 'â‘«', 13: 'â‘¬', 14: 'â‘­', 15: 'â‘®', 16: 'â‘¯', 17: 'â‘°', 18: 'â‘±', 19: 'â‘²', 20: 'â‘³'
            }

            def to_circled(num_str: Any) -> str:
                try:
                    n = int(str(num_str))
                    return circled_map.get(n, str(num_str))
                except Exception:
                    return str(num_str)

            # å˜ä¸€è¡Œã«å„åˆ—ã®é¦¬ç•ªã‚’é…ç½®
            row_cells = []
            for pos_name in position_order:
                horses = positions.get(pos_name, []) or []
                cell = ' '.join([to_circled(num) for num in horses]) if horses else "-"
                row_cells.append(cell)
            lines.append("| " + " | ".join(row_cells) + " |")
            lines.append("")
        
        # å±•é–‹è§£èª¬
        description = tenkai_data.get('description', '')
        if description:
            lines.append("### ğŸ’­ å±•é–‹è§£èª¬")
            lines.append("")
            lines.append(f"> {description}")
            lines.append("")
        
        # Mermaidã«ã‚ˆã‚‹è¦–è¦šåŒ–ã¯ã€è¡¨ã¨æƒ…å ±é‡è¤‡ã®ãŸã‚çœç•¥ï¼ˆç°¡æ½”æ€§ã‚’å„ªå…ˆï¼‰
        
        return '\n'.join(lines)
    
    def _has_results(self, race_data: Dict[str, Any]) -> bool:
        """çµæœãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèª"""
        entries = race_data.get('entries', [])
        for entry in entries:
            if entry.get('result', {}).get('finish_position'):
                return True
        return False
    
    def _generate_paddock_section(self, race_data: Dict[str, Any]) -> str:
        """ãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆè©³ç´°ç‰ˆï¼‰"""
        entries = race_data.get('entries', [])
        paddock_entries = []
        
        for entry in entries:
            paddock_info = entry.get('paddock_info')
            if paddock_info and (paddock_info.get('mark') or paddock_info.get('comment') or paddock_info.get('evaluation')):
                paddock_entries.append({
                    'horse_number': entry['horse_number'],
                    'horse_name': entry['horse_name'],
                    'paddock': paddock_info
                })
        
        if not paddock_entries:
            # ãƒ‘ãƒ‰ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¦ã„ãªã„å ´åˆã®èª¬æ˜
            return "## ğŸ´ ãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±\n\n*ãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆãƒ¬ãƒ¼ã‚¹ç›´å‰ã«å…¬é–‹ã•ã‚Œã¾ã™ï¼‰*"
        
        lines = ["## ğŸ´ ãƒ‘ãƒ‰ãƒƒã‚¯æƒ…å ±"]
        lines.append("")
        
        # è©•ä¾¡ã®é«˜ã„é¦¬ã‚’å„ªå…ˆè¡¨ç¤º
        eval_order = {'â—': 1, 'â—‹': 2, 'â–²': 3, 'â–³': 4, 'â˜†': 5, 'â˜…': 6, 'Ã—': 99, '-': 100}
        paddock_entries.sort(key=lambda x: eval_order.get(x['paddock'].get('mark', '-'), 100))
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        lines.append("| é¦¬ç•ª | é¦¬å | è©•ä¾¡ | ç‚¹æ•° | çŠ¶æ…‹ | æ°—é… | ã‚³ãƒ¡ãƒ³ãƒˆ |")
        lines.append("|:---:|------|:---:|:---:|------|------|----------|")
        
        for entry in paddock_entries[:12]:  # æœ€å¤§12é ­
            paddock = entry['paddock']
            horse_num = entry['horse_number']
            horse_name = entry['horse_name']
            mark = paddock.get('mark', paddock.get('evaluation', '-'))
            score = paddock.get('mark_score', '-')
            condition = paddock.get('condition', '-')
            temperament = paddock.get('temperament', '-')
            comment = paddock.get('comment', '-')
            
            # ã‚³ãƒ¡ãƒ³ãƒˆãŒé•·ã„å ´åˆã¯çŸ­ç¸®
            if comment and comment != '-' and len(comment) > 40:
                comment = comment[:40] + "..."
            
            lines.append(f"| {horse_num} | {horse_name} | {mark} | {score} | {condition} | {temperament} | {comment} |")
        
        # è©³ç´°ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        detailed_comments = [e for e in paddock_entries if e['paddock'].get('comment') and len(e['paddock'].get('comment', '')) > 40]
        if detailed_comments:
            lines.append("")
            lines.append("### ãƒ‘ãƒ‰ãƒƒã‚¯è©³ç´°ã‚³ãƒ¡ãƒ³ãƒˆ")
            lines.append("")
            for entry in detailed_comments[:5]:
                lines.append(f"**{entry['horse_number']}ç•ª {entry['horse_name']}**")
                lines.append(f"> {entry['paddock']['comment']}")
                lines.append("")
        
        return '\n'.join(lines)
    
    def _generate_previous_interview_section(self, race_data: Dict[str, Any]) -> str:
        """å‰èµ°ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆè©³ç´°ç‰ˆï¼‰"""
        entries = race_data.get('entries', [])
        interview_entries = []

        for entry in entries:
            interview = entry.get('previous_race_interview')
            if interview and (interview.get('comment') or interview.get('interview') or interview.get('race_name')):
                interview_entries.append({
                    'horse_number': entry['horse_number'],
                    'horse_name': entry['horse_name'],
                    'jockey': interview.get('jockey', ''),
                    'interview': interview.get('interview', interview.get('comment', '')),  # interviewã‚’å„ªå…ˆã€ãªã‘ã‚Œã°comment
                    'next_race_memo': interview.get('next_race_memo', ''),
                    'race_name': interview.get('race_name', ''),
                    'finish_position': interview.get('finish_position', ''),
                    'date': interview.get('date', '')
                })
        
        if not interview_entries:
            return ""
        
        lines = ["## ğŸ’¬ å‰èµ°ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼"]
        lines.append("")
        
        # ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒã‚ã‚‹é¦¬ã‚’è¡¨ç¤º
        for entry in interview_entries[:8]:  # æœ€å¤§8é ­ã¾ã§è¡¨ç¤ºã«å¢—ã‚„ã™
            lines.append(f"### {entry['horse_number']}ç•ª {entry['horse_name']}")
            
            # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
            if entry.get('race_name'):
                race_info = []
                if entry.get('date'):
                    race_info.append(entry['date'])
                if entry.get('race_name'):
                    race_info.append(entry['race_name'])
                if entry.get('finish_position'):
                    race_info.append(f"{entry['finish_position']}ç€")
                if race_info:
                    lines.append(f"*å‰èµ°: {' / '.join(race_info)}*")
            
            if entry['jockey']:
                lines.append(f"**{entry['jockey']}é¨æ‰‹**")

            # ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å†…å®¹ã‚’è¡¨ç¤º
            if entry.get('interview'):
                # ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã‚„ã™ãæ•´å½¢
                interview_lines = entry['interview'].split('ã€‚')
                formatted_interview = 'ã€‚\n> '.join(line.strip() for line in interview_lines if line.strip())
                if not formatted_interview.endswith('ã€‚'):
                    formatted_interview += 'ã€‚'
                lines.append(f"> {formatted_interview}")
            elif entry.get('comment'):  # å¾Œæ–¹äº’æ›æ€§
                # ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã‚„ã™ãæ•´å½¢
                comment_lines = entry['comment'].split('ã€‚')
                formatted_comment = 'ã€‚\n> '.join(line.strip() for line in comment_lines if line.strip())
                if not formatted_comment.endswith('ã€‚'):
                    formatted_comment += 'ã€‚'
                lines.append(f"> {formatted_comment}")
            else:
                lines.append("> *ã‚³ãƒ¡ãƒ³ãƒˆãªã—*")

            # æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢ãŒã‚ã‚Œã°è¡¨ç¤º
            if entry.get('next_race_memo'):
                lines.append("")
                lines.append("**ğŸ“ æ¬¡èµ°ã¸ã®ãƒ¡ãƒ¢**")
                lines.append(f"> {entry['next_race_memo']}")
            
            lines.append("")
        
        return '\n'.join(lines)
    
    def load_actual_dates(self):
        """
        race_ids ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰å®Ÿéš›ã®é–‹å‚¬æ—¥ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã‚€
        """
        if self.use_new_structure:
            # æ–°æ§‹é€ : races/YYYY/MM/DD/race_info.json ã‚’æ¤œç´¢
            races_dir = os.path.join(self.data_root, 'races')
            if os.path.exists(races_dir):
                for year_dir in os.listdir(races_dir):
                    year_path = os.path.join(races_dir, year_dir)
                    if os.path.isdir(year_path):
                        for month_dir in os.listdir(year_path):
                            month_path = os.path.join(year_path, month_dir)
                            if os.path.isdir(month_path):
                                for day_dir in os.listdir(month_path):
                                    day_path = os.path.join(month_path, day_dir)
                                    if os.path.isdir(day_path):
                                        race_info_file = os.path.join(day_path, 'race_info.json')
                                        if os.path.exists(race_info_file):
                                            date_str = f"{year_dir}{month_dir}{day_dir}"
                                            self._load_race_info_file(race_info_file, date_str)
        else:
            # æ—§æ§‹é€ : race_ids/YYYYMMDD_info.json
            race_ids_dir = os.path.join(self.data_root, 'race_ids')
            if not os.path.exists(race_ids_dir):
                return

            for file_name in os.listdir(race_ids_dir):
                if file_name.endswith('_info.json'):
                    date_str = file_name.replace('_info.json', '')
                    file_path = os.path.join(race_ids_dir, file_name)
                    self._load_race_info_file(file_path, date_str)

    def _load_race_info_file(self, file_path: str, date_str: str):
        """
        ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # å„é–‹å‚¬ã®race_idã‚’å®Ÿéš›ã®æ—¥ä»˜ã«ãƒãƒƒãƒ”ãƒ³ã‚°
            for kaisai_name, races in data.get('kaisai_data', {}).items():
                # é–‹å‚¬åã‹ã‚‰ç«¶é¦¬å ´åã‚’å–å¾—ï¼ˆä¾‹ï¼šã€Œ2å›æ–°æ½Ÿ5æ—¥ç›®ã€â†’ã€Œæ–°æ½Ÿã€ï¼‰
                import re
                # é•·ã„åå‰ã‚’å…ˆã«ãƒãƒƒãƒã•ã›ã‚‹ï¼ˆä¸­äº¬ã‚’ä¸­ã‚ˆã‚Šå„ªå…ˆï¼‰
                venue_match = re.search(r'(æœ­å¹Œ|å‡½é¤¨|ç¦å³¶|æ–°æ½Ÿ|æ±äº¬|ä¸­å±±|ä¸­äº¬|äº¬éƒ½|é˜ªç¥|å°å€‰)', kaisai_name)
                venue_name = venue_match.group(1) if venue_match else ''

                for race in races:
                    race_id = race.get('race_id', '')
                    if race_id:
                        self.actual_date_map[race_id] = date_str
                        if venue_name:
                            self.venue_name_map[race_id] = venue_name
                        # start_time ã‚‚ä¿å­˜
                        if race.get('start_time'):
                            self.start_time_map[race_id] = race['start_time']
                        # ãƒ¬ãƒ¼ã‚¹åã¨ã‚³ãƒ¼ã‚¹æƒ…å ±ã‚’ä¿å­˜
                        self.race_info_map[race_id] = {
                            'race_name': race.get('race_name', ''),
                            'course': race.get('course', '')
                        }
        except Exception as e:
            pass
    
    def _format_date(self, race_id: str) -> str:
        """race_idã‹ã‚‰æ—¥ä»˜ã‚’æ•´å½¢"""
        # å®Ÿéš›ã®é–‹å‚¬æ—¥ä»˜ã‚’ä½¿ç”¨
        if race_id in self.actual_date_map:
            date_str = self.actual_date_map[race_id]
        elif len(race_id) >= 8:
            date_str = race_id[:8]
        else:
            return ""
        
        try:
            year = date_str[:4]
            month = date_str[4:6]
            day = date_str[6:8]
            return f"{year}å¹´{int(month)}æœˆ{int(day)}æ—¥"
        except:
            return ""
    
    def _get_venue_name(self, race_id: str) -> str:
        """race_idã‹ã‚‰ç«¶é¦¬å ´åã‚’å–å¾—"""
        # å®Ÿéš›ã®ç«¶é¦¬å ´åã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
        if race_id in self.venue_name_map:
            return self.venue_name_map[race_id]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚³ãƒ¼ãƒ‰ã‹ã‚‰æ¨æ¸¬
        if len(race_id) >= 10:
            venue_code = race_id[8:10]
            venue_map = {
                '01': 'æœ­å¹Œ',
                '02': 'å‡½é¤¨',
                '03': 'ç¦å³¶',
                '04': 'æ–°æ½Ÿ',
                '05': 'æ±äº¬',
                '06': 'ä¸­å±±',
                '07': 'ä¸­äº¬',
                '08': 'äº¬éƒ½',
                '09': 'é˜ªç¥',
                '10': 'å°å€‰'
            }
            return venue_map.get(venue_code, '')
        return ""
    
    def _get_output_path(self, race_data: Dict[str, Any]) -> str:
        """å‡ºåŠ›ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        race_id = race_data.get('meta', {}).get('race_id', 'unknown')
        
        # æ—¥ä»˜ã‚’å–å¾—
        if race_id in self.actual_date_map:
            date_str = self.actual_date_map[race_id]
        else:
            date_str = race_id[:8] if len(race_id) >= 8 else '00000000'

        year = date_str[:4]
        month = date_str[4:6]
        day = date_str[6:8]

        # ç«¶é¦¬å ´åã‚’å–å¾—
        venue_name = self.venue_name_map.get(race_id, '')
        if not venue_name and len(race_id) >= 10:
            # race_idã‹ã‚‰ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
            venue_code = race_id[8:10]
            venue_map = {
                '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ',
                '05': 'æ±äº¬', '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½',
                '09': 'é˜ªç¥', '10': 'å°å€‰'
            }
            venue_name = venue_map.get(venue_code, '')

        if self.use_new_structure:
            # æ–°æ§‹é€ : races/YYYY/MM/DD/ç«¶é¦¬å ´å/
            if venue_name:
                output_dir = os.path.join(self.data_root, 'races', year, month, day, venue_name)
            else:
                output_dir = os.path.join(self.data_root, 'races', year, month, day)
        else:
            # æ—§æ§‹é€ : organized/YYYY/MM/DD/ç«¶é¦¬å ´å/
            if venue_name:
                output_dir = os.path.join(self.data_root, 'organized', year, month, day, venue_name)
            else:
                output_dir = os.path.join(self.data_root, 'organized', year, month, day)
        
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        return os.path.join(output_dir, f"{race_id}.md")
    
    def batch_generate(self, integrated_dir: str = None) -> Dict[str, Any]:
        """
        çµ±åˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬ã§Markdownã‚’ç”Ÿæˆ
        
        Args:
            integrated_dir: çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼
        """
        if not integrated_dir:
            integrated_dir = os.getenv('KEIBA_DATA_ROOT_DIR', './data') + '/integrated'
        
        json_files = list(Path(integrated_dir).glob('integrated_*.json'))
        
        success = 0
        failed = 0
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    race_data = json.load(f)
                
                self.generate_race_markdown(race_data, save=True)
                success += 1
            except Exception as e:
                print(f"Error processing {json_file}: {e}")
                failed += 1
        
        return {
            'total': len(json_files),
            'success': success,
            'failed': failed
        }
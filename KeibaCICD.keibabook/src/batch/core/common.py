#!/usr/bin/env python3
"""
ãƒãƒƒãƒå‡¦ç†å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

å…¨ã¦ã®ãƒãƒƒãƒå‡¦ç†ã§ä½¿ç”¨ã•ã‚Œã‚‹å…±é€šæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import os
import sys
import logging
import datetime
import requests
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®Configã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from ...utils.config import Config
except ImportError:
    # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã™
    try:
        from utils.config import Config
    except ImportError:
        # Configã‚¯ãƒ©ã‚¹ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ€ãƒŸãƒ¼å®Ÿè£…
        class Config:
            @classmethod
            def get_required_cookies(cls):
                return [
                    {
                        "name": "keibabook_session",
                        "value": os.getenv("KEIBABOOK_SESSION", ""),
                        "domain": "p.keibabook.co.jp"
                    },
                    {
                        "name": "tk",
                        "value": os.getenv("KEIBABOOK_TK", ""),
                        "domain": "p.keibabook.co.jp"
                    },
                    {
                        "name": "XSRF-TOKEN",
                        "value": os.getenv("KEIBABOOK_XSRF_TOKEN", ""),
                        "domain": "p.keibabook.co.jp"
                    }
                ]


def parse_date(date_str: str) -> datetime.date:
    """
    æ—¥ä»˜æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦datetime.dateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
    
    Args:
        date_str: æ—¥ä»˜æ–‡å­—åˆ— (YYYY/MM/DD, YY/MM/DD, YYYYMMDDå½¢å¼)
        
    Returns:
        datetime.date: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸæ—¥ä»˜
        
    Raises:
        ValueError: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æ—¥ä»˜å½¢å¼ã®å ´åˆ
    """
    try:
        # 2025/5/31 ã¾ãŸã¯ 25/5/31 ã®å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ
        if '/' in date_str:
            parts = date_str.split('/')
            if len(parts[0]) == 2:
                parts[0] = '20' + parts[0]
            return datetime.date(int(parts[0]), int(parts[1]), int(parts[2]))
        # 20250531 ã®å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ
        elif len(date_str) == 8:
            return datetime.date(int(date_str[0:4]), int(date_str[4:6]), int(date_str[6:8]))
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æ—¥ä»˜å½¢å¼ã§ã™: {date_str}")
    except Exception as e:
        raise ValueError(f"æ—¥ä»˜ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {date_str}, ã‚¨ãƒ©ãƒ¼: {e}")


def setup_batch_logger(name: str, log_level: str = "INFO", log_file: Optional[str] = None) -> logging.Logger:
    """
    ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®š
    
    Args:
        name: ãƒ­ã‚¬ãƒ¼å
        log_level: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (DEBUG, INFO, WARNING, ERROR)
        log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
        
    Returns:
        logging.Logger: è¨­å®šã•ã‚ŒãŸãƒ­ã‚¬ãƒ¼
    """
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    log_dir = os.environ.get('KEIBA_LOG_DIR')
    if log_dir:
        logs_dir = Path(log_dir)
    else:
        # ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        base_dir = Path(os.environ.get('KEIBA_DATA_DIR', '.'))
        logs_dir = base_dir / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è‡ªå‹•ç”Ÿæˆ
    if log_file is None:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = logs_dir / f'{name}_{timestamp}.log'
    
    # ãƒ­ã‚¬ãƒ¼ã‚’ä½œæˆ
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    logger.handlers.clear()
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã‚’è¨­å®š
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    file_handler = logging.FileHandler(str(log_file), encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # åˆæœŸãƒ­ã‚°å‡ºåŠ›
    logger.info(f"ãƒ­ã‚¬ãƒ¼ '{name}' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file}")
    logger.info(f"ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {log_level}")
    
    return logger


def get_base_directories() -> Dict[str, str]:
    """
    ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—
    
    Returns:
        Dict[str, str]: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¾æ›¸
    """
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰keibabookç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    keibabook_dir = os.environ.get('KEIBA_KEIBABOOK_DIR')
    if keibabook_dir:
        base_dir = Path(keibabook_dir)
    else:
        # ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        base_dir = Path("data/keibabook")
    
    return {
        # ãƒ¬ãƒ¼ã‚¹IDä¿å­˜ç”¨
        'race_ids': str(base_dir / "race_ids"),
        
        # JSONä¿å­˜ç”¨ï¼ˆã™ã¹ã¦åŒä¸€ãƒ•ã‚©ãƒ«ãƒ€ï¼‰
        'json_base': str(base_dir),  # ç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
    }


def ensure_batch_directories():
    """
    ãƒãƒƒãƒå‡¦ç†ã«å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    """
    dirs = get_base_directories()
    
    # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    for dir_path in dirs.values():
        os.makedirs(dir_path, exist_ok=True)
        print(f"âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª/ä½œæˆ: {dir_path}")


def get_race_ids_file_path(date_str: str) -> str:
    """
    ãƒ¬ãƒ¼ã‚¹IDãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
    
    Args:
        date_str: æ—¥ä»˜æ–‡å­—åˆ— (YYYYMMDD)
        
    Returns:
        str: ãƒ¬ãƒ¼ã‚¹IDãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹
    """
    dirs = get_base_directories()
    return os.path.join(dirs['race_ids'], f"{date_str}_info.json")


def get_json_file_path(data_type: str, identifier: str) -> str:
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹ã‚’å–å¾—
    
    Args:
        data_type: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (seiseki, shutsuba, cyokyo, danwa, nittei)
        identifier: ãƒ•ã‚¡ã‚¤ãƒ«è­˜åˆ¥å­ (race_idã¾ãŸã¯æ—¥ä»˜)
        
    Returns:
        str: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹
    """
    dirs = get_base_directories()
    filename = f"{data_type}_{identifier}.json"
    return os.path.join(dirs['json_base'], filename)


def create_authenticated_session() -> requests.Session:
    """
    Cookieèªè¨¼ä»˜ãã®HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    
    Returns:
        requests.Session: èªè¨¼è¨­å®šæ¸ˆã¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³
    """
    session = requests.Session()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®š
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "ja,en-US;q=0.7,en;q=0.3",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    })
    
    # å¿…è¦ãªCookieã‚’è¨­å®š
    cookies_data = Config.get_required_cookies()
    for cookie in cookies_data:
        if cookie['value']:  # å€¤ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿
            session.cookies.set(
                name=cookie['name'],
                value=cookie['value'],
                domain=cookie.get('domain', 'p.keibabook.co.jp'),
                path=cookie.get('path', '/')
            )
    
    return session


@dataclass
class BatchStats:
    """ãƒãƒƒãƒå‡¦ç†ã®çµ±è¨ˆæƒ…å ±ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    total_races: int = 0
    success_count: int = 0
    error_count: int = 0
    skipped_count: int = 0
    start_time: Optional[datetime.datetime] = None
    end_time: Optional[datetime.datetime] = None
    processed_races: List[str] = field(default_factory=list)
    failed_races: List[str] = field(default_factory=list)
    
    def start(self):
        """å‡¦ç†é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²"""
        self.start_time = datetime.datetime.now()
    
    def finish(self):
        """å‡¦ç†çµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²"""
        self.end_time = datetime.datetime.now()
    
    def add_success(self, race_id: str):
        """æˆåŠŸã—ãŸãƒ¬ãƒ¼ã‚¹ã‚’è¨˜éŒ²"""
        self.success_count += 1
        self.processed_races.append(race_id)
    
    def add_error(self, race_id: str):
        """å¤±æ•—ã—ãŸãƒ¬ãƒ¼ã‚¹ã‚’è¨˜éŒ²"""
        self.error_count += 1
        self.failed_races.append(race_id)
    
    def add_skip(self):
        """ã‚¹ã‚­ãƒƒãƒ—ã—ãŸãƒ¬ãƒ¼ã‚¹ã‚’è¨˜éŒ²"""
        self.skipped_count += 1
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡ã‚’è¨ˆç®—"""
        if self.total_races == 0:
            return 0.0
        return (self.success_count / self.total_races) * 100
    
    @property
    def elapsed_time(self) -> Optional[datetime.timedelta]:
        """çµŒéæ™‚é–“ã‚’è¨ˆç®—"""
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        return None
    
    def to_dict(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’è¾æ›¸å½¢å¼ã§è¿”ã™"""
        return {
            'total_races': self.total_races,
            'success_count': self.success_count,
            'error_count': self.error_count,
            'skipped_count': self.skipped_count,
            'success_rate': f"{self.success_rate:.1f}%",
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'elapsed_time': str(self.elapsed_time) if self.elapsed_time else None,
            'processed_races': self.processed_races,
            'failed_races': self.failed_races
        }
    
    def print_summary(self, logger: Optional[logging.Logger] = None):
        """çµ±è¨ˆæƒ…å ±ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        output_func = logger.info if logger else print
        
        output_func("=" * 50)
        output_func("ğŸ“Š ãƒãƒƒãƒå‡¦ç†çµ±è¨ˆã‚µãƒãƒªãƒ¼")
        output_func("=" * 50)
        output_func(f"ğŸ“ˆ å‡¦ç†çµæœ:")
        output_func(f"  - ç·ãƒ¬ãƒ¼ã‚¹æ•°: {self.total_races}")
        output_func(f"  - æˆåŠŸ: {self.success_count}")
        output_func(f"  - å¤±æ•—: {self.error_count}")
        output_func(f"  - ã‚¹ã‚­ãƒƒãƒ—: {self.skipped_count}")
        output_func(f"  - æˆåŠŸç‡: {self.success_rate:.1f}%")
        
        if self.elapsed_time:
            output_func(f"  - å‡¦ç†æ™‚é–“: {self.elapsed_time}")
        
        if self.failed_races:
            output_func(f"âŒ å¤±æ•—ã—ãŸãƒ¬ãƒ¼ã‚¹:")
            for race_id in self.failed_races:
                output_func(f"  - {race_id}")
        
        output_func("=" * 50)


# é–‹å‚¬å ´æ‰€ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå…±é€šå®šæ•°ï¼‰
VENUE_MAPPING = {
    "æ±äº¬": "04",
    "ä¸­å±±": "06", 
    "é˜ªç¥": "01",
    "äº¬éƒ½": "02",
    "æ–°æ½Ÿ": "03",
    "ç¦å³¶": "05",
    "å°å€‰": "07",
    "æœ­å¹Œ": "08",
}

# é€†å¼•ãç”¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°
VENUE_CODE_TO_NAME = {v: k for k, v in VENUE_MAPPING.items()}

# ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®å®šç¾©
DATA_TYPES = ["seiseki", "shutsuba", "cyokyo", "danwa"] 
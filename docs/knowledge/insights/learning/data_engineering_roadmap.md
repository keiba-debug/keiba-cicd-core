# データエンジニアリング実践ロードマップ

競馬AIプロジェクト（KeibaCICD）のデータ基盤を強化するための実践的ロードマップ。
「座学→実践」ではなく、**プロジェクト自体を教材にして DE と DS を同時に学ぶ**アプローチ。

> 🧭 **考察の全体像**: [考察マスター](../../consideration_master.md) セクション4-6（運用・アーキテクチャ）と合わせて読む。
> 📖 **ML知識の体系**: [ML学習ロードマップ](ml_learning_roadmap.md) の各Levelと対応するDEフェーズを示す。
>
> 最終更新: 2026-02-12

---

## 1. なぜデータエンジニアリングが最優先か

### 松風ブログの教訓

- **Zeus（DB管理）が8モジュールの1つ**（blog-011）。予測モジュール（Poseidon）と同格の独立モジュールとしてデータ基盤を設計
- **「データはパワー」**（blog-012）。数千万円をデータ投資し1ヶ月で回収。データの量と質が競争優位の根源
- **バグで200万円損失**（blog-011）。データ（バンクロール状態）の一貫性が壊れただけで致命的な損害
- **運用ミスが最大のリスク**（blog-009）。モデルの精度より、データと運用の堅牢性が収益に直結

### データの価値チェーン

```
[収集]→[品質管理]→[蓄積/整備]→[分析/ML]→[意思決定]→[価値(収益)]
  ↑        ↑           ↑          ↑          ↑
 成熟     ☆不在       ★未稼働    構築中      設計中

 ← データエンジニアリング →|← データサイエンス →|← 運用 →
```

どんなに精緻な LightGBM モデルを作っても、入力データの品質が保証されなければ **Garbage In, Garbage Out**。

---

## 2. プロジェクトの現状診断

### 成熟度マップ

| レイヤー | 状態 | 具体的なアセット |
|----------|------|------------------|
| データ収集 | ★★★ 成熟 | fast_batch_cli.py（22ワーカー並列）、requests ベースの高速スクレイパー |
| データ解析 | ★★★ 成熟 | 出馬表/成績/調教/談話パーサー、RaceDataIntegrator |
| JRA-VANライブラリ | ★★★ 成熟 | common.jravan の統一IF、IDマッピング、調教分析 |
| パス管理 | ★★ 基盤あり | common/config.py で環境変数統一化 |
| バッチ自動化 | ★★ 基盤あり | daily/weekly スクリプト |
| SQL Server | ★ 定義のみ | スキーマ定義あり、EF Core 設定あり、**実データなし** |
| API | ★ 設計のみ | FastAPI / ASP.NET Core、**未デプロイ** |
| データ品質 | ☆ 不在 | スキーマ検証・異常検出・完全性チェックなし |
| データプロファイリング | ☆ 不在 | 分布・欠損率の自動把握なし |
| 監視・アラート | ☆ 不在 | パイプライン失敗の検知なし |
| MLパイプライン | ☆ 不在 | モデル再学習・バージョン管理なし |

### 現在のデータフロー

```
Web (競馬ブック)
    ↓ fast_batch_cli.py
Raw HTML/JSON
    ↓ Parsers (seiseki, syutuba, cyokyo, danwa)
    ↓ RaceDataIntegrator
Integrated JSON (organized/YYYY/MM/DD/{venue}/)
    ↓
[ここで断絶] ← 品質チェックなし、DBへの投入なし
    ↓ (手動 or アドホック)
分析スクリプト / Jupyter Notebook

JRA-VAN (C:\TFJV)
    ↓ common.jravan
Python オブジェクト
    ↓ (手動 or アドホック)
分析スクリプト / PCI計算
```

### リスク

- JSON ファイルに品質チェックがない → **サイレントなデータ破損がモデルに流入**
- JRA-VAN のフォーマット変更 → パーサーがサイレントに壊れる可能性
- 日次バッチの失敗 → 気づけない（アラートなし）
- 過去データの再現性 → 同じ条件で同じ特徴量を計算できる保証がない

---

## 3. 実践ロードマップ：Phase 1-5

### Phase 1: 品質の可視化（まず現状を知る）

**目標**: 既存データの品質を定量的に把握する

**やること**:

1. 主要テーブル（出馬表・成績・調教・オッズ）の `describe()` → 欠損率、分布、外れ値の概観
2. 時系列での品質推移 → 「先月から調教データの欠損率が上がった」等の変化を検知
3. カラム間の整合性チェック → 「出走頭数と実際のレコード数が合わない」等
4. データプロファイルレポートの自動生成

**学べるスキル**:

| スキル | 対応するDS知識 |
|--------|----------------|
| pandas profiling / ydata-profiling | 記述統計の実践（Level 0-1） |
| データ品質KPI設計 | 可視化（Level 0-2） |
| 品質メトリクスの時系列追跡 | 時系列分析の入口 |

**成果物**: データ品質レポート（自動生成）

---

### Phase 2: 品質ゲートの構築

**目標**: 壊れたデータがモデルに流れないようにする

**やること**:

1. integrated JSON のスキーマ定義 → pydantic / pandera で自動検証
2. バッチ実行後の自動品質チェック → daily_batch の後に実行
3. 品質ゲートの合格/不合格ルール → 不合格時は処理停止 + 通知
4. 異常値の自動検出 → オッズの急変、馬体重の異常、欠損率の急増

**学べるスキル**:

| スキル | 対応するDS知識 |
|--------|----------------|
| pydantic / pandera | スキーマ定義・型安全 |
| Great Expectations | データ検証フレームワーク |
| 異常検出の設計 | 統計検定（Level 0-5）、外れ値検出 |
| CI/CD 的な思考 | 品質ゲート＝テストと同じ発想 |

**成果物**: 自動品質チェックスクリプト + 品質ダッシュボード

---

### Phase 3: データウェアハウスの稼働

**目標**: JSON → SQL Server への ETL を構築し、分析可能な状態にする

**やること**:

1. 既存の DB スキーマ定義を活用して SQL Server を実稼働
2. JSON → DB の ETL パイプライン構築（増分更新対応）
3. 分析用ビューの設計（特徴量計算に使いやすい形）
4. 過去データの一括ロード + 日次差分更新

**学べるスキル**:

| スキル | 対応するDS知識 |
|--------|----------------|
| SQL（SELECT/JOIN/GROUP BY/WINDOW 関数） | クロス集計（Level 0-3）、集約統計 |
| ETL の設計パターン | データパイプラインの基本思考 |
| データモデリング（スター/スノーフレーク） | 分析しやすいデータ構造の設計 |
| インデックス設計 | クエリパフォーマンス最適化 |

**成果物**: 稼働する SQL Server + 日次更新の ETL スクリプト

---

### Phase 4: パイプラインの自動化と監視

**目標**: 収集→品質→DB→特徴量の一気通貫自動化と、障害の早期検知

**やること**:

1. 収集→品質チェック→DB登録→特徴量計算の一気通貫パイプライン
2. 各ステップのログ・メトリクスの収集
3. 失敗時のリトライとアラート（Slack/メール等）
4. データ鮮度の監視（「今日のデータがまだ来ていない」検知）

**学べるスキル**:

| スキル | 対応するDS知識 |
|--------|----------------|
| Prefect / Airflow | パイプラインオーケストレーション |
| ログ設計 | 改ざん防止ログ（blog-010 の税務要件） |
| リトライ戦略 | blog-011 の「運用ミスが最大のリスク」 |
| 監視ダッシュボード | 可視化（Level 0-2）の運用版 |

**成果物**: 自動パイプライン + 監視ダッシュボード + アラート

---

### Phase 5: MLパイプラインとの統合

**目標**: データ基盤の上にMLの学習→評価→デプロイを自動化

**やること**:

1. DB から直接特徴量を計算するクエリ/スクリプト
2. 特徴量の再現性保証（同じ入力 → 同じ特徴量）
3. モデルの学習→評価→デプロイの自動化
4. 予測結果と実績の突合せ（キャリブレーション監視）

**学べるスキル**:

| スキル | 対応するDS知識 |
|--------|----------------|
| MLflow / Weights & Biases | モデルバージョン管理 |
| 特徴量ストア | 特徴量エンジニアリング（Level 3） |
| Walk-Forward Validation の自動化 | 時系列検証（Level 1-3） |
| キャリブレーション監視 | 確率推定の品質保証（Level 1-1） |

**成果物**: 自動ML パイプライン + モデルレジストリ + 予測品質監視

---

## 4. DE × DS 統合ロードマップ

各Phaseで **DE（作る）と DS（分析する）が対になっている**。

```
        データエンジニアリング          データサイエンス
        (基盤構築)                    (分析・モデル)
Phase1  データプロファイリング    ←→   記述統計・EDA (Level 0-1, 0-2)
Phase2  品質ゲート構築          ←→   統計検定・異常検出 (Level 0-5)
Phase3  データウェアハウス      ←→   SQL・クロス集計 (Level 0-3, 0-6)
Phase4  パイプライン自動化      ←→   特徴量エンジニアリング (Level 3)
Phase5  ML基盤統合             ←→   モデル構築・評価 (Level 1-2)
        ─────────────────────────────────────────────
        全Phase: 可視化・監視ダッシュボード (Level 0-2)
```

---

## 5. 技術スタックの選定指針

| 領域 | 推奨技術 | 理由 |
|------|----------|------|
| データ品質 | pandera / Great Expectations | pandas との親和性、宣言的なルール定義 |
| スキーマ定義 | pydantic | 既存の Python コードと統合しやすい |
| DB | SQL Server（既存） | スキーマ定義済み、EF Core 設定済み |
| ETL | Python + SQLAlchemy / pandas | 既存アセットとの親和性 |
| オーケストレーション | Prefect | Python ネイティブ、軽量、ローカル実行可 |
| 監視 | Grafana + Prometheus / 自作ダッシュボード | 柔軟性 |
| ML管理 | MLflow | OSS、LightGBM 対応、ローカル実行可 |
| プロファイリング | ydata-profiling | 1行で品質レポート生成 |

---

## 6. 松風アーキテクチャとの対応

```
松風の8モジュール:              KeibaCICD の対応:
  Zeus（DB管理）          →   Phase 3: SQL Server + ETL
  Poseidon（モデル構築）  →   Phase 5: MLflow + 自動学習
  Themis（購入決定）      →   （将来: EV計算 + 購入ロジック）
  [データ収集]            →   既存: fast_batch_cli.py ✓
  [予測]                  →   Phase 5: 予測サービング
  [購入実行]              →   （将来: PAT連携）
  [ツイート/証跡]         →   Phase 4: ログ + 改ざん防止
  [分析基盤]              →   Phase 4: 監視ダッシュボード
```

---

## 7. 優先順位の判断基準

| 優先度 | 条件 | このプロジェクトでの例 |
|--------|------|------------------------|
| 高 | データ品質に直結。既存資産で始められる | Phase 1（プロファイリング）、Phase 2（品質ゲート） |
| 中 | 分析・モデリングの効率を上げる。構築コスト中 | Phase 3（DWH）、Phase 4（自動化） |
| 低 | 本格運用時に必要。現段階では設計のみでよい | Phase 5（MLパイプライン）、クラウドデプロイ |

**松風の教訓を適用**: 「80%の確信で実装開始し、実運用データで再検証するサイクルを回す」（仮説検証マスター 6-6）。完璧な基盤を作ってからMLを始めるのではなく、Phase 1-2 で品質を確保しつつ、並行してモデル構築も進める。

---

## タグ

`#運用` `#データソース` `#前処理` `#モデル` `#特徴量`

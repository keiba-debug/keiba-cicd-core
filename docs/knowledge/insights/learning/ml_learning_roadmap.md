# 競馬AI開発のためのML学習ロードマップ

松風ブログの知見と競馬AI開発の実務要件から逆算した、学ぶべき知識の体系的整理。

> 📖 **用語集**: 本ロードマップで登場する用語の詳細は [ML用語集](ml_glossary.md) を参照。
> 🧭 **考察の全体像**: [考察マスター](../../consideration_master.md) のテーママップと合わせて読むと、各Level が「何のために必要か」が明確になる。
> 🔧 **データ基盤**: [データエンジニアリング実践ロードマップ](data_engineering_roadmap.md) で DE × DS の統合学習計画を確認。
> 📚 **書籍連携**: [書籍×プロジェクト実践学習ロードマップ](book_learning_roadmap.md) で所有書籍の各章と keiba-v2 コードの対応を確認。
>
> 最終更新: 2026-02-12

---

## 全体マップ

```
┌──────────────────────────────────────────────────────────┐
│                    競馬AIシステム全体像                      │
│                                                            │
│  [収集]→[品質]→[蓄積]→[探索]→[前処理]→[モデル]→[購入]→[実行]│
│    ↑      ↑      ↑      ↑       ↑       ↑      ↑      ↑   │
│  スクレ  検証   SQL/DB  EDA    特徴量  ML基礎  期待値  運用  │
│  イピング 異常   ETL   記述統計 エンジニ アルゴ  ケリー  自動化│
│  API    検出   DWH    可視化  アリング リズム  基準        │
│                       相関/検定       確率論  ポートフォ   │
│                       クロス集計      キャリ  リオ理論     │
│                                      ブレー              │
│  ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─  │
│  [DE基盤] 品質管理・パイプライン監視・データ鮮度チェック     │
│  [DS基盤] 記述統計・可視化・相関分析・統計検定・クロス集計   │
│  ↑ 両者は全フェーズに通底する基盤スキル                     │
└──────────────────────────────────────────────────────────┘
```

> **重要**: データ分析（DS）とデータエンジニアリング（DE）の基盤スキルは Level 0 で学んで終わりではなく、**全 Level のあらゆるフェーズで継続的に使う**。DE はデータの信頼性を保証し、DS はそのデータから知見を引き出す。両輪がなければ価値は生まれない。
> 詳細は [データエンジニアリング実践ロードマップ](data_engineering_roadmap.md) を参照。

---

## Level 0: データ分析・統計・確率の基礎（最優先）

松風ブログの根幹は「確率論的競馬観」。MLアルゴリズムの前にここが土台。
また、ここで身につける分析スキルは Level 0 を「卒業」して終わりではなく、**モデリングの前・中・後のすべてのフェーズで常に使う基盤スキル**。

### 0-1. 記述統計と探索的データ分析（EDA）★★★

**モデルを作る前にデータの姿を知る**。ここを飛ばしてMLに進むと、外れ値・欠損・偏りに気づけず、無意味なモデルを作ることになる。

| トピック | なぜ必要か | 競馬での具体例 |
|---|---|---|
| 代表値（平均・中央値・最頻値） | データの中心を把握 | 馬体重の平均480kgを知らずに外れ値判定はできない |
| 散布度（標準偏差・IQR・範囲） | データのばらつきを把握 | 走破タイムの標準偏差でレースの接戦度がわかる |
| 分布の形状（歪度・尖度・ヒストグラム） | 正規分布かどうか、外れ値の存在 | オッズは右に歪んだ分布。対数変換の判断に直結 |
| 欠損値・外れ値の検出 | データ品質の確認 | JRA-VANデータの欠損パターンを知らずに前処理はできない |
| 集約統計（GROUP BY的な操作） | カテゴリ別の傾向把握 | 競馬場別・距離別・馬場別の平均走破タイム |

```
EDAの基本ステップ（競馬データ）:

  1. 全特徴量のdescribe() → 分布・欠損・外れ値の概観
  2. 目的変数の分布確認 → 勝率は約6%（18頭立て）、極端な不均衡
  3. 主要特徴量のヒストグラム → 馬体重、オッズ、タイム等の分布形状
  4. カテゴリ変数の頻度表 → 芝/ダート比率、クラス分布、競馬場の偏り
  5. 時系列トレンド → 年度ごとの走破タイムの推移（馬場の高速化等）
```

### 0-2. 可視化 ★★★

記述統計を「目で見る」力。数表だけでは気づけないパターンを発見する。

| グラフ種別 | 用途 | 競馬での具体例 |
|---|---|---|
| ヒストグラム・密度プロット | 分布の形状確認 | オッズ分布、馬体重増減分布 |
| 箱ひげ図 | 群間比較、外れ値検出 | 競馬場別の走破タイム比較 |
| 散布図 | 2変数の関係性 | 予測確率 vs 実際の勝率（キャリブレーションプロット） |
| 折れ線グラフ | 時系列推移 | バンクロール推移、月次回収率推移 |
| ヒートマップ | 相関行列、クロス集計 | 特徴量間の相関、馬券種間の相関 |
| バープロット | カテゴリ別比較 | 脚質別勝率、枠番別複勝率 |

```
★★★ 可視化が活きる場面（全Level共通）:

  Level 0: データの姿を知る（ヒストグラム、箱ひげ図）
  Level 1: キャリブレーションプロット（予測確率 vs 実際の勝率）
  Level 2: ハイパラ最適化の経過（Optunaの可視化）
  Level 3: 特徴量重要度、SHAP summary plot
  Level 4: バンクロール推移シミュレーション、ドローダウン分布
  Level 5: 運用ダッシュボード、収支モニタリング
```

### 0-3. クロス集計と層別分析 ★★

カテゴリ変数の交差を見て、パターンと仮説を生成する手法。

| トピック | なぜ必要か | 競馬での具体例 |
|---|---|---|
| クロス集計（二元表） | 2つのカテゴリの関連を見る | 芝/ダート × 脚質別の勝率 |
| 層別分析 | 条件を絞って傾向を見る | 「東京芝2000mでの差し馬の成績」 |
| ピボットテーブル | 多次元の集計 | 距離×馬場状態×枠番の平均着順 |

```
★★★ 注意: クロス集計の罠（blog-005の教訓）

  クロス集計は「仮説の生成」に使う。「仮説の検証」に使ってはいけない。

  × 種牡馬×距離×コースで高回収率の組合せを発見 → そのまま採用
    → サンプル10レースの偶然にフィット = 過学習

  ○ 種牡馬×距離×コースの傾向を見る → 仮説を立てる → 別データで検証
    → 「この種牡馬は長距離で好走する」を時系列分割で確認

  クロス集計のセル（=条件の組合せ）が細かくなるほどサンプルは減る。
  「サンプル30未満のセルの結果は信じない」が安全な目安。
```

### 0-4. 確率論の基礎 ★★★

| トピック | なぜ必要か | 松風ブログとの関連 |
|---|---|---|
| 条件付き確率・ベイズの定理 | 「出走馬Aが勝つ確率」の正しい計算 | 003: 確率的予測の基礎 |
| 確率分布（正規、二項、ポアソン） | モデル出力の解釈、分散の理解 | 005: 収束に必要な回数 |
| 大数の法則・中心極限定理 | 「大量購入で収束する」の根拠 | 002: 設定6のジャグラー |
| 期待値と分散 | EV計算、リスク評価の基礎 | 006: EV>1.0を全部買え |

### 0-5. 統計検定 ★★

「偶然か実力か」を判断するための道具立て。

| トピック | なぜ必要か | 松風ブログとの関連 |
|---|---|---|
| 仮説検定（t検定、カイ二乗検定） | 「回収率100%超は偶然か？」の判定 | 005: 統計的有意性 |
| 信頼区間・ブートストラップ | バックテスト結果の信頼性評価 | 009: 回収率114%の検定 |
| 多重検定補正（Bonferroni等） | 馬券種別収支の同時評価。「サイコロ100個」の罠を防ぐ | 012: サイコロ100個の比喩 |
| 並べ替え検定（Permutation Test） | 分布の前提を置かないノンパラ検定。競馬データは正規分布に従わないことが多い | — |
| 自己相関・ラン検定 | 試行間の独立性検証 | 009: 独立性仮定 |
| 効果量（Cohen's d等） | p値だけでなく「差の大きさ」も評価。サンプル大だとp値は小さくなりがちなので効果量で補完 | — |

```
★★ 統計検定の実務的な心得:

  1. p値は「どのくらい珍しいか」であって「どのくらい重要か」ではない
  2. 競馬データはサンプルが大きいのでp < 0.05は簡単に出る → 効果量を見る
  3. 競馬データは厳密な独立同分布を満たさないことが多い
     → ブートストラップや並べ替え検定の方が堅牢
  4. 多重検定補正を忘れると、ランダムな差を「発見」してしまう
```

### 0-6. 相関分析と回帰の基礎 ★★★

| トピック | なぜ必要か | 競馬での具体例 |
|---|---|---|
| 相関係数（ピアソン・スピアマン） | 2変数の関連の強さと方向 | 走破タイムと上がり3Fの相関 |
| 共分散行列 | 多変数間の相関構造を一覧 | 馬券種間の相関（ポートフォリオ設計） |
| 偏相関・疑似相関 | 第三の変数の影響を排除した真の関連 | 馬体重と勝率の相関（クラスが交絡変数） |
| 線形回帰・ロジスティック回帰 | 最もシンプルな予測モデル。ベースライン | 勝率推定のベースライン。LightGBMの比較対象 |
| 決定係数(R²)・残差分析 | モデルの適合度評価 | 走破タイム予測の精度評価 |

```
相関分析の使いどころ（プロジェクト横断）:

  特徴量選択:
    相関が高い特徴量ペア → 片方を落とすか差分を取る（多重共線性の除去）
    目的変数との相関が低い特徴量 → 削減候補

  ポートフォリオ設計（柱5）:
    馬券種間の相関行列 → ワイドと馬連の相関が高ければ分散効果は薄い
    相関の低い馬券種の組合せ → リスク分散

  モデル監視:
    特徴量重要度と相関の変化 → モデルの経年劣化の検知
```

---

## Level 1: 機械学習の基礎

### 1-1. 教師あり学習（Supervised Learning）★最重要

競馬AIの中核。「過去データから学習し、未来を予測する」パラダイム。

| トピック | 内容 | 競馬での用途 |
|---|---|---|
| **分類（Classification）** | カテゴリを予測 | 「勝つ/勝たない」の二値分類 |
| **回帰（Regression）** | 連続値を予測 | 走破タイム予測 |
| **確率推定** | 各クラスの確率を出力 | 各馬の勝率推定 ← **本命** |
| **ランキング学習** | 順位関係を学習 | 着順予測 |

#### 目的変数（ターゲット）の設計 ★★★

松風ブログの知見(004)から、**何を予測するか**がアルゴリズム以上に重要。

```
目的変数の候補と特性:

1. 着順（1着/2着/3着...）
   - タイプ: 多クラス分類 or 順序回帰
   - 利点: 直感的
   - 欠点: 「1着を当てる」に最適化されがち → 回収率最大化と乖離

2. 勝率/複勝率（0〜1の確率値）
   - タイプ: 確率推定（二値分類のpredict_proba）
   - 利点: 直接EV計算に使える。松風ブログの思想と完全整合
   - 欠点: キャリブレーション（較正）が必須
   - ★★★ 推奨

3. 走破タイム
   - タイプ: 回帰
   - 利点: 物理的に意味がある、馬場差補正等と組み合わせやすい
   - 欠点: 確率への変換が別途必要

4. 着差/相対タイム
   - タイプ: 回帰
   - 利点: 絶対タイムよりも安定

5. 期待値（EV）を直接予測
   - タイプ: 回帰（オッズを入力に含む）
   - 利点: 最終目標に直結
   - 欠点: オッズ自体が変動する、過学習リスク大
```

#### キャリブレーション（較正）★★

確率推定モデルの生命線。「勝率30%と予測した馬が実際に約30%勝つ」ことの保証。

```
較正が良いモデル:
  予測確率30%の馬 → 実際の勝率 ≈ 30% ← EV計算が正確

較正が悪いモデル:
  予測確率30%の馬 → 実際の勝率 = 15% ← EV計算が狂う → 破産

評価指標:
  - キャリブレーションプロット（信頼度図）
  - ブライアスコア = Σ(予測確率 - 実際結果)² / N
  - 対数損失（Log Loss）

較正手法:
  - Plattスケーリング（シグモイド補正）
  - 等頻度ビニング（Isotonic Regression）
  - Temperature Scaling
```

### 1-2. 教師なし学習（Unsupervised Learning）

直接的には馬券購入に使わないが、データ理解と前処理で有用。

| 手法 | 内容 | 競馬での用途 |
|---|---|---|
| **クラスタリング**（K-means, DBSCAN） | データのグループ分け | レースタイプの分類、馬の脚質分類 |
| **次元削減**（PCA, t-SNE, UMAP） | 高次元データの可視化・圧縮 | 特徴量の可視化、多重共線性の除去 |
| **異常検出** | 外れ値の発見 | 異常オッズ検出、データ品質チェック |

**競馬での優先度**: 低〜中。まず教師あり学習で基盤を作り、必要に応じて導入。

### 1-3. 評価手法 ★★

モデルの良し悪しを正しく測る方法。過学習防止の要。

| トピック | 内容 | なぜ重要か |
|---|---|---|
| **交差検証（Cross-Validation）** | データを分割して汎化性能を測る | 005: 過学習防止の核心 |
| **時系列分割** | 未来のデータでテスト | 競馬は時系列データ → ランダム分割はNG |
| **学習曲線** | サンプル数と性能の関係 | 十分なデータ量の判断 |
| **混同行列・AUC-ROC** | 分類性能の多角的評価 | 的中率以外の評価軸 |
| **ブライアスコア・ECE** | 確率予測の較正精度を直接測る | キャリブレーションの定量評価。AUCより重視すべき |

```
★★★ 競馬での交差検証の注意点:

  × ランダムにtrain/testを分割
    → 未来のデータで学習してしまう（データリーク）

  ○ 時系列で分割（Walk-Forward Validation）
    → 2020年データで学習 → 2021年データでテスト
    → 2020-2021年データで学習 → 2022年データでテスト
    → ...
```

### 1-4. 説明可能性（Explainability）★★

予測の根拠を理解し、デバッグと信頼性向上に使う。

| 手法 | 内容 | 競馬での用途 |
|---|---|---|
| **SHAP（SHapley Additive exPlanations）** | 各特徴量が個別予測にどれだけ寄与したか | 馬ごとの好材料・懸念材料の特定。デバッグ |
| **特徴量重要度（Feature Importance）** | 全体で各特徴量がどれだけ効いているか | モデル全体の傾向把握。リーク疑い検出 |
| **Partial Dependence Plot（PDP）** | 1つの特徴量と予測の関係を可視化 | 「馬体重増減と勝率」などの非線形関係の理解 |
| **LIME** | 個別予測の局所的な説明 | SHAP の軽量代替。速度重視の場合 |

```
SHAPの実践的な使い方:

  1. モデル全体の特徴量重要度 → 上位の特徴量が妥当か確認
  2. 個別予測の分解 → 「なぜこの馬が高確率か」を説明
  3. リーク検出 → 本来使えない情報が重要度上位にいないか
  4. 推理エンターテインメント → prediction_interview_feature の基盤
```

**関連**: [予測根拠のインタビュー機能](../model/prediction_interview_feature.md

---

## Level 2: アルゴリズム詳論

### 2-1. アンサンブル学習 ★★

複数のモデルを組み合わせて性能を上げる手法群。

```
アンサンブルの種類:

1. バギング（Bagging）
   代表: RandomForest
   原理: 複数の決定木を並列に学習 → 多数決/平均
   利点: 過学習に強い、安定、チューニング少

2. ブースティング（Boosting）★★★
   代表: LightGBM, XGBoost, CatBoost
   原理: 弱い学習器を逐次的に改善 → 残差を学習
   利点: 表形式データで最強クラス、高精度

3. スタッキング（Stacking）
   原理: 複数モデルの出力を別モデルの入力にする
   利点: 異なるモデルの長所を統合
   リスク: 過学習しやすい、複雑化
```

### 2-2. 勾配ブースティング（Gradient Boosting）★★★

**競馬AI開発のデファクトスタンダード**。松風もおそらくこの系統。

| ライブラリ | 特徴 | 推奨度 |
|---|---|---|
| **LightGBM** | 高速、メモリ効率良、カテゴリ変数を直接扱える | ★★★ 最推奨 |
| **XGBoost** | 安定、実績豊富 | ★★ |
| **CatBoost** | カテゴリ変数に強い、順序ブースティング | ★★ |

```
なぜ勾配ブースティングか:
  1. 表形式データ（CSV）で最高性能（← 競馬データは表形式）
  2. 特徴量重要度が見える → どの情報が効いているか分かる
  3. 欠損値を自然に扱える
  4. カテゴリ変数をエンコードなしで扱える（LightGBM, CatBoost）
  5. チューニングの余地が大きい
  6. 確率出力（predict_proba）が可能

学ぶべき主要パラメータ:
  - learning_rate: 学習率（小さいほど慎重、大きいほど速い）
  - num_leaves / max_depth: 木の複雑さ
  - n_estimators: 木の数
  - min_child_samples: 葉の最小サンプル数（過学習防止）
  - reg_alpha / reg_lambda: 正則化（L1/L2）
  - subsample / colsample: ランダム化（過学習防止）
```

### 2-3. ハイパーパラメータ最適化 ★★

モデルの性能を引き出すための自動チューニング。

```
手法の比較:

  グリッドサーチ（Grid Search）
    - 全組合せを試す。パラメータ数が少ないときのみ実用的
    - ★ 非推奨（探索空間が大きいと計算量爆発）

  ランダムサーチ（Random Search）
    - 無作為にサンプリング。グリッドより効率的
    - 基本的だが意外と強い

  ベイズ最適化 / Optuna ★★★
    - 過去の結果から次に試すべきパラメータを賢く選ぶ
    - TPE（Tree-structured Parzen Estimator）が主流
    - 枝刈り（Pruning）で無駄な試行を早期打ち切り

Optunaの基本パターン:
  import optuna

  def objective(trial):
      params = {
          'learning_rate': trial.suggest_float('lr', 0.005, 0.1, log=True),
          'num_leaves': trial.suggest_int('num_leaves', 15, 255),
          'min_child_samples': trial.suggest_int('min_child', 5, 100),
          'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
          'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
      }
      # Walk-Forward CV で評価
      return cv_score(params)

  study = optuna.create_study(direction='minimize')
  study.optimize(objective, n_trials=200)

★★★ 注意:
  - 最適化用の検証データとは別に、ホールドアウトを確保
  - 「最適化への過学習」を防ぐ
  - 005の教訓: チューニングにも平均回帰が効く
```

### 2-4. ランキング学習（Learning to Rank）★

着順予測に直接取り組むアプローチ。確率推定とは相補的。

```
手法:
  Pointwise: 各馬の「スコア」を個別に回帰 → ソート
  Pairwise:  「AがBに先着する確率」をペア単位で学習
  Listwise:  レース全体の着順関係を一括で学習 ★

代表アルゴリズム:
  - LambdaRank / LambdaMART（LightGBMの'lambdarank'目的関数）
  - RankNet（ニューラルネット版ペアワイズ）
  - ListNet / ListMLE（Listwise系）

競馬での位置づけ:
  - 「確率推定→EV計算」がメインパイプライン（柱1）
  - ランキング学習は「着順の相対関係」を直接最適化
  - 三連単等の組合せ馬券で、着順関係の精度が効く場面がある
  - ★ まず確率推定を確立した後、補完として検討
```

### 2-5. 条件付き確率モデル（着順の依存構造）★★

組合せ馬券（馬連・三連単等）の確率を正しく計算するための数理。

```
Harville モデル:
  P(A→B→C) = P(A勝) × P(B勝|A除外) × P(C勝|A,B除外)
  P(B勝|A除外) = P(B勝) / (1 - P(A勝))
  利点: シンプル、単勝確率から変換可能
  欠点: IIA仮定（脱落馬の確率が比例配分される）

Henery モデル:
  能力値をガンベル分布と仮定し、IIA仮定を緩和
  より正確だが計算コストが高い

Thurstone モデル:
  能力値を正規分布と仮定。馬ごとの「分散」も考慮
  IIA違反の根本原因（分散の違い）に対応

段階的アプローチ:
  Step 1: Harville で組合せ確率の基盤を構築
  Step 2: 人気馬バイアス補正（Henery的な調整）
  Step 3: 馬ごとの分散推定（Thurstone的な拡張）
```

**関連**: [組合せ馬券の確率計算](../market/combination_ticket_probability.md, [HarvilleのIIA批判](../market/harville_iia_critique.md

### 2-6. ディープラーニング（Deep Learning）

| 観点 | 評価 |
|---|---|
| 表形式データへの適用 | △ 勾配ブースティングに劣ることが多い |
| 画像データ（レース映像等） | ★★★ 圧倒的に有利 |
| テキストデータ（競馬新聞コメント等） | ★★ 有用 |
| 学習コスト（人間の学習） | 高い（基礎知識が多い） |
| 計算コスト | 高い（GPU必要） |

```
ディープラーニングが活きる場面:

  1. レース映像解析（CNN / Vision Transformer）
     → 位置取り、脚質、不利の自動検出
     → 012: 松風が数千万円投資した「目視データ」の自動化版

  2. テキスト情報の活用（NLP / Transformer）
     → 競馬新聞のコメント、調教師コメントの数値化

  3. 時系列パターン（RNN / LSTM / Transformer）
     → 過去N走の成績パターンの学習

  4. TabNet等の表形式特化DL
     → 勾配ブースティングの代替として検討可能
```

**結論**: まずLightGBMで基盤を作る。ディープラーニングは独自データ（映像等）に拡張する際に学ぶ。

### 2-7. アルゴリズム選択の判断基準

```
判断フロー:

  データは表形式？
    ├─ Yes → LightGBM / XGBoost（★★★ まずこれ）
    │         └─ 確率出力が不十分 → キャリブレーション追加
    │
    └─ No
        ├─ 画像 → CNN / Vision Transformer
        ├─ テキスト → BERT / Transformer
        └─ 時系列 → LSTM / Transformer

  松風(004)の「アルゴリズムは何でもいい」:
    → 表形式データにおいて、LightGBMとXGBoostの差は
      特徴量設計の差に比べて小さい、という意味
```

---

## Level 3: 特徴量エンジニアリング ★★★

松風ブログで「アルゴリズムより重要」と断言された領域。

### 3-1. 特徴量の種類

| カテゴリ | 具体例 | エンコーディング |
|---|---|---|
| **数値** | 走破タイム、馬体重、オッズ | そのまま or 正規化 |
| **カテゴリ** | 競馬場、馬場状態、脚質 | Label / OneHot / Target Encoding |
| **順序** | クラス（G1>G2>...）、枠番 | 数値マッピング |
| **時系列** | 過去N走の成績 | 集約統計量（平均、最大、トレンド） |
| **テキスト** | 調教コメント | TF-IDF / Embedding |

### 3-2. 競馬特有の特徴量設計

```
基本特徴量（公開データから）:
  - 馬の基本情報: 年齢、性別、馬体重、馬体重増減
  - 過去成績: 過去N走の着順、タイム、上がり3F
  - コース適性: 芝/ダート、距離、右/左回り
  - 騎手: 騎手ID、騎手の直近成績
  - 調教: 調教タイム、調教パターン
  - 枠順: 枠番、馬番
  - レース条件: クラス、出走頭数、天候、馬場状態

上級特徴量（独自計算）:
  - オッズ乖離度: AI予測確率 vs 市場オッズ（001）
  - スマートマネー指標: 最終→確定オッズの変動（007）
  - 馬主クラブフラグ: 応援馬券によるオッズ歪み（001）
  - 各馬券のEV: 確率 × オッズ（006）

差別化特徴量（独自データから）:
  - レース映像解析: 位置取り、不利、コース取り（012）
  - パドック解析: 馬体のコンディション
  - 馬場の詳細: 内外差、含水率
```

### 3-3. 特徴量選択と注意点

```
やるべきこと:
  ✓ 特徴量重要度の確認（LightGBMのfeature_importance）
  ✓ 相関の高い特徴量の除去（多重共線性）
  ✓ 時間的にリークしない特徴量のみ使用
  ✓ 十分なサンプルがある粒度で集計

やってはいけないこと（005の教訓）:
  × 種牡馬×距離×コースの細分化分析
  × 少数サンプルで高回収率の条件を探す
  × 結果を見てから特徴量を追加/削除
```

---

## Level 4: 購入戦略の数理

### 4-1. 期待値（EV）計算

```
基本: EV = P(的中) × オッズ
  EV > 1.0 → 長期的にプラス → 購入
  EV < 1.0 → 長期的にマイナス → 見送り
```

### 4-2. ケリー基準（Kelly Criterion）

最適な賭け金を数学的に導出する理論。

```
ケリー基準:
  f* = (p × b - q) / b

  f* = 最適賭け率（バンクロールに対する割合）
  p  = 勝率
  q  = 1 - p（負ける確率）
  b  = オッズ - 1（純利益倍率）

例: 勝率30%、オッズ5.0の場合
  f* = (0.3 × 4 - 0.7) / 4 = 0.125（バンクの12.5%）

実用上の注意:
  - フルケリーは変動が激しすぎる
  - ハーフケリー（f*/2）or クォーターケリーが推奨
  - 松風の「safety_factor」はこの調整に相当
```

### 4-3. ポートフォリオ理論

```
マーコウィッツ理論の馬券版:
  目的: 期待リターンを最大化しつつ、リスク（分散）を最小化
  手段: 相関の低い馬券種を組み合わせる

  シャープレシオ = (期待リターン - 無リスク利子率) / 標準偏差
  → 馬券では: (回収率 - 1) / 収支の標準偏差
```

### 4-4. モンテカルロシミュレーション

```
用途:
  - 破産確率の推定
  - ドローダウン分布の把握
  - パラメータの最適値探索

手順:
  1. モデルの的中率・回収率分布を推定
  2. N年分の仮想レースを生成
  3. バンクロール推移をシミュレーション
  4. 破産（バンク < 閾値）した回数 / 総試行回数 = 破産確率
  5. 10万回以上繰り返して信頼性を確保
```

---

## Level DE: データエンジニアリング基盤

データの収集・品質管理・蓄積・パイプライン構築に関するスキル。MLモデルの信頼性はデータ基盤の堅牢性に依存する。

> 詳細は [データエンジニアリング実践ロードマップ](data_engineering_roadmap.md) を参照。

### DE-1. データ品質管理 ★★★

「壊れたデータがモデルに流れない」ことを保証する。

| トピック | 内容 | 競馬での用途 |
|---|---|---|
| **データプロファイリング** | 分布・欠損率・外れ値の自動把握 | JRA-VAN/競馬ブックデータの品質レポート |
| **スキーマ検証** | データ構造の自動検証（pydantic/pandera） | integrated JSONの型チェック |
| **品質KPI** | 完全性・正確性・一貫性・鮮度の4軸 | 「調教データの欠損率が今週急増」の検知 |
| **異常検出** | 統計的に逸脱したデータの自動フラグ | オッズの急変、馬体重の異常値 |

### DE-2. ETL と データウェアハウス ★★

データを収集→変換→蓄積するパイプラインの構築。

| トピック | 内容 | 競馬での用途 |
|---|---|---|
| **ETLの設計** | Extract/Transform/Load のパターン | JSON → SQL Server への変換パイプライン |
| **SQL（分析クエリ）** | JOIN/GROUP BY/WINDOW関数 | 過去N走の集約、条件別勝率のクロス集計 |
| **データモデリング** | スター/スノーフレークスキーマ | 分析しやすいテーブル設計 |
| **増分更新** | 差分のみを効率的に更新 | 日次の新規レースデータの追加 |

### DE-3. パイプラインの自動化・監視 ★★

一気通貫の自動化と障害の早期検知。

| トピック | 内容 | 競馬での用途 |
|---|---|---|
| **オーケストレーション** | Prefect/Airflow でのタスク管理 | 収集→品質→DB→特徴量の自動実行 |
| **ログ・監視** | 構造化ログ、メトリクス収集 | パイプライン失敗の即座の検知 |
| **リトライ戦略** | 一時的な障害からの自動復旧 | スクレイピング失敗時の再試行 |
| **データ鮮度チェック** | 期待通りにデータが更新されているか | 「今日のレースデータがまだ来ていない」検知 |

---

## Level 5: 実装・運用スキル

### 5-1. Pythonライブラリ

| 領域 | ライブラリ | 用途 |
|---|---|---|
| データ操作 | pandas, numpy | データ前処理の基盤 |
| ML | scikit-learn | 基本ML、前処理、評価、キャリブレーション |
| 勾配ブースティング | lightgbm, xgboost, catboost | メインモデル |
| ハイパラ最適化 | optuna | ベイズ最適化によるチューニング |
| 説明可能性 | shap | SHAP値算出、特徴量の寄与可視化 |
| 可視化 | matplotlib, seaborn, plotly | キャリブレーションプロット、ダッシュボード等 |
| 統計 | scipy.stats | 検定、分布 |
| シミュレーション | numpy (random) | モンテカルロシミュレーション |
| DL（将来） | PyTorch | 画像・テキスト解析 |

### 5-2. データベース

```
必要な知識:
  - SQL基礎（SELECT, JOIN, GROUP BY, WINDOW関数）
  - JRA-VANデータのスキーマ理解
  - 時系列データの効率的なクエリ
```

### 5-3. 自動化・運用

```
必要な知識:
  - スケジューリング（cron, タスクスケジューラ）
  - プロセス管理（マルチプロセス、状態同期 ← 011のバグ教訓）
  - エラーハンドリング・リトライ
  - ログ管理（改ざん防止 ← 010の税務要件）
```

---

## 学習の優先順位

```
Phase 1（まず動くものを作る）:
  ├── 記述統計・EDA・可視化（Level 0-1, 0-2）★ データの姿を知る
  ├── 確率・統計の基礎（Level 0-4, 0-5）
  ├── 相関分析・回帰の基礎（Level 0-6）
  ├── 教師あり学習の基礎（Level 1-1）
  ├── LightGBMの使い方（Level 2-2）
  ├── 基本特徴量の設計（Level 3）
  └── EV計算の実装（Level 4-1）

Phase 2（精度を上げる）:
  ├── クロス集計で仮説生成（Level 0-3）★ 特徴量の着想を得る
  ├── 統計検定で仮説を検証（Level 0-5）★ 偶然か実力かを判断
  ├── キャリブレーション（Level 1-1）
  ├── 交差検証・時系列分割（Level 1-3）
  ├── SHAP・説明可能性（Level 1-4）
  ├── Optunaによるハイパラ最適化（Level 2-3）
  ├── 特徴量エンジニアリング応用（Level 3）
  ├── 過学習対策の深掘り（Level 1-3, 2-2）
  └── ケリー基準・バンクロール管理（Level 4-2）

Phase 3（差別化する）:
  ├── 条件付き確率モデル・Harville（Level 2-5）
  ├── ポートフォリオ最適化（Level 4-3）★ 相関分析が前提
  ├── モンテカルロシミュレーション（Level 4-4）
  ├── ランキング学習（Level 2-4）
  ├── ディープラーニング基礎（Level 2-6）
  ├── 独自データの構築（映像解析等）
  └── 運用自動化（Level 5）

DE（Phase 1-2 と並行して進める）:
  ├── データプロファイリング（Level DE-1）★ 品質を可視化
  ├── 品質ゲート構築（Level DE-1）★ 壊れたデータを止める
  ├── ETL・データウェアハウス稼働（Level DE-2）
  └── パイプライン自動化・監視（Level DE-3）
  → 詳細は data_engineering_roadmap.md のPhase 1-5を参照

全Phase共通:
  └── 可視化・記述統計・相関分析（Level 0）★ 常に使い続ける基盤
  └── データ品質管理・鮮度チェック（Level DE-1）★ 全フェーズの前提
```

---

## 松風ブログの知見 × ML知識の対応表

| 松風ブログの知見 | 必要なML知識 | ロードマップ |
|---|---|---|
| 確率論的競馬観（003） | 確率推定、キャリブレーション | Level 0-4, 1-1 |
| データの姿を知れ（004） | 記述統計、EDA、可視化 | Level 0-1, 0-2 |
| 特徴量が全て（004） | 特徴量エンジニアリング + クロス集計で仮説生成 | Level 0-3, 3 |
| EV>1.0を全部買え（006） | 期待値計算、ケリー基準 | Level 4-1, 4-2 |
| アルゴリズムは何でもいい（004） | 勾配ブースティング（まずLightGBM） | Level 2-2 |
| 過学習の回避（005） | 交差検証、正則化、時系列分割、統計検定 | Level 0-5, 1-3, 2-2 |
| サイコロ100個の罠（012） | 多重検定補正、効果量 | Level 0-5 |
| なぜこの馬が高確率か（insight） | SHAP、説明可能性 | Level 1-4 |
| チューニングは慎重に（007） | Optuna、ハイパラ最適化 | Level 2-3 |
| 三連単の条件付き確率（insight） | Harville/Thurstone モデル | Level 2-5 |
| 馬券ポートフォリオ（008） | 相関行列、ポートフォリオ理論 | Level 4-3 |
| スマートマネー（007） | 時系列分析、オッズ変動モデル | Level 3 |
| 独立性仮定（009） | 自己相関、ラン検定、マルコフ連鎖 | Level 0-2 |
| 破産確率（008,009） | モンテカルロシミュレーション | Level 4-4 |
| 独自データ（012） | ディープラーニング（CNN, NLP） | Level 2-6 |
| Themis設計（011） | ソフトウェア設計、モジュール分離 | Level 5 |
| 競合戦略・規模の経済（012） | 市場分析、参入障壁の理解 | 考察マスター 4-1 |
| Zeus＝DB管理（011） | ETL、DWH、SQL | Level DE-2 |
| データはパワー（012） | データ品質管理、プロファイリング | Level DE-1 |
| バグで200万損失（011） | パイプライン監視、品質ゲート | Level DE-1, DE-3 |
| 運用ミスが最大のリスク（009） | 自動化、リトライ、アラート | Level DE-3 |

---

## タグ

`#モデル` `#特徴量` `#確率論` `#過学習` `#馬券戦略` `#バンクロール`

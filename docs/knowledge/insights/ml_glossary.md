# ML用語集（競馬AI開発向け）

[ML学習ロードマップ](ml_learning_roadmap.md)の補足として、競馬AI開発で頻出するML用語を定義・解説する。

> **凡例**
> - **競馬AI**: 競馬AI開発での位置づけ・注意点
> - **関連**: リンクするinsights・ロードマップ

---

## 1. エンコーディング

### ワンホットエンコーディング（One-Hot Encoding）

**定義**: カテゴリ値を、そのカテゴリに対応する次元だけが1、他が0のベクトルに変換する手法。Nカテゴリ → N次元（またはN-1次元で冗長性を除去）。

**例**: 馬場状態「良」→ [1,0,0]、馬場状態「稍重」→ [0,1,0]、馬場状態「重」→ [0,0,1]

**メリット**: カテゴリ間に順序を仮定しない。線形モデル・ニューラルネットで扱いやすい。

**デメリット**: カテゴリ数が多いと次元が爆発。騎手ID（100人以上）には不向き。

**競馬AI**: LightGBM/CatBoostはカテゴリをネイティブに扱えるため、必ずしも必要ない。scikit-learn系モデルを使う場合は必須。

---

### ラベルエンコーディング（Label Encoding）

**定義**: カテゴリを0, 1, 2, ... の連番に単純に割り当てる手法。

**例**: 競馬場「東京」→ 0、「京都」→ 1、「阪神」→ 2

**メリット**: 次元を増やさない。実装が簡単。

**デメリット**: 本来順序のないカテゴリに「距離」を導入してしまう。樹木モデルでは影響は小さいが、線形モデルでは歪んだ解釈になる。

**競馬AI**: 順序が意味を持つ変数（クラスG1>G2>...、枠番等）には適切。そうでない場合はTarget Encoding等を検討。

---

### ターゲットエンコーディング（Target Encoding）

**定義**: カテゴリ値を、そのカテゴリにおける目的変数の平均値（または確率）で置き換える手法。Mean Encodingとも呼ばれる。

**例**: 競馬場「東京」→ 東京で出走した馬の勝率0.12 に置換

**メリット**: 高次元カテゴリ（騎手ID、調教師ID等）でも1変数で表現できる。目的変数との関係を直接 encode する。

**注意（重要）**: 
- **データリークのリスク**が高い。学習データの値を使ってテストデータをエンコードするとリークになる。
- 学習時は**各foldで目的変数の平均を計算**する必要がある（sklearnの`TargetEncoder`や手動実装で対応）。
- 少数カテゴリでは過学習しやすい。**スムージング**（全体平均との加重平均）をかけることが多い。

**競馬AI**: human_vs_aiでは「第二層・AI/自動化に任せる」に分類。騎手・競馬場等のカテゴリで有効だが、005の過学習リスク（少数条件分け）に注意。サンプル数の少ない種牡馬×距離等の組み合わせでは危険。

---

### 頻度エンコーディング（Frequency Encoding）

**定義**: カテゴリを、そのカテゴリの出現頻度（または出現回数）で置き換える手法。

**例**: 騎手A（出走500回）→ 0.05、騎手B（出走50回）→ 0.005

**メリット**: データリークしない。高次元カテゴリでも1変数。

**デメリット**: 目的変数との関係を直接 encode していない。補助的な特徴量として使うことが多い。

---

### Embedding

**定義**: 高次元の離散値（カテゴリID、語彙など）を、より低次元の連続ベクトルに変換する表現。ニューラルネットの学習過程で獲得される。

**例**: 騎手ID 100人 → それぞれ10次元のベクトルにマッピング

**競馬AI**: ディープラーニング（TabNet、NLP等）で利用。表形式データでLightGBMを使う現状では優先度は低い。

---

## 2. 評価指標

### AUC-ROC（Area Under the ROC Curve）

**定義**: 二値分類モデルが、正例と負例をどれだけ正しく識別できるかを示す指標。0.5（ランダム）〜1.0（完璧）。ROC曲線下面積。

**解釈**: AUC 0.7 = 無作為に正例と負例を1つずつ取り出したとき、正例のスコアが高い確率70%。

**競馬AI**: 単純な「勝ち/負け」の識別性能評価に使用。ただし003で指摘の通り、馬券収益に直結するのは**キャリブレーション**であり、AUCが高くても較正が悪いとEV計算が狂う。

---

### ブライアスコア（Brier Score）

**定義**: 確率予測の精度を測る指標。`BS = (1/N) × Σ(予測確率 - 実際結果)²`。0が完璧、0.25がランダム予測相当。

**メリット**: 較正（キャリブレーション）の良さを直接反映。馬券のEV計算には較正が効くため、競馬AIではAUCより重視すべき。

**競馬AI**: モデル評価の第一指標として推奨。H-02（仮説検証）の成功基準にも使用。

---

### 対数損失（Log Loss / Cross-Entropy Loss）

**定義**: 確率予測と実際の0/1ラベルの乖離を測る損失。`-Σ[y·log(p) + (1-y)·log(1-p)]`。小さいほど良い。

**メリット**: 確率の「自信の度合い」も評価に含まれる。過信するとペナルティが大きい。

**競馬AI**: 学習時の目的関数として使用。ブライアスコアと同様、較正の良さに敏感。

---

### 混同行列（Confusion Matrix）

**定義**: 分類モデルの予測結果を、実際のクラス×予測クラスで集計した行列。TP, FP, TN, FN の4区分。

**競馬AI**: 的中率以外の評価軸（適合率・再現率・F1）の算出に使用。単純な的中率は003で「結果で判断するな」と戒められている。

---

### ECE（Expected Calibration Error）

**定義**: 予測確率の較正誤差を定量的に測る指標。予測確率をビン分けし、各ビン内の平均予測確率と実際の正解率の差を重み付きで集計。

**競馬AI**: キャリブレーションの定量的評価。H-02の成功基準（ECE < 0.05）に使用。

---

## 3. キャリブレーション（較正）

### キャリブレーション（Calibration）

**定義**: モデルが「30%と予測した馬が、実際に約30%の確率で勝つ」状態になること。確率出力の信頼性を保証する。

**較正が良い**: 予測30% → 実際の勝率≈30% → EV計算が正確。

**較正が悪い**: 予測30% → 実際15% → EVが過大評価 → 購入判断が狂う → 破産リスク。

**競馬AI**: 003の確率論的競馬観の根幹。EV計算の前提条件。ロードマップLevel 1の最重要トピック。

---

### Plattスケーリング（Platt Scaling）

**定義**: モデル出力をシグモイド関数で変換し、較正された確率を得る手法。`P(y=1) = 1 / (1 + exp(A·f + B))`。A, Bは検証データで fitting。

**競馬AI**: ブースティング系モデルの出力を較正する定番。実装はsklearnの`CalibratedClassifierCV`等で可能。

---

### Isotonic Regression（等張回帰）

**定義**: 単調増加の制約のもとで、予測確率と実際の正解率の関係を非線形に較正する手法。

**メリット**: Plattより柔軟。較正誤差が複雑な形状でも対応できる。

**デメリット**: データが少ないと過学習しやすい。

---

### Temperature Scaling

**定義**: ニューラルネットの最終層の出力を、温度パラメータTで割ってからsoftmaxする較正手法。`softmax(z/T)`。T>1で予測を「柔らかく」する。

**競馬AI**: ディープラーニングモデルで使用。LightGBM等の表形式モデルではPlatt/Isotonicが主。

---

## 4. 検証・交差検証

### 交差検証（Cross-Validation, CV）

**定義**: データを複数回に分けて学習・評価を繰り返し、汎化性能を推定する手法。

**競馬AIでの注意**: **ランダム分割はNG**。未来のデータで学習することになる（データリーク）。必ず**時系列分割**で実施。

---

### 時系列分割（Time Series Split）

**定義**: 時系列順にデータを分割し、過去で学習・未来で評価する方法。

**例**: 2018-2019年で学習 → 2020年でテスト / 2018-2020年で学習 → 2021年でテスト

**競馬AI**: 005の過学習防止の核心。Walk-Forward Validationと同義で使われることが多い。

---

### Walk-Forward Validation

**定義**: 時系列に沿って学習期間をスライドさせ、逐次的に将来を予測・検証する手法。リアルタイム運用に近い検証ができる。

**競馬AI**: 本番運用に最も近い検証。ロードマップで推奨。

---

### データリーク（Data Leakage）

**定義**: 学習時点では得られない情報（未来の情報・テストデータの情報）がモデルに入力に紛れ込むこと。

**典型例**: 
- テスト期間の平均でTarget Encoding
- 全期間の統計量で正規化
- レース結果を含む特徴量を「レース前」に使う

**競馬AI**: 致命的。EV計算が過大評価され、本番で大損する原因。特徴量設計のたびに確認すべき。

---

### ホールドアウト（Hold-out）

**定義**: データを学習用・検証用・テスト用に分け、テスト用を一切触らずに最後の評価にだけ使う手法。

**競馬AI**: Optuna等でハイパラ最適化する際、最適化用の検証データとは別に、完全に分離したホールドアウトを用意することで「最適化への過学習」を防ぐ。

---

## 5. 過学習・正則化

### 過学習（Overfitting）

**定義**: 学習データに過度に適合し、未知データに対する汎化性能が低下する状態。

**競馬AI**: 005の核心。種牡馬×距離×コースの細分化、少数サンプルでの高回収率条件探索が典型。松風ブログで繰り返し戒められている。

---

### 正則化（Regularization）

**定義**: モデルの複雑さにペナルティを課し、過学習を抑制する手法。

**種類**: 
- **L1正則化**: 係数の絶対値の和。スパース化（不要な特徴量を0に）を促す。
- **L2正則化**: 係数の二乗和。係数を全体的に小さくする。

**競馬AI**: LightGBMの`reg_alpha`（L1）、`reg_lambda`（L2）で制御。num_leaves増加時はこれらの値を上げて過学習を防ぐ（ml-experimentsの知見）。

---

### Early Stopping

**定義**: 学習を繰り返すうち、検証データでの性能が悪化し始めた時点で学習を打ち切る手法。

**競馬AI**: ブースティングの`n_estimators`が大きい場合、early stoppingで最適な反復数を自動決定。Optunaと組み合わせて使用。

---

## 6. アンサンブル

### バギング（Bagging）

**定義**: 複数のモデルを並列に学習し、予測を平均または多数決でまとめる手法。Bootstrap Aggregating。

**代表例**: RandomForest

---

### ブースティング（Boosting）

**定義**: 弱い学習器を逐次的に改善し、前のモデルの残差（誤差）を次のモデルで学習する手法。

**代表例**: LightGBM, XGBoost, CatBoost。競馬AIのデファクトスタンダード。

---

### スタッキング（Stacking）

**定義**: 複数のモデルの出力を、メタモデル（ブレンダー）の入力として学習する手法。

**注意**: 過学習しやすい。検証データでメタ特徴量を生成する等、リーク対策が必須。

---

## 7. LightGBM主要パラメータ

| パラメータ | 意味 | 競馬AIでの目安 |
|---|---|---|
| `learning_rate` | 各木の寄与度。小さいほど慎重 | 0.01〜0.05 |
| `num_leaves` | 1本の木の葉の最大数。大きいほど表現力↑ | 31〜127（過学習に注意） |
| `min_child_samples` | 葉の最小サンプル数。大きいほど過学習抑制 | 20〜100 |
| `reg_alpha` / `reg_lambda` | L1/L2正則化 | num_leaves増加時に上げる |
| `subsample` | 行のサンプリング率 | 0.7〜0.9 |
| `colsample_bytree` / `feature_fraction` | 列のサンプリング率 | 特徴量増加時は0.8程度に |
| `n_estimators` | 木の本数 | 1000〜5000 + early stopping |

**関連**: ml-experimentsのハイパラ知見

---

## 8. 馬券・確率論

### EV（Expected Value / 期待値）

**定義**: 馬券の期待値。`EV = P(的中) × オッズ`。EV > 1.0 なら長期的にプラス。

**競馬AI**: 006の核心。「EV>1.0を全部買え」。購入判断の基本単位。

---

### ケリー基準（Kelly Criterion）

**定義**: 最適な賭け金割合を数学的に導く公式。`f* = (p×b - q) / b`（p=勝率, q=1-p, b=オッズ-1）。

**競馬AI**: フルケリーは変動が激しい。ハーフケリー・クォーターケリー（safety_factor）が実務では推奨。H-05で最適safety_factorを検証。

---

### 破産確率（Risk of Ruin）

**定義**: バンクロールが閾値（例: 初期の10%）を下回る確率。

**競馬AI**: モンテカルロシミュレーションで推定。H-04（追い下げ vs 固定額）、H-05（safety_factor）の評価に使用。

---

### シャープレシオ（Sharpe Ratio）

**定義**: リスク調整後のリターン指標。`(期待リターン - 無リスク利子率) / 標準偏差`。

**競馬AI**: ポートフォリオ理論（008）で、馬券種間の組み合わせ最適化に使用。

---

## 9. その他

### predict_proba

**定義**: 分類モデルが各クラスに属する確率を出力するメソッド。

**競馬AI**: 確率推定の本命。`predict`（クラスラベル）ではなく`predict_proba`を使い、EV計算に確率を渡す。

---

### 特徴量重要度（Feature Importance）

**定義**: 各特徴量が予測にどれだけ寄与したかを示す指標。勾配ブースティングでは gain / split / permutation などの算出方法がある。

**競馬AI**: どの情報が効いているかの解釈、過学習の検出（重要だが本番で使わない特徴量が上位＝リーク疑い）に使用。

---

### 多重共線性（Multicollinearity）

**定義**: 複数の特徴量が強く相関しており、モデルがそれらを分離して解釈しづらい状態。

**競馬AI**: 相関の高い特徴量の片方を削除する等で対応。解釈性・安定性の向上。

---

## インデックス（五十音順）

| 用語 | セクション |
|---|---|
| AUC-ROC | 2. 評価指標 |
| Early Stopping | 5. 過学習・正則化 |
| ECE | 2. 評価指標 |
| Embedding | 1. エンコーディング |
| EV | 8. 馬券・確率論 |
| Isotonic Regression | 3. キャリブレーション |
| Plattスケーリング | 3. キャリブレーション |
| Temperature Scaling | 3. キャリブレーション |
| Walk-Forward Validation | 4. 検証 |
| ブライアスコア | 2. 評価指標 |
| キャリブレーション | 3. キャリブレーション |
| グリッドサーチ | （Optunaに置換推奨） |
| 交差検証 | 4. 検証 |
| シャープレシオ | 8. 馬券・確率論 |
| データリーク | 4. 検証 |
| ターゲットエンコーディング | 1. エンコーディング |
| 多重共線性 | 9. その他 |
| 対数損失 | 2. 評価指標 |
| 破産確率 | 8. 馬券・確率論 |
| ブースティング | 6. アンサンブル |
| バギング | 6. アンサンブル |
| ホールドアウト | 4. 検証 |
| プラットスケーリング | 3. キャリブレーション |
| ワンホットエンコーディング | 1. エンコーディング |
| ラベルエンコーディング | 1. エンコーディング |
| ランダムフォレスト | 6. アンサンブル（バギング） |
| 正則化 | 5. 過学習・正則化 |
| ロジスティック回帰 | （Level 0） |
| 混同行列 | 2. 評価指標 |
| 頻度エンコーディング | 1. エンコーディング |
| 特徴量重要度 | 9. その他 |
| 過学習 | 5. 過学習・正則化 |
| 較正 | 3. キャリブレーション |
| 時系列分割 | 4. 検証 |
| ケリー基準 | 8. 馬券・確率論 |
| スタッキング | 6. アンサンブル |
| predict_proba | 9. その他 |

---

## タグ

`#モデル` `#特徴量` `#確率論` `#過学習` `#用語集`

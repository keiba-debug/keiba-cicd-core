# ML用語集（競馬AI開発向け）

[ML学習ロードマップ](ml_learning_roadmap.md)の補足として、競馬AI開発で頻出するML用語を定義・解説する。

> **凡例**
> - **競馬AI**: 競馬AI開発での位置づけ・注意点
> - **関連**: リンクするinsights・ロードマップ
>
> 最終更新: 2026-02-12

---

## 0. データ分析の基礎

### 記述統計（Descriptive Statistics）

**定義**: データの特徴を要約する統計量の総称。代表値（平均、中央値、最頻値）と散布度（標準偏差、分散、IQR、範囲）に大別される。

**競馬AI**: 全ての分析の出発点。各特徴量の `describe()` で分布・欠損・外れ値の概観を把握してからモデリングに進む。オッズや走破タイムの分布形状を知らずに前処理はできない。

---

### 探索的データ分析（EDA: Exploratory Data Analysis）

**定義**: データの構造・パターン・異常を可視化や集計で探索するアプローチ。仮説を事前に固定せず、データに「語らせる」姿勢が特徴。Tukey (1977) が提唱。

**競馬AI**: モデル構築前のEDA、特徴量設計中の探索、モデル評価後の診断、運用中のモニタリングと、全フェーズで継続的に行う。ロードマップ Level 0-1。

---

### クロス集計（Cross Tabulation）

**定義**: 2つ以上のカテゴリ変数の組合せごとに度数や平均値を集計する手法。ピボットテーブルとも呼ばれる。

**例**: 芝/ダート × 脚質（逃げ/先行/差し/追込）の勝率テーブル。

**競馬AI**: 特徴量設計の初期仮説を生成する手段として有効。ただし、セルが細かくなるほどサンプル数が減り、偶然の偏りを「発見」しやすい。blog-005の過学習教訓と直結。「仮説の生成」に使い、「仮説の検証」は別データ・別手法で行うこと。

---

### 効果量（Effect Size）

**定義**: 差や関連の「大きさ」を示す指標。代表例はCohen's d（2群の平均差を標準偏差で割ったもの）。p値とは独立した概念。

**解釈目安**: d = 0.2（小）、0.5（中）、0.8（大）

**競馬AI**: 競馬データはサンプルが大きいので、わずかな差でもp < 0.05は簡単に出る。効果量を見て「統計的に有意だが、実務的に意味のある差か？」を判断する。

---

### ブートストラップ（Bootstrap）

**定義**: 手元のデータから復元抽出で繰り返しリサンプリングし、統計量の分布（信頼区間等）を推定するノンパラメトリック手法。分布の前提を置かなくてよい。

**競馬AI**: 回収率やEVの信頼区間推定に使用。「回収率114%の95%信頼区間は [102%, 126%]」のように結果の不確実性を定量化できる。競馬データは正規分布に従わないことが多いため、t検定の信頼区間よりブートストラップの方が堅牢。

---

### 並べ替え検定（Permutation Test）

**定義**: ラベル（例: 購入/非購入）をランダムに入れ替えて統計量の帰無分布を生成し、観測値がどれだけ極端かを評価するノンパラメトリック検定。

**競馬AI**: 分布の前提を置かないため、t検定が怪しい場面で使える。「このモデルの回収率は本当にランダムより良いか」の検証に有効。

---

### 多重検定補正（Multiple Testing Correction）

**定義**: 多数の検定を同時に行うと、偶然有意になる確率（家族内エラー率）が上がる問題への対処法。

**代表手法**:
- **Bonferroni補正**: 有意水準αを検定数Nで割る（α/N）。保守的だが単純。
- **Benjamini-Hochberg法（FDR制御）**: 偽発見率を制御。Bonferroniより緩やかで実用的。

**競馬AI**: blog-012の「サイコロ100個」の比喩そのもの。馬券種別・条件別に多数の収支を評価すると、ランダムでも一部は好成績に見える。多重検定補正なしに「ワイドが悪い」「東京の芝が良い」と結論するのは危険。

---

### ABC分析 / パレート分析

**定義**: 項目を重要度（売上・利益等）の降順に並べ、累積寄与率でA（上位70%）/ B（70-90%）/ C（90-100%）にランク分けする手法。パレートの法則（80:20の法則）に基づく。

**競馬AI**: 限定的だが運用の意思決定に使える。特徴量重要度の上位20%が予測精度の80%を説明する場合、残りは削減候補。レース種別ごとの利益貢献度の偏りの把握にも。ただしこのプロジェクトでは概念として知っていれば十分で、深く学ぶ対象ではない。

---

## 1. エンコーディング

### ワンホットエンコーディング（One-Hot Encoding）

**定義**: カテゴリ値を、そのカテゴリに対応する次元だけが1、他が0のベクトルに変換する手法。Nカテゴリ → N次元（またはN-1次元で冗長性を除去）。

**例**: 馬場状態「良」→ [1,0,0]、馬場状態「稍重」→ [0,1,0]、馬場状態「重」→ [0,0,1]

**メリット**: カテゴリ間に順序を仮定しない。線形モデル・ニューラルネットで扱いやすい。

**デメリット**: カテゴリ数が多いと次元が爆発。騎手ID（100人以上）には不向き。

**競馬AI**: LightGBM/CatBoostはカテゴリをネイティブに扱えるため、必ずしも必要ない。scikit-learn系モデルを使う場合は必須。

---

### ラベルエンコーディング（Label Encoding）

**定義**: カテゴリを0, 1, 2, ... の連番に単純に割り当てる手法。

**例**: 競馬場「東京」→ 0、「京都」→ 1、「阪神」→ 2

**メリット**: 次元を増やさない。実装が簡単。

**デメリット**: 本来順序のないカテゴリに「距離」を導入してしまう。樹木モデルでは影響は小さいが、線形モデルでは歪んだ解釈になる。

**競馬AI**: 順序が意味を持つ変数（クラスG1>G2>...、枠番等）には適切。そうでない場合はTarget Encoding等を検討。

---

### ターゲットエンコーディング（Target Encoding）

**定義**: カテゴリ値を、そのカテゴリにおける目的変数の平均値（または確率）で置き換える手法。Mean Encodingとも呼ばれる。

**例**: 競馬場「東京」→ 東京で出走した馬の勝率0.12 に置換

**メリット**: 高次元カテゴリ（騎手ID、調教師ID等）でも1変数で表現できる。目的変数との関係を直接 encode する。

**注意（重要）**: 
- **データリークのリスク**が高い。学習データの値を使ってテストデータをエンコードするとリークになる。
- 学習時は**各foldで目的変数の平均を計算**する必要がある（sklearnの`TargetEncoder`や手動実装で対応）。
- 少数カテゴリでは過学習しやすい。**スムージング**（全体平均との加重平均）をかけることが多い。

**競馬AI**: human_vs_aiでは「第二層・AI/自動化に任せる」に分類。騎手・競馬場等のカテゴリで有効だが、005の過学習リスク（少数条件分け）に注意。サンプル数の少ない種牡馬×距離等の組み合わせでは危険。

---

### 頻度エンコーディング（Frequency Encoding）

**定義**: カテゴリを、そのカテゴリの出現頻度（または出現回数）で置き換える手法。

**例**: 騎手A（出走500回）→ 0.05、騎手B（出走50回）→ 0.005

**メリット**: データリークしない。高次元カテゴリでも1変数。

**デメリット**: 目的変数との関係を直接 encode していない。補助的な特徴量として使うことが多い。

---

### Embedding

**定義**: 高次元の離散値（カテゴリID、語彙など）を、より低次元の連続ベクトルに変換する表現。ニューラルネットの学習過程で獲得される。

**例**: 騎手ID 100人 → それぞれ10次元のベクトルにマッピング

**競馬AI**: ディープラーニング（TabNet、NLP等）で利用。表形式データでLightGBMを使う現状では優先度は低い。

---

## 2. 評価指標

### AUC-ROC（Area Under the ROC Curve）

**定義**: 二値分類モデルが、正例と負例をどれだけ正しく識別できるかを示す指標。0.5（ランダム）〜1.0（完璧）。ROC曲線下面積。

**解釈**: AUC 0.7 = 無作為に正例と負例を1つずつ取り出したとき、正例のスコアが高い確率70%。

**競馬AI**: 単純な「勝ち/負け」の識別性能評価に使用。ただし003で指摘の通り、馬券収益に直結するのは**キャリブレーション**であり、AUCが高くても較正が悪いとEV計算が狂う。

---

### ブライアスコア（Brier Score）

**定義**: 確率予測の精度を測る指標。`BS = (1/N) × Σ(予測確率 - 実際結果)²`。0が完璧、0.25がランダム予測相当。

**メリット**: 較正（キャリブレーション）の良さを直接反映。馬券のEV計算には較正が効くため、競馬AIではAUCより重視すべき。

**競馬AI**: モデル評価の第一指標として推奨。H-02（仮説検証）の成功基準にも使用。

---

### 対数損失（Log Loss / Cross-Entropy Loss）

**定義**: 確率予測と実際の0/1ラベルの乖離を測る損失。`-Σ[y·log(p) + (1-y)·log(1-p)]`。小さいほど良い。

**メリット**: 確率の「自信の度合い」も評価に含まれる。過信するとペナルティが大きい。

**競馬AI**: 学習時の目的関数として使用。ブライアスコアと同様、較正の良さに敏感。

---

### 混同行列（Confusion Matrix）

**定義**: 分類モデルの予測結果を、実際のクラス×予測クラスで集計した行列。TP, FP, TN, FN の4区分。

**競馬AI**: 的中率以外の評価軸（適合率・再現率・F1）の算出に使用。単純な的中率は003で「結果で判断するな」と戒められている。

---

### ECE（Expected Calibration Error）

**定義**: 予測確率の較正誤差を定量的に測る指標。予測確率をビン分けし、各ビン内の平均予測確率と実際の正解率の差を重み付きで集計。

**競馬AI**: キャリブレーションの定量的評価。H-02の成功基準（ECE < 0.05）に使用。

---

## 3. 説明可能性（Explainability）

### SHAP（SHapley Additive exPlanations）

**定義**: ゲーム理論のShapley値をベースに、各特徴量が個別の予測にどれだけ寄与したかを定量的に示す手法。正の寄与（確率を押し上げ）と負の寄与（押し下げ）を分離して示せる。

**主要な可視化**:
- **Summary Plot**: 全特徴量の重要度と影響方向を一覧
- **Force Plot**: 個別予測の分解（ベース値→予測値への寄与の積み上げ）
- **Dependence Plot**: 特徴量値とSHAP値の関係（交互作用の発見にも有効）

**競馬AI**: 馬ごとに「なぜ高確率か」を分解する基盤。prediction_interview_featureの技術的背景。また、重要度上位に「本番では使えない情報」があればデータリークの疑い。

**関連**: [予測根拠のインタビュー機能](prediction_interview_feature.md), ロードマップ Level 1-4

---

### Partial Dependence Plot（PDP）

**定義**: 1つ（または2つ）の特徴量と予測値の平均的な関係を、他の特徴量を周辺化して可視化する手法。

**例**: 馬体重増減（-10kg〜+10kg）と予測勝率の関係を曲線で表示。

**競馬AI**: 「馬体重が増えると勝率が上がる/下がる」等の非線形関係を発見。SHAP Dependence Plotと組み合わせると、交互作用も見える。

---

### Permutation Importance

**定義**: 特徴量の値をシャッフルしたときにモデル性能がどれだけ低下するかで重要度を測る手法。モデルに依存しない（model-agnostic）。

**競馬AI**: LightGBMのgain-based importanceとは違う視点。実際の予測精度への寄与を直接測るので、過学習した特徴量を発見しやすい。

---

## 4. キャリブレーション（較正）

### キャリブレーション（Calibration）

**定義**: モデルが「30%と予測した馬が、実際に約30%の確率で勝つ」状態になること。確率出力の信頼性を保証する。

**較正が良い**: 予測30% → 実際の勝率≈30% → EV計算が正確。

**較正が悪い**: 予測30% → 実際15% → EVが過大評価 → 購入判断が狂う → 破産リスク。

**競馬AI**: 003の確率論的競馬観の根幹。EV計算の前提条件。ロードマップLevel 1の最重要トピック。

---

### Plattスケーリング（Platt Scaling）

**定義**: モデル出力をシグモイド関数で変換し、較正された確率を得る手法。`P(y=1) = 1 / (1 + exp(A·f + B))`。A, Bは検証データで fitting。

**競馬AI**: ブースティング系モデルの出力を較正する定番。実装はsklearnの`CalibratedClassifierCV`等で可能。

---

### Isotonic Regression（等張回帰）

**定義**: 単調増加の制約のもとで、予測確率と実際の正解率の関係を非線形に較正する手法。

**メリット**: Plattより柔軟。較正誤差が複雑な形状でも対応できる。

**デメリット**: データが少ないと過学習しやすい。

---

### Temperature Scaling

**定義**: ニューラルネットの最終層の出力を、温度パラメータTで割ってからsoftmaxする較正手法。`softmax(z/T)`。T>1で予測を「柔らかく」する。

**競馬AI**: ディープラーニングモデルで使用。LightGBM等の表形式モデルではPlatt/Isotonicが主。

---

## 5. 検証・交差検証

### 交差検証（Cross-Validation, CV）

**定義**: データを複数回に分けて学習・評価を繰り返し、汎化性能を推定する手法。

**競馬AIでの注意**: **ランダム分割はNG**。未来のデータで学習することになる（データリーク）。必ず**時系列分割**で実施。

---

### 時系列分割（Time Series Split）

**定義**: 時系列順にデータを分割し、過去で学習・未来で評価する方法。

**例**: 2018-2019年で学習 → 2020年でテスト / 2018-2020年で学習 → 2021年でテスト

**競馬AI**: 005の過学習防止の核心。Walk-Forward Validationと同義で使われることが多い。

---

### Walk-Forward Validation

**定義**: 時系列に沿って学習期間をスライドさせ、逐次的に将来を予測・検証する手法。リアルタイム運用に近い検証ができる。

**競馬AI**: 本番運用に最も近い検証。ロードマップで推奨。

---

### データリーク（Data Leakage）

**定義**: 学習時点では得られない情報（未来の情報・テストデータの情報）がモデルに入力に紛れ込むこと。

**典型例**: 
- テスト期間の平均でTarget Encoding
- 全期間の統計量で正規化
- レース結果を含む特徴量を「レース前」に使う

**競馬AI**: 致命的。EV計算が過大評価され、本番で大損する原因。特徴量設計のたびに確認すべき。

---

### ホールドアウト（Hold-out）

**定義**: データを学習用・検証用・テスト用に分け、テスト用を一切触らずに最後の評価にだけ使う手法。

**競馬AI**: Optuna等でハイパラ最適化する際、最適化用の検証データとは別に、完全に分離したホールドアウトを用意することで「最適化への過学習」を防ぐ。

---

## 6. 過学習・正則化

### 過学習（Overfitting）

**定義**: 学習データに過度に適合し、未知データに対する汎化性能が低下する状態。

**競馬AI**: 005の核心。種牡馬×距離×コースの細分化、少数サンプルでの高回収率条件探索が典型。松風ブログで繰り返し戒められている。

---

### 正則化（Regularization）

**定義**: モデルの複雑さにペナルティを課し、過学習を抑制する手法。

**種類**: 
- **L1正則化**: 係数の絶対値の和。スパース化（不要な特徴量を0に）を促す。
- **L2正則化**: 係数の二乗和。係数を全体的に小さくする。

**競馬AI**: LightGBMの`reg_alpha`（L1）、`reg_lambda`（L2）で制御。num_leaves増加時はこれらの値を上げて過学習を防ぐ（ml-experimentsの知見）。

---

### Early Stopping

**定義**: 学習を繰り返すうち、検証データでの性能が悪化し始めた時点で学習を打ち切る手法。

**競馬AI**: ブースティングの`n_estimators`が大きい場合、early stoppingで最適な反復数を自動決定。Optunaと組み合わせて使用。

---

## 7. アンサンブル

### バギング（Bagging）

**定義**: 複数のモデルを並列に学習し、予測を平均または多数決でまとめる手法。Bootstrap Aggregating。

**代表例**: RandomForest

---

### ブースティング（Boosting）

**定義**: 弱い学習器を逐次的に改善し、前のモデルの残差（誤差）を次のモデルで学習する手法。

**代表例**: LightGBM, XGBoost, CatBoost。競馬AIのデファクトスタンダード。

---

### スタッキング（Stacking）

**定義**: 複数のモデルの出力を、メタモデル（ブレンダー）の入力として学習する手法。

**注意**: 過学習しやすい。検証データでメタ特徴量を生成する等、リーク対策が必須。

---

## 8. ハイパーパラメータ最適化

### Optuna

**定義**: Pythonのハイパーパラメータ最適化フレームワーク。TPE（Tree-structured Parzen Estimator）ベースのベイズ最適化を行い、過去の試行結果から次に試すべきパラメータを効率的に選択する。

**主要機能**:
- **suggest API**: `trial.suggest_float()`, `trial.suggest_int()` 等で探索空間を定義
- **Pruning（枝刈り）**: 有望でない試行を学習途中で打ち切り、計算コストを削減
- **可視化**: `optuna.visualization` でパラメータ重要度、最適化履歴を可視化

**競馬AI**: LightGBMのパラメータ最適化に使用。ただし「最適化への過学習」に注意。最適化用CVとは別のホールドアウトで最終評価すること。

**関連**: ロードマップ Level 2-3

---

### グリッドサーチ（Grid Search）

**定義**: 指定したパラメータの全組合せを網羅的に探索する手法。

**競馬AI**: パラメータ数が少ない場合のみ実用的。Optunaに置き換え推奨。

---

## 9. LightGBM主要パラメータ

| パラメータ | 意味 | 競馬AIでの目安 |
|---|---|---|
| `learning_rate` | 各木の寄与度。小さいほど慎重 | 0.01〜0.05 |
| `num_leaves` | 1本の木の葉の最大数。大きいほど表現力↑ | 31〜127（過学習に注意） |
| `min_child_samples` | 葉の最小サンプル数。大きいほど過学習抑制 | 20〜100 |
| `reg_alpha` / `reg_lambda` | L1/L2正則化 | num_leaves増加時に上げる |
| `subsample` | 行のサンプリング率 | 0.7〜0.9 |
| `colsample_bytree` / `feature_fraction` | 列のサンプリング率 | 特徴量増加時は0.8程度に |
| `n_estimators` | 木の本数 | 1000〜5000 + early stopping |

**関連**: ml-experimentsのハイパラ知見

---

## 10. 馬券・確率論

### EV（Expected Value / 期待値）

**定義**: 馬券の期待値。`EV = P(的中) × オッズ`。EV > 1.0 なら長期的にプラス。

**競馬AI**: 006の核心。「EV>1.0を全部買え」。購入判断の基本単位。

---

### ケリー基準（Kelly Criterion）

**定義**: 最適な賭け金割合を数学的に導く公式。`f* = (p×b - q) / b`（p=勝率, q=1-p, b=オッズ-1）。

**競馬AI**: フルケリーは変動が激しい。ハーフケリー・クォーターケリー（safety_factor）が実務では推奨。H-05で最適safety_factorを検証。

---

### 破産確率（Risk of Ruin）

**定義**: バンクロールが閾値（例: 初期の10%）を下回る確率。

**競馬AI**: モンテカルロシミュレーションで推定。H-04（追い下げ vs 固定額）、H-05（safety_factor）の評価に使用。

---

### シャープレシオ（Sharpe Ratio）

**定義**: リスク調整後のリターン指標。`(期待リターン - 無リスク利子率) / 標準偏差`。

**競馬AI**: ポートフォリオ理論（008）で、馬券種間の組み合わせ最適化に使用。

---

### ドローダウン（Drawdown）

**定義**: バンクロールが過去最高値からどれだけ減少したかを示す指標。最大ドローダウン（Maximum Drawdown）は期間中の最大減少幅。

**競馬AI**: 破産リスクの事前評価に使用。モンテカルロシミュレーションでドローダウン分布を把握し、safety_factorの設計に反映。007の「耐える期間」の定量的評価。

---

### モンテカルロシミュレーション（Monte Carlo Simulation）

**定義**: 乱数を用いて大量の仮想シナリオを生成し、結果の分布を統計的に推定する手法。

**手順**: 1) モデルの的中率・回収率分布を推定 → 2) N年分の仮想レースを生成 → 3) バンクロール推移をシミュレーション → 4) 破産確率・ドローダウン分布を算出 → 5) 10万回以上繰り返して信頼性確保。

**競馬AI**: H-04（追い下げvs固定額）、H-05（最適safety_factor）の評価に使用。ロードマップ Level 4-4。

---

### Favorite-Longshot Bias（FLB）

**定義**: 馬券市場において、人気馬（Favorite）のオッズが相対的に適正に近く、不人気馬（Longshot）のオッズが過大に高く設定される傾向。言い換えると、人気薄の馬は買われすぎ（期待値が低い）。

**競馬AI**: 市場の構造的非効率性の代表例。AIがFLBを正しく認識すれば、人気馬の過小評価を突ける場合がある。ただし単純な「人気馬を買う」戦略ではなく、確率推定の精度でFLBを超えるのが本来のアプローチ。

**関連**: [馬券市場の構造的非効率性](market_structural_inefficiencies.md)

---

### IIA（Independence of Irrelevant Alternatives）

**定義**: 「無関係な選択肢からの独立性」。ある選択肢が除外されたとき、残りの選択肢間の確率比率が変わらないという仮定。Harvilleモデルの前提。

**例**: A馬が出走取消になったとき、B馬とC馬の勝率比はA馬がいたときと同じ（IIA仮定）。実際には、A馬と脚質が似たB馬の方がより恩恵を受ける可能性があり、IIAは破れやすい。

**競馬AI**: IIA違反はHarvilleモデルの組合せ確率計算に歪みを生む。Thurstone/Heneryモデルでの緩和が課題。

**関連**: [HarvilleのIIA批判](harville_iia_critique.md), ロードマップ Level 2-5

---

### Harville モデル

**定義**: 単勝確率から複勝・馬連・三連単等の組合せ確率を導く数理モデル。`P(A→B) = P(A) × P(B) / (1 - P(A))`。

**競馬AI**: 組合せ馬券のEV計算の基盤。IIA仮定の限界を認識しつつ、まずHarvilleで構築し、段階的にHenery/Thurstoneへ改善するアプローチが推奨。

**関連**: [組合せ馬券の確率計算](combination_ticket_probability.md), ロードマップ Level 2-5

---

## 11. ランキング・順序学習

### ランキング学習（Learning to Rank）

**定義**: アイテム（馬）の順位関係を直接最適化する機械学習の一分野。Pointwise / Pairwise / Listwise の3アプローチがある。

**代表手法**: LambdaRank, LambdaMART（LightGBMの`lambdarank`目的関数）, RankNet, ListNet。

**競馬AI**: 「確率推定→EV計算」がメインだが、三連単等で着順関係の精度が必要な場面で補完的に使える。

**関連**: ロードマップ Level 2-4

---

## 12. データエンジニアリング

### ETL（Extract, Transform, Load）

**定義**: データを「抽出（Extract）→変換（Transform）→格納（Load）」する一連のプロセス。データソースからデータを取り出し、分析に適した形に加工し、データベースやデータウェアハウスに投入する。

**競馬AI**: JRA-VAN の固定長テキスト / 競馬ブックのHTML → パース → integrated JSON → SQL Server という流れが ETL に相当。現状は JSON までで止まっている。

**関連**: [データエンジニアリング実践ロードマップ](data_engineering_roadmap.md) Phase 3, ロードマップ Level DE-2

---

### データウェアハウス（DWH: Data Warehouse）

**定義**: 分析を目的として構造化・統合されたデータの格納庫。業務データベース（OLTP）とは別に、時系列分析や集約クエリに最適化された設計（スター/スノーフレークスキーマ）で構築する。

**競馬AI**: SQL Server に既存のスキーマ定義あり。稼働すれば「過去N走の集約」「条件別勝率のクロス集計」等のSQLクエリで分析が高速化する。

---

### データプロファイリング（Data Profiling）

**定義**: データの統計的特性（分布・欠損率・外れ値・型・カーディナリティ等）を自動的に収集・可視化する工程。データの「健康診断」。

**ツール例**: ydata-profiling（旧 pandas-profiling）。1行で包括的なレポートを生成できる。

**競馬AI**: 出馬表・成績・調教・オッズの各テーブルで定期的にプロファイリングを行い、品質の推移を追跡する。Level DE-1 の出発点。

---

### スキーマ検証（Schema Validation）

**定義**: データが期待する構造（型・必須フィールド・値の範囲等）に適合しているかを自動チェックすること。

**ツール例**: pydantic（Pythonオブジェクトの型検証）、pandera（DataFrame のスキーマ検証）、Great Expectations（宣言的なデータ検証フレームワーク）。

**競馬AI**: integrated JSON にスキーマ定義を適用し、フォーマット変更やパーサーの不具合を自動検出する。品質ゲートの核。

---

### オーケストレーション（Orchestration）

**定義**: 複数のタスク（データ収集→品質チェック→DB投入→特徴量計算等）の実行順序・依存関係・スケジュール・エラーハンドリングを一元管理する仕組み。

**ツール例**: Prefect（Python ネイティブ、軽量）、Apache Airflow（大規模向け、DAG定義）。

**競馬AI**: 現状は daily/weekly スクリプトの手動実行。パイプライン全体を Prefect 等で自動化し、失敗時のリトライ・アラートを実現する。Level DE-3。

---

### データ鮮度（Data Freshness）

**定義**: データが「いつ時点のものか」「期待通りの頻度で更新されているか」を示す品質指標。

**競馬AI**: 「今日のレースデータがまだ取り込まれていない」「調教データの更新が3日止まっている」等の検知に使用。品質KPIの一つ。

---

### データ品質の4軸

**定義**: データ品質を評価する4つの基本指標。
- **完全性（Completeness）**: 必要なデータが欠損なく揃っているか
- **正確性（Accuracy）**: データの値が正しいか
- **一貫性（Consistency）**: 複数テーブル間・時点間で矛盾がないか
- **鮮度（Timeliness）**: データが十分に新しいか

**競馬AI**: 「出走頭数と実際のレコード数が合わない」（一貫性）、「馬体重が0kg」（正確性）、「先週の調教データが欠けている」（完全性）等。品質ゲートで4軸すべてをチェックする。

---

### パイプライン（Data Pipeline）

**定義**: データが収集されてから分析・予測に使われるまでの一連の処理フロー。各ステップが前のステップの出力を入力として受け取る。

**競馬AI**: `Web → fast_batch_cli → Parsers → integrated JSON → [品質チェック] → SQL Server → 特徴量計算 → モデル` というフロー全体がパイプライン。現状は途中で断絶がある。

---

## 13. その他

### predict_proba

**定義**: 分類モデルが各クラスに属する確率を出力するメソッド。

**競馬AI**: 確率推定の本命。`predict`（クラスラベル）ではなく`predict_proba`を使い、EV計算に確率を渡す。

---

### 特徴量重要度（Feature Importance）

**定義**: 各特徴量が予測にどれだけ寄与したかを示す指標。勾配ブースティングでは gain / split / permutation などの算出方法がある。

**競馬AI**: どの情報が効いているかの解釈、過学習の検出（重要だが本番で使わない特徴量が上位＝リーク疑い）に使用。

---

### 多重共線性（Multicollinearity）

**定義**: 複数の特徴量が強く相関しており、モデルがそれらを分離して解釈しづらい状態。

**競馬AI**: 相関の高い特徴量の片方を削除する等で対応。解釈性・安定性の向上。

---

## インデックス（五十音順）

| 用語 | セクション |
|---|---|
| ABC分析 / パレート分析 | 0. データ分析の基礎 |
| AUC-ROC | 2. 評価指標 |
| Early Stopping | 6. 過学習・正則化 |
| ECE | 2. 評価指標 |
| EDA（探索的データ分析） | 0. データ分析の基礎 |
| Embedding | 1. エンコーディング |
| ETL | 12. データエンジニアリング |
| EV | 10. 馬券・確率論 |
| Favorite-Longshot Bias (FLB) | 10. 馬券・確率論 |
| Harville モデル | 10. 馬券・確率論 |
| IIA | 10. 馬券・確率論 |
| Isotonic Regression | 4. キャリブレーション |
| Optuna | 8. ハイパーパラメータ最適化 |
| Partial Dependence Plot (PDP) | 3. 説明可能性 |
| Permutation Importance | 3. 説明可能性 |
| Plattスケーリング | 4. キャリブレーション |
| predict_proba | 13. その他 |
| SHAP | 3. 説明可能性 |
| Temperature Scaling | 4. キャリブレーション |
| Walk-Forward Validation | 5. 検証 |
| オーケストレーション | 12. データエンジニアリング |
| キャリブレーション | 4. キャリブレーション |
| 記述統計 | 0. データ分析の基礎 |
| クロス集計 | 0. データ分析の基礎 |
| グリッドサーチ | 8. ハイパーパラメータ最適化 |
| 効果量 | 0. データ分析の基礎 |
| ケリー基準 | 10. 馬券・確率論 |
| 交差検証 | 5. 検証 |
| 混同行列 | 2. 評価指標 |
| 較正 | 4. キャリブレーション |
| 過学習 | 6. 過学習・正則化 |
| スキーマ検証 | 12. データエンジニアリング |
| シャープレシオ | 10. 馬券・確率論 |
| スタッキング | 7. アンサンブル |
| 正則化 | 6. 過学習・正則化 |
| 対数損失 | 2. 評価指標 |
| ターゲットエンコーディング | 1. エンコーディング |
| 多重共線性 | 13. その他 |
| 多重検定補正 | 0. データ分析の基礎 |
| 時系列分割 | 5. 検証 |
| データウェアハウス (DWH) | 12. データエンジニアリング |
| データ鮮度 | 12. データエンジニアリング |
| データ品質の4軸 | 12. データエンジニアリング |
| データプロファイリング | 12. データエンジニアリング |
| データリーク | 5. 検証 |
| ドローダウン | 10. 馬券・確率論 |
| 特徴量重要度 | 13. その他 |
| 並べ替え検定 | 0. データ分析の基礎 |
| パイプライン | 12. データエンジニアリング |
| バギング | 7. アンサンブル |
| 破産確率 | 10. 馬券・確率論 |
| ブートストラップ | 0. データ分析の基礎 |
| ブースティング | 7. アンサンブル |
| ブライアスコア | 2. 評価指標 |
| プラットスケーリング | 4. キャリブレーション |
| ホールドアウト | 5. 検証 |
| モンテカルロシミュレーション | 10. 馬券・確率論 |
| ラベルエンコーディング | 1. エンコーディング |
| ランキング学習 | 11. ランキング・順序学習 |
| ランダムフォレスト | 7. アンサンブル（バギング） |
| ロジスティック回帰 | （Level 0） |
| ワンホットエンコーディング | 1. エンコーディング |
| 頻度エンコーディング | 1. エンコーディング |

---

## タグ

`#モデル` `#特徴量` `#確率論` `#過学習` `#用語集`

# 特徴量設計とハイパーパラメータ: 人間の仕事か、AIの仕事か

> 起点: モデル設計において「特徴量の作成」と「ハイパーパラメータの設定」は人間の腕の見せ所なのか？それともAIに任せるべきなのか？

---

## 問題の構造化

競馬AIのモデル構築を工程に分解すると、各工程で「人間がやるべきか」「AIに任せるべきか」の判断が異なる。

```
工程1: 何のデータを集めるか        ← ?
工程2: どんな特徴量を作るか        ← ?
工程3: 特徴量の変換・エンコーディング ← ?
工程4: アルゴリズムの選択           ← ?
工程5: ハイパーパラメータの調整      ← ?
工程6: 評価指標・検証方法の設計     ← ?
工程7: 結果の解釈と次の仮説立案     ← ?
```

先に結論を述べる:

```
工程1: 何のデータを集めるか        ← 人間（これこそ腕の見せ所）
工程2: どんな特徴量を作るか        ← 人間 × AI（二層構造）
工程3: 特徴量の変換・エンコーディング ← AI（自動化すべき）
工程4: アルゴリズムの選択           ← AI（松風も「何でもいい」）
工程5: ハイパーパラメータの調整      ← AI（Optuna等に任せる）
工程6: 評価指標・検証方法の設計     ← 人間（ここを間違えると全て崩壊）
工程7: 結果の解釈と次の仮説立案     ← 人間（AIは「なぜ」を考えられない）
```

---

## 工程別の詳細考察

### 工程1: 何のデータを集めるか ★★★ 人間の領域

松風が数千万円で「過去20年の目視レースデータ」を購入した判断（012）。これはAIには不可能。

```
人間にしかできないこと:
  - 「レース映像から位置取りを数値化すれば有用ではないか」という仮説
  - 「パドック映像から馬体のコンディションが読めるのではないか」
  - 「調教師のコメントに本音が隠れているのではないか」
  - 「馬主クラブの会員数とオッズの歪みに関係があるのではないか」

AIにはできないこと:
  - まだ存在しないデータの価値を想像すること
  - データ取得のコスト/リスクと見返りの経営判断
  - 競馬というドメインの「何が重要か」の直感

松風の実績:
  004: 「guzai（特徴量）が全て」
  012: 「データはパワー」= データ選択は最上流の意思決定
```

**結論**: データの選択・収集は完全に人間の仕事。ここが最も差別化に効く。

### 工程2: どんな特徴量を作るか ★★★ 二層構造

ここが最も議論が分かれるところ。答えは「二層に分ける」。

#### 第一層: 仮説駆動の特徴量（人間）

人間がドメイン知識から「これは効くはず」と仮説を立てて作る特徴量。

```
人間が作るべき特徴量の例:

  競馬ドメイン知識から:
  - 前走からの馬体重変動（太り/絞り → コンディション指標）
  - 休養明けの日数（フレッシュ度 vs 実戦勘）
  - 同コース・同距離の過去成績（適性指標）
  - 内枠/外枠の有利不利（コース特性）

  松風ブログの知見から:
  - オッズ乖離度: AI予測確率 vs 市場オッズ（001）
  - スマートマネー指標: 最終→確定オッズの変動（007）
  - 馬主クラブフラグ（001）
  - ワイドの条件付きEV（007）

  独自の仮説から:
  - 三連単フォーメーションバイアス指標（市場非効率性考察）
  - 騎手×コースの相性指標
  - 調教パターンの類似度
```

**なぜ人間か**: 「オッズの歪みは馬主クラブの応援馬券が原因ではないか」という仮説は、競馬を知らないAIには立てられない。松風の「10文字のブレークスルー」（002）もおそらく人間の洞察。

#### 第二層: データ駆動の特徴量（AI/自動化）

仮説なしに、データから機械的に生成する特徴量。

```
AIに任せるべき特徴量生成:

  自動集約:
  - 過去N走の成績の平均/最大/最小/標準偏差/トレンド
  - 騎手の直近M日間の勝率/回収率
  - 競馬場別、距離別、馬場状態別の集計統計量

  自動交互作用:
  - LightGBMが内部で特徴量の交互作用を自動発見
  - 人間が「種牡馬×距離」を手動で作る必要はない
    → モデルに発見させる（005: 手動交互作用は過学習の温床）

  自動変換:
  - 対数変換、Box-Cox変換
  - ビニング（連続値 → カテゴリ）
  - Target Encoding（カテゴリ → 数値）
```

**なぜAIか**: 「過去5走の上がり3Fタイムの標準偏差」は人間も作れるが、こうした集約パターンは膨大にあり、全部人間が考える必要はない。

#### 二層構造のまとめ

```
┌──────────────────────────────────────────┐
│  第一層: 仮説駆動（人間の腕の見せ所）       │
│  「このデータを、こう加工すれば効くはず」    │
│  → 競馬ドメイン知識 + 創造的仮説            │
│  → 数は少ないが、一つ一つの価値が高い        │
│  → 他者との差別化ポイント                   │
├──────────────────────────────────────────┤
│  第二層: データ駆動（AI/自動化）             │
│  「過去N走の集計統計量を全パターン生成」      │
│  → 機械的に大量生成                         │
│  → 数は多いが、個々の価値は小さい           │
│  → モデルが取捨選択する                     │
└──────────────────────────────────────────┘

両方必要。
第一層だけでは「見落とし」がある。
第二層だけでは「発想」がない。
```

### 工程3: 変換・エンコーディング → AI

```
自動化すべき:
  - カテゴリ変数のエンコーディング（LightGBMなら不要）
  - 欠損値の処理（LightGBMなら内部で処理）
  - 正規化・標準化（木系モデルでは不要）
  - 特徴量選択（重要度ベースで自動削減）

人間が判断すべき例外:
  - ドメイン的に意味のある欠損値の扱い
    例: 「過去の海外遠征成績がない」= 海外未経験（欠損≠不明）
```

### 工程4: アルゴリズム選択 → AI（ただし現実解あり）

```
松風(004): 「カレー粉は何でもいい」
現実的結論: LightGBMで始めて、必要なら他を試す

自動化の選択肢:
  - AutoML（auto-sklearn, FLAML, AutoGluon）
    → 複数アルゴリズムを自動で比較
  - ただし競馬では「確率出力の較正」が最重要
    → AutoMLの最適化目標をブライアスコアに設定する必要（人間の判断）

現実解:
  Phase 1: LightGBM固定（人間の判断）
  Phase 2: Optuna等で LightGBM vs XGBoost vs CatBoost を自動比較
  Phase 3: AutoMLで網羅的探索
```

### 工程5: ハイパーパラメータ調整 ★★★ AIの領域

**ここは完全にAIに任せるべき**。人間がグリッドサーチするのは時間の無駄。

```
なぜAIに任せるべきか:

  1. 探索空間が広すぎる
     LightGBMの主要パラメータだけで10個以上
     → 全組合せは数百万通り
     → 人間が「経験」で決めるのは非効率

  2. ベイズ最適化が人間より賢い
     Optuna / Hyperopt:
     - 過去の試行結果から「次に試すべき値」を推定
     - 100回の試行で、グリッドサーチ10,000回分の情報を得る
     - 人間の「勘」より統計的に優れている

  3. 再現性が保証される
     人間: 「learning_rateは0.01くらいがいい気がする」
     AI: 「100回の試行の結果、0.0137が最適（95%CI: 0.011-0.016）」

  4. 人間の時間を解放する
     ハイパーパラメータ調整に費やす時間を
     特徴量設計（第一層）やデータ収集に回すべき
```

#### Optunaの実用例

```python
import optuna
import lightgbm as lgb

def objective(trial):
    params = {
        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 16, 256),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
    }
    # Walk-Forward Validationでブライアスコアを計算
    score = walk_forward_cv(params)
    return score  # 最小化

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=200)
```

#### ただし人間が決めるべきこと

```
Optunaに任せる前に人間が設計すること:

  1. 最適化の目標関数
     → ブライアスコア？対数損失？回収率？
     → 「何を最適化するか」は人間が決める（006: 回収率最大化≠収支最大化）

  2. 探索範囲の設定
     → learning_rateを0.001〜1.0にするか0.01〜0.1にするか
     → ドメイン知識で不合理な範囲を除外

  3. 交差検証の方法
     → 時系列分割の切り方（何年分で学習、何年分でテスト）
     → これを間違えると過学習を自動化してしまう

  4. 過学習の監視
     → Optunaは「バックテストに過学習」するリスクがある
     → テストデータを二段階に分ける（validation + hold-out）
```

### 工程6: 評価指標・検証方法の設計 ★★★ 人間の領域

**ここを間違えると、工程3-5のAI自動化が全て逆効果になる**。

```
人間が設計すべき:

  1. 評価指標の選択
     × 的中率（003: 結果で判断するな）
     × 単純な回収率（005: 小サンプルでは意味がない）
     ○ ブライアスコア（較正精度）
     ○ 信頼区間付き回収率（005: 統計的有意性）
     ○ EV精度（購入馬券の期待値が実際にプラスか）

  2. 交差検証の設計
     × ランダム分割（未来の情報がリーク）
     ○ Walk-Forward Validation（時系列分割）
     ○ パージング（レース間の独立性を確保）

  3. 過学習検出の仕組み
     → 学習データと検証データの性能差を監視
     → 特徴量重要度の安定性（異なる期間で同じ特徴量が効くか）

  4. 「成功」の定義
     → 松風(006): 回収率が高ければいいのではなく、収支が最大化されること
     → これは人間の戦略的判断
```

**なぜ人間か**: Optunaは与えられた目標関数を最適化するが、「目標関数自体が正しいか」は判断できない。間違った評価指標を最適化すると、精度良く間違った方向に進む。

### 工程7: 結果の解釈と次の仮説 ★★★ 人間の領域

```
モデルが「騎手Xの特徴量重要度が高い」と出力:

  AIの回答: 「騎手Xは予測に重要です」（事実の報告）

  人間の解釈:
  - 「騎手Xは短期免許の外国人騎手で、過去データが少ない。
     これは過学習の可能性がある」（007の知見）
  - 「騎手Xはリーディング上位で単に勝率が高いだけかも。
     オッズにすでに織り込まれていればEVは上がらない」
  - 「騎手Xは特定のコースだけ成績が良い。
     サンプル数は十分か？」（005の過学習警告）

  → 次の仮説: 「騎手の生涯成績ではなく、
     直近の調子（過去30日成績）を使うべきでは？」
  → 新しい特徴量の設計（工程2の第一層に戻る）
```

---

## 「全部AIに任せる」の罠

### AutoMLの限界

```
AutoMLが得意なこと:
  ✓ アルゴリズムの比較
  ✓ ハイパーパラメータの最適化
  ✓ 基本的な特徴量変換
  ✓ 欠損値処理

AutoMLが苦手なこと:
  × ドメイン固有の特徴量設計
  × 「なぜその特徴量が効くか」の理解
  × 評価指標の妥当性判断
  × データリークの検出（時系列の問題）
  × 過学習の本質的な回避
  × まだ存在しないデータの発想
```

### 「自動化した過学習」のリスク

```
危険なパターン:

  1. 大量の特徴量を自動生成
  2. Optunaでハイパーパラメータを最適化
  3. 「バックテストで回収率130%！」
  4. 実運用で回収率85%...

原因:
  - 特徴量生成時にデータリークが紛れ込んでいた
  - Optunaがバックテストの「癖」に過学習した
  - 評価指標（回収率）のサンプル数が不十分だった

対策:
  - 人間がデータリークを確認する（時系列の整合性）
  - Hold-outデータを完全に分離する
  - 統計的有意性を確認する（005: 信頼区間）
```

---

## 実践的な分業設計

### 我々のプロジェクトへの適用

```
┌─────────────────────────────────────────────────────┐
│            人間（ふくだ君 + カカシ）の仕事             │
│                                                       │
│  1. データソースの選定                                │
│     「JRA-VAN + 競馬ブック + 独自データ」              │
│                                                       │
│  2. 仮説駆動の特徴量設計（第一層）                    │
│     「オッズ乖離度」「スマートマネー指標」              │
│     「三連単フォーメーションバイアス」etc.              │
│                                                       │
│  3. 評価フレームワークの設計                           │
│     「ブライアスコア + Walk-Forward + 信頼区間」        │
│                                                       │
│  4. 結果の解釈と次の仮説                              │
│     「この特徴量が効く理由は何か」「次に試すべきは何か」│
│                                                       │
│  5. 戦略的判断                                        │
│     「回収率を下げてでも購入金額を増やす」（006）       │
│     「税務要件を満たす設計にする」（010）               │
├─────────────────────────────────────────────────────┤
│               AI/自動化の仕事                          │
│                                                       │
│  1. データ駆動の特徴量生成（第二層）                   │
│     過去N走の集約統計量を網羅的に生成                  │
│                                                       │
│  2. 特徴量選択                                        │
│     重要度ベースで自動的に不要な特徴量を削減            │
│                                                       │
│  3. ハイパーパラメータ最適化                           │
│     Optunaで200回試行、最適パラメータを探索            │
│                                                       │
│  4. アルゴリズム比較                                   │
│     LightGBM vs XGBoost vs CatBoostの自動比較          │
│                                                       │
│  5. キャリブレーション                                 │
│     Plattスケーリング / Isotonic Regressionの自動適用   │
└─────────────────────────────────────────────────────┘
```

### 時間配分の目安

```
理想的な時間配分:

  特徴量設計（第一層・人間）:  40%  ← 最も時間をかけるべき
  データ収集・前処理:          20%
  評価フレームワーク設計:      15%
  結果の解釈・仮説立案:        15%
  ─────────────────────────────
  ハイパーパラメータ調整:       5%  ← AIに任せて放置
  アルゴリズム選択:            5%  ← AIに任せて放置

松風(004)の「アルゴリズムは何でもいい」:
  = アルゴリズムとハイパーパラメータに時間を使うな
  = その時間を特徴量設計に使え
```

---

## 松風ブログ知見との統合

### 松風の「腕の見せ所」はどこだったか

12記事を振り返ると、松風の競争優位は以下の人間の判断に集約される:

| 判断 | 内容 | 自動化可能か |
|---|---|---|
| 10文字のブレークスルー(002) | おそらくEV計算の発想 | × 人間の洞察 |
| ワイドEV計算の方法(007) | 3着全候補の条件付き期待値 | × 人間の発想、計算はAI |
| 目視データへの数千万円投資(012) | データの価値を見抜く経営判断 | × 人間の判断 |
| EV>1.0を全部買う(006) | 回収率より収支の最大化 | × 人間の戦略転換 |
| Themisの「目隠し」設計(011) | 確率とオッズだけで判断 | × 人間の設計思想 |
| 税務通達を設計に織り込む(010) | 法的要件の認識 | × 人間の知識 |
| AlphaImpactとの提携(012) | 競争戦略の経営判断 | × 人間の判断 |

一方、松風が自動化していたこと:

| 工程 | 内容 |
|---|---|
| モデリング(Poseidon) | 予測モデルの構築・学習 |
| 購入決定(Themis) | EV計算→購入金額決定→実行 |
| データ管理(Zeus) | DBの保守管理 |
| 3万年シミュレーション(009) | パラメータ最適化のための大規模計算 |

**パターン**: 「何を、なぜ」は人間。「どうやって、いくつ」はAI。

---

## 結論

### 一言で言えば

> **特徴量の「発想」は人間の腕の見せ所。ハイパーパラメータは完全にAIの仕事。**
> **ただし、評価の枠組みを設計する「審判」の仕事も人間にしかできない。**

### 三つの役割

```
人間 = 監督（何をやるか決める人）
  - データの選定
  - 仮説駆動の特徴量設計
  - 評価指標と検証方法の設計
  - 結果の解釈と次の方向性

AI = 選手（最適に実行する人）
  - データ駆動の特徴量生成
  - ハイパーパラメータ最適化
  - アルゴリズム選択
  - キャリブレーション

人間 = 審判（正しく測る人）
  - 過学習の検出
  - データリークの確認
  - 統計的有意性の判断
  - 「本当に意味があるか」の最終判断
```

### 最も危険な考え方

```
× 「全部手動でやる」
  → ハイパーパラメータ調整に時間を浪費
  → 特徴量設計に使える時間が減る

× 「全部AutoMLに任せる」
  → ドメイン知識を活かせない
  → 過学習を自動化するリスク
  → 評価指標の妥当性を誰もチェックしない

○ 「人間が仮説を立て、AIが検証し、人間が判断する」
  → 仮説 → 実験 → 解釈 のサイクルを高速に回す
```

---

## アクションアイテム

- [ ] Optunaを使ったハイパーパラメータ最適化パイプラインの構築
- [ ] 特徴量自動生成フレームワークの設計（過去N走の集約統計量の網羅的生成）
- [ ] 評価フレームワークの設計（ブライアスコア + Walk-Forward + Hold-out二段階）
- [ ] 仮説駆動特徴量のリスト整理（features.mdとの統合）
- [ ] 過学習検出の自動化（学習/検証の性能差アラート、特徴量重要度の期間安定性）

## タグ

`#モデル` `#特徴量` `#チューニング` `#過学習`

# 着順以外の目的変数: 何を予測すればAIは賢くなるか

モデルの精度の天井を決めるのは、特徴量でもアルゴリズムでもなく「何を予測させるか」（目的変数の設計）。着順をそのまま使うことの問題と、人間が設計した「より良い目的変数」の可能性を考察する。

> 起点: 「着順以外の目的変数のようなものを作ることについて考察したい。それは人が調整したり考案したりした数字が入ることもありとする」

---

## 1. なぜ「何を予測するか」が最重要なのか

### 目的変数はモデルの「世界観」を決める

```
機械学習のモデルは「目的変数を最も正確に予測するように」学習する。
つまり目的変数が「何を重要とみなすか」の全てを決める。

例え:
  テストの点数で成績をつけるなら、生徒はテストの点数を上げる方法を学ぶ。
  レポートの質で成績をつけるなら、生徒はレポートの書き方を学ぶ。
  → 「何で評価するか」が「何を学ぶか」を決定する。

競馬AIの場合:
  目的変数 = 着順     → 「着順が上の馬はどういう馬か」を学ぶ
  目的変数 = 1着かどうか → 「勝つ馬はどういう馬か」を学ぶ
  目的変数 = 能力値   → 「能力が高い馬はどういう馬か」を学ぶ

  それぞれ同じデータを使っても、学習結果が変わる。
  → 目的変数の設計は、特徴量追加の10倍インパクトがある可能性。
```

### 着順を目的変数にする場合の5つの問題

```
問題1: 順序尺度であって間隔尺度ではない
  1着と2着の差 ≠ 10着と11着の差
  → 着順を数値として扱うと、「1着→3着」と「8着→10着」が
    同じ2の差として処理される。実際の意味は全く違う。

問題2: レースのレベルが反映されない
  G1の10着 > 未勝利の1着（能力的には）
  → 着順はレース内の相対順位にすぎない。絶対能力を示さない。

問題3: ノイズが大きい
  同じ馬が同じ能力で走っても、展開・枠順・不利で
  1着にも5着にもなる。着順の分散が大きい。
  → 着順を目的変数にすると、モデルは「ノイズ」まで学習しようとする。

問題4: 出走頭数の影響
  8頭立ての5着 vs 18頭立ての5着
  → 同じ「5着」でも意味が違う。

問題5: 「惜しい負け」と「完敗」の区別がない
  0.1秒差の2着 vs 3.0秒差の2着 → 同じ「2着」
  → 着差という重要情報が失われる。
```

---

## 2. 既存の目的変数の選択肢

### 選択肢一覧

```
┌────────────────────────────────────────────────────────┐
│                目的変数の選択肢マップ                     │
├────────────────────────────────────────────────────────┤
│                                                        │
│  A. 着順（そのまま）     → 回帰問題。問題多い。         │
│  B. 1着フラグ（勝/負）   → 二値分類。現在の計画。       │
│  C. 3着内フラグ           → 二値分類。複勝用。          │
│  D. 着差（秒差）          → 回帰問題。情報量多い。      │
│  E. 相対着順（着順/頭数） → 回帰問題。頭数補正あり。    │
│  F. スピード指数          → 回帰問題。レース横断比較可。 │
│  G. 能力レーティング      → 回帰問題。Elo/Glicko。      │
│  H. 人間設計のスコア      → 回帰問題。★本考察の主題。   │
│  I. 複数目的変数          → マルチタスク学習。           │
│                                                        │
└────────────────────────────────────────────────────────┘
```

### A. 着順（回帰）

```
目的変数: y = 着順（1〜18の整数）
手法: LightGBM回帰

利点:
  - シンプル、理解しやすい
  - データの加工が不要

欠点:
  - 問題1-5すべてに該当
  - 回帰なので「y=2.7着」のような中間値が出る → 解釈が難しい
  - 損失関数（MSE）が「1着を3着と予測する」と「10着を12着と予測する」を
    同じ重さで扱う → 上位の精度が重要なのに

評価: ★☆☆ → 推奨しない
```

### B. 1着フラグ（二値分類）★現在の計画

```
目的変数: y = 1（1着）or 0（2着以下）
手法: LightGBM分類 → softmax出力 → 各馬の勝率

利点:
  - 出力がそのまま「勝率」= P(win)
  - Harville変換への入力として直接使える
  - 馬券のEV計算に直結

欠点:
  - 2着以下の情報を全て捨てている（2着も18着も同じ「0」）
  - 18頭中1頭だけが「1」→ 非常にクラスが不均衡
  - 「惜しい2着」の情報がモデルに伝わらない

評価: ★★☆ → 実用的だが改善の余地あり
```

### C. 3着内フラグ

```
目的変数: y = 1（3着以内）or 0（4着以下）
手法: LightGBM分類

利点:
  - 複勝・ワイドの確率に直結
  - クラス不均衡がBより緩和（3/18 ≈ 17%）
  - 「安定好走型」の情報をモデルに伝えられる

欠点:
  - 1着と3着を区別しない
  - 4着と18着を区別しない
  - 複勝確率は得られるが、1着確率が直接得られない

評価: ★★☆ → Bとの併用（マルチタスク）が有効
```

### D. 着差（秒差）

```
目的変数: y = 1着馬とのタイム差（秒）
  1着: y = 0.0
  2着: y = 0.2（0.2秒差）
  最下位: y = 3.5（3.5秒差）

手法: LightGBM回帰

利点:
  - 着順より情報量が圧倒的に多い
  - 「惜しい2着」(0.1秒差) と「完敗の2着」(2.0秒差) を区別できる
  - 連続値なので回帰として自然

欠点:
  - レースのペース・馬場で着差の意味が変わる
    （ハイペースの0.5秒差 ≠ スローペースの0.5秒差）
  - 1着馬が「弱い1着」の場合、着差0秒でも能力が高いとは限らない
  - レースレベルの違いは依然として反映されない

評価: ★★☆ → 着順より良いが、レベル補正なしでは限界あり
```

---

## 3. 人間が設計する目的変数のアイデア

### E. 「パフォーマンススコア」（基本版）

```
概念: 着順・着差・クラス・馬場を統合した「そのレースでの能力発揮度」

計算式:
  Score = クラス基準値 + 着差補正 + 上がり補正

  クラス基準値（レースのレベルに応じた基礎点）:
    G1:      100
    G2:      93
    G3:      87
    OP/L:    80
    3勝クラス: 73
    2勝クラス: 66
    1勝クラス: 59
    未勝利:   52
    新馬:     50

  着差補正:
    1着: +0
    着差0.0秒: -0（1着と同タイム = ほぼ同じ能力）
    着差0.1秒ごと: -1
    着差1.0秒: -10
    着差3.0秒: -30（大敗）

  上がり補正:
    上がり3F順位が1位: +3
    上がり3F順位が2位: +2
    上がり3F順位が3位: +1
    → 「着順は悪いが末脚は使えた」馬を救済

具体例:
  G1で0.3秒差の5着、上がり最速:
    Score = 100 + (-3) + 3 = 100 ★能力は非常に高い

  未勝利で1着、上がり5位:
    Score = 52 + 0 + 0 = 52

  3勝クラスで2.0秒差の10着、上がり15位:
    Score = 73 + (-20) + 0 = 53

→ 「G1の5着」(100) >> 「未勝利の1着」(52) が自然に表現される。
→ 着順だけでは見えない「能力の序列」が数値化される。
```

### F. 「真の能力値」（人間の判断を入れる版）

```
概念: Eの自動計算に加えて、人間が「補正」を入れる。

自動計算部分（E と同じ）:
  auto_score = クラス基準値 + 着差補正 + 上がり補正

人間が追加できる補正:

  ① 不利補正（+5 〜 +15）
    - 出遅れた（+5）
    - 進路を塞がれた（+8）
    - 落鉄した（+5）
    - 斜行を受けた（+10）
    - ゲート内で暴れて消耗した（+5）
    → 「本来ならもっと走れた」ことをスコアに反映

  ② 展開補正（-5 〜 +10）
    - ペースが合わなかった（差し馬でスロー、+5）
    - ペースが合った（差し馬でハイペース、-3）
    - 最内を通って距離ロスなし（-3）
    - 大外を回った（+5）

  ③ 仕上がり補正（-5 〜 +10）
    - 明らかに太め（+5〜10）
    - 休み明けで8分仕上げ（+5〜8）
    - 叩き良化途上（+3）

  ④ 距離適性補正（-5 〜 +5）
    - 明らかに距離が長かった（+5）
    - 得意距離ドンピシャ（-3）

  final_score = auto_score + 不利補正 + 展開補正 + 仕上がり補正 + 距離適性補正

★これは人間の「目利き」をデータに込める仕組み。
  松風の「20年分の目視レースデータ」（012）に相当する情報が
  数値としてモデルに伝わる。
```

### G. 「着順は結果、スコアは能力」の分離

```
■ 着順 = その日の結果
  → 展開、不利、枠順、馬場のランダム要因を含む
  → ノイズが大きい
  → 「次のレース」の予測には不向き

■ パフォーマンススコア = その日に発揮した（であろう）能力
  → ランダム要因を補正した「本来の実力」の推定
  → ノイズが小さい
  → 「次のレース」の予測に向いている

目的変数として使う場合:
  モデルの入力: 過去のスコア推移、特徴量群
  モデルの出力: 次走のスコアの予測値

  次走スコア予測 → 全馬のスコア予測をソフトマックス
  → 各馬の「勝率」に変換 → EV計算 → Themisへ

利点:
  「着順を予測する」のではなく「能力を予測する」モデルになる。
  → ノイズが少ない目的変数で学習するので、汎化性能が高い可能性。
  → 「不利を受けて負けた馬」の次走好走を予測しやすくなる。
```

---

## 4. もっとラディカルなアイデア

### H. 「レース後に振り返って採点する」目的変数

```
概念: レースの映像・データを見た後に、各馬に「採点」する。
      レース前の予想ではなく、レース後の事後評価。

採点基準（10点満点）:
  10: 圧倒的なパフォーマンス。負けなし。
   9: 非常に強い競馬。多少の不利も跳ね返した。
   8: 能力を出し切った好走。結果は2-3着でも内容は一流。
   7: 標準的な好走。着順相応の内容。
   6: やや物足りないが、言い訳材料あり。
   5: 凡走。ただし展開や条件の影響あり。
   4: 力負け。現状のクラスでは足りない。
   3: 大敗。コンディションや適性に問題。
   2: 著しく不本意な内容。故障の疑いあり。
   1: 競走中止・落馬等。

この「採点」を目的変数にする:
  → 着順ではなく「内容の質」を予測するモデルになる
  → 「次走で8点以上のパフォーマンスを出す確率」を予測
  → 8点以上 ≈ 好走 → 馬券に繋がる

最大の欠点:
  → 全レースを採点する労力が膨大
  → 主観が入る（評価者によってブレる）
  → 一貫性の維持が難しい

現実的な対処:
  → 重賞レースのみ採点（年間約130レース × 18頭 ≈ 2,300件）
  → 条件戦は自動採点（E の計算式）に任せる
  → 人間の採点と自動採点の中間モデルを学習させる
     （少量の人間採点 → 自動採点モデルの教師データにする）
```

### I. 「この馬は次走で巻き返すか」の直接予測

```
概念: 馬券に直結する「次走で好走するか」を直接予測する。

通常のアプローチ:
  特徴量 → P(次走で1着) → EV計算

巻き返し予測アプローチ:
  特徴量 + 前走の内容 → P(次走で着順が3以上改善する) → 人気との乖離 → EV

なぜこれが有用か:
  → 「着順が悪かった馬」は人気が落ちる
  → その中で「実は次走で好走する馬」がいれば、オッズが割高
  → 「巻き返し確率」と「人気落ちによるオッズ上昇」の積 = EV

目的変数の設計:
  y = 1 if (前走着順 - 今走着順) >= 3 else 0

  つまり「前走から3着順以上改善したか」を予測する。

  これは「能力が高いのに前走で走れなかった馬」を検出する。
  → 前走の不利、展開、距離不適合を特徴量で入力
  → 「この馬は巻き返す」を予測する

利点:
  → 馬券で最も利益が出やすい「人気落ちの巻き返し馬」に特化
  → 目的変数自体が「利益源泉」に直結
  → beyond_finishing_position.md の「巻き返し候補検出」を
     特徴量ではなく目的変数として組み込む

欠点:
  → 汎用性が低い（巻き返し馬券だけに使える）
  → 通常の勝率予測と別にモデルが必要
```

### J. 「期待値に直結するスコア」= 最終的にはEVそのもの

```
概念: 馬券の期待値を直接予測する。

  目的変数: y = (的中したら得られる金額 - 購入金額) / 購入金額
            = オッズ × 的中フラグ - 1

  単勝の場合:
    1着の馬: y = オッズ - 1（例: 10倍なら y = 9）
    それ以外: y = -1（ハズレ = 購入額を失う）

  これを回帰で予測する。
  → 「この馬の単勝を買うと、期待値はいくらか」を直接予測

利点:
  → EV計算のステップが不要。モデルの出力がそのまま購入判断
  → 「P(win) × オッズ」の分解を経由しない → 中間の誤差がない

欠点:
  → yの分散が非常に大きい（-1 か +大きな値）→ 学習が極めて困難
  → オッズの情報がモデル内に入る → 「オッズを見て買う」モデルになる
  → 市場の情報に依存しすぎて、独自の予測能力が育たない危険
  → Themisの目隠し原則に反する

評価: ★☆☆ → 理論的には美しいが実用的ではない
```

---

## 5. マルチタスク学習: 複数の目的変数を同時に予測

### 一つに絞らなくてもいい

```
概念: 一つのモデルで複数の目的変数を同時に予測する。

例:
  目的変数1: P(1着)       → 勝率予測（単勝EV用）
  目的変数2: P(3着以内)   → 複勝率予測（複勝/ワイドEV用）
  目的変数3: パフォーマンススコア → 能力の絶対値（分析用）

LightGBMでの実装:
  → 直接のマルチタスクは難しい。選択肢は:

  方法1: 3つの別モデルを作る
    model_win = LightGBM(y = 1着フラグ)
    model_place = LightGBM(y = 3着内フラグ)
    model_score = LightGBM(y = パフォーマンススコア)

    利点: シンプル。各モデルが独立に最適化。
    欠点: モデル間の整合性がない（P(win) > P(place)になりうる）

  方法2: パフォーマンススコアを予測 → 変換
    model = LightGBM(y = パフォーマンススコア)
    predicted_scores → softmax → P(win)
    predicted_scores → 閾値 → P(place)

    利点: 整合性がある。1つのモデルで全てカバー。
    欠点: スコアの変換精度が鍵。

  方法3: 着順分布そのものを予測
    model = LightGBM(y = 正規化着順)で分布の平均μを予測
    model2 = LightGBM(y = |着順 - 平均着順|)で分散σを予測
    (μ, σ) → Thurstone的シミュレーション → 組合せ確率

    利点: harville_iia_critique.md で議論した
          「馬ごとのσ」を直接モデル化できる
    欠点: 複雑。2つのモデルの連携が必要。

  ★ 方法2が最もバランスが良い。推奨。
```

---

## 6. 「人間が設計する数字」の価値と危険性

### 価値: AIが見えないものを教える

```
AIがデータから学習できないもの:

  1. 「この馬は不利を受けた」
     → JRA-VANに「不利フラグ」はない
     → 映像を見ないとわからない
     → 人間がスコアに反映すれば、AIに教えられる

  2. 「この馬は本気で走っていなかった」
     → 前哨戦で力を温存した
     → 勝ちにいかず3着で十分と判断した
     → 着順は「真の能力」を反映していない

  3. 「この馬は初めてのコースで戸惑っていた」
     → 右回り初体験でスムーズに走れなかった
     → データ上は「右回り成績ゼロ」だが、次走は改善する可能性
     → 人間なら映像から判断できる

  4. 「この馬の脚色が良かった」
     → 着順は5着だが、ゴール後も余力があった
     → データには「脚色」の情報はない
     → 人間が「+5点」を加えれば、「次走で走る」を示唆

→ 人間の目利き = AIのデータ外の情報を補完する手段
→ 松風の「数千万円の目視データ」に相当する価値を持ちうる
```

### 危険性: 人間のバイアス

```
1. 確証バイアス
   → 自分の好きな馬に高い点をつけてしまう
   → 「この馬は強い」という先入観でスコアを歪める

2. 後知恵バイアス
   → レース後に結果を見てからスコアをつけると、
     結果を「予測可能だった」ように感じてスコアが歪む
   → 「あの不利がなければ勝っていた」は事後的な解釈

3. 一貫性の欠如
   → 疲れている日と元気な日で採点基準が変わる
   → 1年前の採点と今日の採点が同じ基準とは限らない

4. スケーラビリティ
   → 年間3,400レース × 平均14頭 ≈ 48,000件の採点
   → 一人で全て採点するのは非現実的
   → 自動採点と人間採点のハイブリッドが必要

対策:
  → 採点基準を明文化し、チェックリスト化する
  → 「自動計算部分」と「人間補正部分」を分離する
  → 人間補正は加算（±N点）のみとし、ベースを上書きしない
  → 補正の理由を必ず記録する（後で検証可能にする）
  → 定期的に自分の補正の「的中率」を検証する
```

---

## 7. 実装設計: ハイブリッドスコアシステム

### 三層構造

```
┌─────────────────────────────────────────────────┐
│  Layer 1: 自動計算スコア（全レース対象）          │
│                                                 │
│  score_auto = クラス基準値                       │
│              + 着差補正（1着との秒差 × -10）     │
│              + 上がり補正（上がり順位ボーナス）   │
│              + 斤量補正（負担重量の影響）         │
│              + 馬場補正（重馬場の減速を考慮）     │
│                                                 │
│  → JRA-VANデータから自動計算。年間48,000件全て。 │
├─────────────────────────────────────────────────┤
│  Layer 2: ルールベース補正（条件に該当するもの）  │
│                                                 │
│  score_rule = 出遅れ検出（1角で大きく順位低下）  │
│             + 大外ロス推定（枠順 × 通過順位）    │
│             + 休み明け補正（間隔 × 叩きN戦目）   │
│             + 昇級補正（初めてのクラスで凡走）    │
│                                                 │
│  → ルールで自動判定。人間の判断を近似する。       │
├─────────────────────────────────────────────────┤
│  Layer 3: 人間の手動補正（重要レースのみ）        │
│                                                 │
│  score_human = ±N点（理由を必ず記録）            │
│                                                 │
│  対象: 重賞レース（年間約130R）                   │
│       + 注目馬のレース（随時）                    │
│       + 自動採点と着順の乖離が大きいケース        │
│                                                 │
│  → 映像を見て判断。不利、脚色、仕上がりを反映。   │
└─────────────────────────────────────────────────┘

最終スコア:
  score_final = score_auto + score_rule + score_human

→ Layer 1で95%のケースをカバー
→ Layer 2で残り4%を補正
→ Layer 3は1%だが、重賞（高額馬券）に集中 → 金額インパクト大
```

### モデルの入力/出力設計

```
■ 学習時:
  入力: 特徴量（血統、騎手、枠順、調教、ローテ、環境...）
  目的変数: score_final（直近レースのスコア...ではなく）

  ★ 目的変数は「次のレースでのスコア」
  つまり:
    各レースの行 = (特徴量, 次のレースのスコア)
    「この特徴量の馬が、次のレースでどれくらいのスコアを出すか」を学習

■ 予測時:
  入力: 出走馬の特徴量
  出力: predicted_score（各馬のスコア予測値）

  スコア → 確率への変換:
    P(A wins) = softmax(predicted_scores)[A]
    = exp(score_A) / Σ exp(score_k)

  → これがHarville変換の入力になる。

■ 「現在のスコア」も特徴量として使える
  - 過去5走のスコアの平均
  - 過去5走のスコアの標準偏差（= 安定度 = horse_performance_distribution）
  - スコアのトレンド（上昇中/下降中/横ばい）
  - 最高スコアと平均スコアの差（ポテンシャル）
```

---

## 8. 具体的なスコア計算の設計案

### クラス基準値の設定

```
原則: 「そのクラスの平均的な勝ち馬のスコアが基準値」

基準値案:
  ┌──────────────────┬────────┬─────────────────────────┐
  │ クラス            │ 基準値 │ 根拠                    │
  ├──────────────────┼────────┼─────────────────────────┤
  │ G1               │ 115    │ 最高レベル              │
  │ G2               │ 108    │ G1とG3の中間            │
  │ G3               │ 102    │ 重賞の入口              │
  │ OP/リステッド     │ 96     │ 条件戦の上限            │
  │ 3勝クラス        │ 90     │                         │
  │ 2勝クラス        │ 84     │                         │
  │ 1勝クラス        │ 78     │                         │
  │ 未勝利           │ 72     │ 新馬を含まない          │
  │ 新馬             │ 70     │ 実績なし。不確実性最大  │
  └──────────────────┴────────┴─────────────────────────┘

  注意: これは「1着の基準値」。2着以降は着差で減算。

  例: G1で0.5秒差の3着 → 115 + (-5) = 110
      2勝クラスで快勝（0.0秒差）→ 84
      → G1の3着(110) > 2勝クラスの1着(84) ← 自然！

  ★ この基準値自体もデータから推定すべき。
  → 各クラスの1着馬が次走以降で出すスコアの平均を使う
  → 初期値は上記の手動設定、データが溜まったら更新
```

### 着差補正の設計

```
着差補正 = -α × 着差（秒）

  α = 10 の場合:
    着差0.0秒: 0
    着差0.1秒: -1
    着差0.5秒: -5
    着差1.0秒: -10
    着差2.0秒: -20
    着差5.0秒: -50（大差）

  α の設定根拠:
    「0.1秒差 ≈ 1馬身 ≈ 能力1ポイント差」が直感的。
    実際のデータでαを最適化すべき。

  非線形補正の検討:
    着差が大きくなるほど情報が少なくなる（大敗はどれも「力不足」）
    → 着差補正 = -α × min(着差, 3.0)（3秒以上は打ち切り）
    → あるいは -α × log(1 + 着差) で対数的に圧縮
```

### 上がり・位置取り補正の設計

```
上がり3F順位補正:
  1位: +4
  2位: +3
  3位: +2
  4-5位: +1
  それ以外: 0

  根拠: 「着順は悪いが末脚は速かった」= 展開が合わなかった
  → 能力は着順より高い可能性をスコアに反映

4角→着順の改善補正:
  4角順位 - 着順 > 5: +3（大まくり。能力の高さを示唆）
  4角順位 - 着順 > 3: +2
  4角順位 - 着順 > 1: +1
  → 終盤の加速力をスコアに反映

斤量補正:
  斤量差 = (実際の斤量 - そのクラスの標準斤量)
  補正 = -斤量差 × 2
  → 重い斤量を背負って好走 = 実質的に能力が高い
```

---

## 9. このアプローチの位置づけ

### 既存insightとの統合

```
■ human_vs_ai_in_model_design.md:
  「工程6: 評価指標・検証方法の設計 ← 人間」
  → 目的変数の設計はまさにこの工程。
  → 「何を正解とするか」を人間が決め、AIはそれを予測する。

■ beyond_finishing_position.md:
  着順以外の評価基準として8つのアプローチを整理した。
  → その「特徴量」を、本考察では「目的変数」に格上げする。
  → 上がり3Fギャップや着差は、特徴量であると同時に
    目的変数の構成要素にもなる。

■ horse_performance_distribution.md:
  安定型/一発型の3類型。
  → パフォーマンススコアの標準偏差 = 安定度の直接的な指標になる。
  → スコアベースなら着順分布よりノイズが少ない。

■ harville_iia_critique.md:
  Thurstoneモデルに必要な「各馬のμとσ」。
  → μ = スコアの予測値、σ = スコアの標準偏差
  → スコアベースのモデルなら、Thurstone変換との相性が良い。

■ prediction_interview_feature.md:
  SHAP値でモデルの判断根拠を可視化する。
  → スコア予測モデルなら「なぜこの馬のスコアが高い/低いか」を
    インタビュー機能で提示できる。
```

### 松風との比較

```
松風のアプローチ（推測）:
  → 1着確率を予測（二値分類 or softmax分類）
  → Harville変換で組合せ確率
  → Themisで購入判断

本考察のアプローチ:
  → パフォーマンススコアを予測（回帰）
  → スコア → softmax → 確率
  → Harville（or Thurstone）変換で組合せ確率
  → Themisで購入判断

違い:
  → 中間に「人間が設計したスコア」が入る
  → スコアが「着順のノイズ」を除去した目的変数になる
  → モデルは「結果」ではなく「能力」を学習する

松風を超える可能性:
  → 松風は（おそらく）1着確率の直接予測
  → 着順の持つノイズをそのまま学習している
  → スコアベースなら、より精密な能力推定が可能
  → ただし、スコア設計のミスはモデル全体を歪める
    → 慎重な設計と検証が必要
```

---

## 10. 実装ロードマップ

```
Phase 0: 現在の計画通り（1着フラグ予測）
  → まず動くものを作る。ベースラインを確立。
  → これで利益が出ることを確認してから次に進む。

Phase 1: パフォーマンススコア（自動計算のみ）の導入
  Step 1: クラス基準値 + 着差補正 + 上がり補正のスコア計算
  Step 2: 過去データで全馬のスコアを算出
  Step 3: スコアを目的変数としたモデルと、1着フラグモデルの精度比較
  Step 4: スコアモデルのEVがベースラインを上回るか検証
  → 上回らなければPhase 2に進まない。

Phase 2: ルールベース補正の追加
  Step 1: 出遅れ検出、大外ロス推定のロジック実装
  Step 2: 補正の有無でスコアの精度を比較
  Step 3: 有効な補正のみ採用

Phase 3: 人間の手動補正（重賞のみ）
  Step 1: 採点基準のチェックリスト作成
  Step 2: 直近の重賞レースから採点開始
  Step 3: 人間補正の「的中率」を検証（補正した馬が次走で好走するか）
  Step 4: 有効と確認されたら正式運用

Phase X: マルチタスク化
  Step 1: スコア予測 + 1着確率予測のマルチモデル
  Step 2: スコアの分散予測（→ Thurstone変換に直結）
  → harville_iia_critique.md のPhase 4と統合
```

---

## アクションアイテム

- [ ] パフォーマンススコアの計算式を確定（クラス基準値、着差係数α）
- [ ] 過去データで全馬のスコアを試算し、分布を確認
- [ ] スコアを目的変数としたLightGBMモデルのプロトタイプ
- [ ] 1着フラグモデル vs スコアモデルの精度比較（回収率シミュレーション）
- [ ] 出遅れ検出ロジックの設計（1角通過順位の急落を閾値判定）
- [ ] 重賞レースの手動採点チェックリストの作成
- [ ] features.mdに「スコアの統計量」特徴量を追加

## 関連ドキュメント

| 関連insight | 接続点 |
|---|---|
| [着順以外の評価基準](beyond_finishing_position.md) | スコアの構成要素（着差、上がり、位置取り） |
| [特徴量設計とハイパラ](human_vs_ai_in_model_design.md) | 工程6「評価指標の設計は人間の仕事」 |
| [馬の着順分布の形状](horse_performance_distribution.md) | スコアの標準偏差 = 安定度の指標 |
| [Harville IIA批判](harville_iia_critique.md) | スコアのμとσ → Thurstone変換への入力 |
| [予測根拠のインタビュー](prediction_interview_feature.md) | スコア予測のSHAP説明 |
| [ローテーション分析](rotation_interval_analysis.md) | 休み明け補正、叩き良化補正 |

## タグ

`#モデル` `#特徴量` `#確率論` `#馬券戦略`

# 競馬とギャンブルの話②③ ランダムネスと平均回帰

- **出典**: Matsukaze.AI
  - ②「ランダムネスと流れ」 http://matsukaze.ai/?p=529
  - ③「平均回帰の法則とよくある分析手法」 http://matsukaze.ai/?p=540
- **日付**: 2025-02-11（元記事: ② 2018-05-10 / ③ 2018-05-22）
- **前編**: [003 競馬観と確率認知](003_競馬観と確率認知.md)

## 要点

### ② ランダムネスと流れ

#### 人間のランダム観は歪んでいる

- 0と1をランダムに並べる実験 → 人間は「遷移回数」を実際のランダムより多くしてしまう
- iPodのシャッフル問題: 真のランダムは同じ曲が連続しやすく、ユーザーは「ランダムではない」と感じた
  - ジョブズ: 「よりランダムな感じを出すために、少しランダムではなくした」
- **誕生日のパラドックス**: 23人で同じ誕生日ペアが50%超 → 直感とのギャップ

#### 確率の偏りと「流れ」

- 人間はランダムに対して「偏りの少なさ」を過度に期待してしまう
- **確率の収束に必要な回数は、直感よりずっと多い**
- ギャンブラーが言う「流れ」= 自分のイメージを超える確率の偏りを説明するための概念
- **ホットハンド誤謬**: 前回の良い結果が次の良い結果に結びつくと信じる誤り
  - ルメールが午前中に2勝 → 午後も好調に見える → しかし合理的根拠はない
- 逆方向（悪い流れ → 自滅）はありうる: 偏りで我を失い、さらに負ける

#### まとめ（原文）

- 真のランダムは意外とランダムじゃない（偏る）
- 収束に必要な回数は直感よりずっと多い
- 勘違いして勝手に自滅するな

### ③ 平均回帰の法則とよくある分析手法

#### 平均回帰の法則

- 極端に良い/悪い結果の次は、平均に近い結果が出る確率が高い
- 例:
  - テスト期待50点の人が95点 → 次は95点より低い確率が高い
  - ディープインパクトの仔 → ディープより弱い確率が高い
  - 三冠馬×三冠馬 → 仔が三冠取れない確率が高い

#### 飛行教官の誤謬

- 訓練生が良い飛行 → 褒める → 次は平均回帰で悪くなる
- 訓練生が悪い飛行 → 叱る → 次は平均回帰で良くなる
- 教官の結論: 「褒めると付け上がる、叱れば上達する」 → **完全に間違い**

#### 競馬への適用

- 「大勝負すると当たらない、買わないと当たる」= **平均回帰に翻弄されているだけ**
  - 大勝負する時 = 回収率が外れ値的に良い瞬間 → 次は平均に回帰
  - 諦めた時 = 回収率が外れ値的に悪い瞬間 → 次は平均に回帰

#### 「よくある分析手法」への痛烈な批判

- **「この産駒はこの距離このコース」系の分析は血液型占いレベルの疑似科学**
- 過去の好成績を観測 → それを買い続ける手法は平均回帰を無視している
- 「私の今年の西田雄一郎と森祐太郎の回収率は22325%だから買い続ける」と同じ
- サンプルサイズが小さい条件分けでの好成績 = 単なる偶然の可能性が高い
- **この種の手法は勝利から全力で遠ざかる**

#### まとめ（原文）

- 流れとか調子とかない
- あるのは平均回帰の法則だけなので、冷静になれ
- 血統予想は血液型占いと同じレベルの疑似科学

## AI開発への示唆

### 1. 過学習（オーバーフィッティング）の回避 ← 最重要

- ③の批判は、そのまま**機械学習の過学習問題**に対応する
- 「この産駒×この距離×このコース」= **特徴量の過度な交互作用**
- サンプルが少ない条件分けで高回収率を見つける = **ノイズにフィットしている**
- 対策:
  - **十分なサンプルサイズの確保**: 条件ごとの出走数が少なすぎる組み合わせを使わない
  - **交差検証の徹底**: 学習データで良い成績 ≠ 未知データで良い成績
  - **正則化**: モデルが少数の極端なパターンに引きずられないようにする
  - **特徴量の安定性テスト**: 異なる期間で同じ特徴量が有効かを検証

### 2. バックテストの信頼性

- 「長期的にプラス」の「長期」は直感より遥かに長い
- **収束に必要なレース数の見積もり**:
  - 年間回収率110%が真の実力だとして、それを統計的に有意に示すのに必要なレース数は？
  - 分散が大きい馬券種ほど、必要なサンプルサイズは増大
  - 単勝（低分散）vs 三連単（超高分散）で必要回数が桁違い
- **信頼区間の明示**: 「回収率115%」ではなく「回収率115% ± 20%（95%CI）」と報告すべき

### 3. 血統特徴量の扱い方

- Matsukaze氏は血統予想を「疑似科学」と断じているが、これは**小サンプル × 多条件分け**の問題
- 血統自体を全否定しているわけではなく、**統計的に有意でない分析手法**を批判
- AIでの血統特徴量の正しい使い方:
  - 種牡馬成績は**十分なサンプルで集計**（個別コース×距離ではなく、距離カテゴリ程度）
  - **カテゴリエンコーディング** or **Embedding**として使い、モデルに学習させる
  - 交互作用はモデルに発見させ、人間が恣意的に決めない

### 4. メンタルモデルとしての自動化

- 「勘違いして自滅するな」→ 人間の判断を排除するためのAI自動化
- 自動購入のメリット:
  - 「流れ」に惑わされない
  - 大勝ち/大負けの後も同じロジックで淡々と購入
  - 平均回帰に翻弄されない
- **Matsukaze氏の大規模自動購入（年間17.5億円）はまさにこの哲学の実装**

## 独自考察

### 003→005で形成された「やってはいけないこと」リスト

| やりがちなこと | なぜダメか | 正しいアプローチ |
|---|---|---|
| 的中率で手法を評価 | 確率事象の結果で判断している | 期待値・較正精度で評価 |
| 少数レースで判断 | 収束に必要な回数が足りない | 数千レースのバックテスト |
| 「流れ」で賭け金を変える | ホットハンド誤謬 | 固定ロジックで機械的に購入 |
| 産駒×距離×コースの分析 | 平均回帰 + 小サンプル | モデルに交互作用を学習させる |
| 好成績条件を買い続ける | 過学習（ノイズへのフィット） | 交差検証 + 正則化 |
| 結果で戦略を変更 | 飛行教官の誤謬 | 十分なサンプルの事前設計 |

### 「血統は疑似科学」への補足考察

- Matsukaze氏の主張は「クソほど研究した上で」の結論 → 単なる感想ではない
- しかし血統が**完全に無意味**とまでは言えない理由:
  - 遺伝的な能力差は確実に存在する
  - 種牡馬の産駒成績には統計的に有意な傾向がある（十分なサンプルで）
  - 問題は「芝1600m東京」のような**過度に細分化した分析**
- **AI開発での結論**: 血統は特徴量として使うが、細分化しすぎない。モデルに任せる。

### 統計的有意性の実用的ガイドライン

- 回収率の偏りが統計的に有意かを判断する簡易的な目安:
  - **単勝**: 最低500レース以上のサンプル
  - **複勝**: 最低300レース以上
  - **ワイド**: 最低500レース以上
  - **三連単**: 最低数千レース以上（分散が極めて大きいため）
- **検定方法**: ブートストラップ法で回収率の95%信頼区間を求め、100%を上回っているかを確認

## 関連データ

| データ項目 | 用途 | 備考 |
|---|---|---|
| 種牡馬別成績（大サンプル） | 血統特徴量の正しい使い方の検証 | 細分化しすぎない |
| 全レース回収率の時系列 | 平均回帰・分散の実測 | 馬券種別に分析 |
| 騎手別成績の変動 | ホットハンド誤謬の検証 | 短期 vs 長期の傾向差 |

## アクションアイテム

- [ ] バックテストに信頼区間（ブートストラップ）を実装
- [ ] 血統特徴量の粒度設計: 種牡馬ID vs 距離適性カテゴリ vs 個別コース
- [ ] 過学習防止: 交差検証パイプラインの構築
- [ ] 「サンプルサイズ不足警告」機能の設計（条件別分析時）
- [ ] 馬券購入ロジックの完全自動化（人間の判断を排除）

## タグ

`#確率論` `#モデル` `#血統` `#馬券戦略` `#過学習`

# 逆算してゆく競馬AIの作り方 (1/3〜3/3)

- **出典**: Matsukaze.AI「逆算してゆく競馬AIの作り方」
  - 1/3: http://matsukaze.ai/?p=563
  - 2/3: http://matsukaze.ai/?p=567
  - 3/3: http://matsukaze.ai/?p=573
- **日付**: 2025-02-11（元記事: 2018-06-01）

## 要点

### 1/3: モデル学習（カレー粉 = 機械学習ライブラリ）

- scikit-learnを使ったモデル構築を「カレー作り」に例えた超入門
- コードの本質はたった3行:
  ```python
  from sklearn.ensemble import RandomForestRegressor
  curry = RandomForestRegressor()
  curry.fit(guzai, target)
  ```
- カレー粉（アルゴリズム）は何でもいい（RandomForest / MLP / 何でも）
- **必要なのは「guzai（特徴量）」と「target（予測対象）」だけ**

### 2/3: データ準備（具材 = 競馬データCSV）

- pandasでCSVを読み込むだけ:
  ```python
  import pandas as pd
  guzai = pd.read_csv('guzai.csv').values
  target = pd.read_csv('target.csv').values
  ```
- データソースの選択肢:
  - **TARGET（JRA-VAN viewer）** からCSVエクスポート
  - **JRA-VAN Data Lab SDK** を使って自前でCSVダウンロードツールを作る
- targetは「着順」「走破タイム」など何でもよい

### 3/3: 前処理（具材を切る = データクレンジング）

- 前処理 = 「味が染み出し、染み込み、煮崩れしないギリギリの切り方」
- 実際にやったこと:
  - JRA-VANのデータにはヘッダーがない → `header=None`で対応
  - 文字列データが混在 → 文字列列を全部削除（「アク取り」）
  - JRA-VAN固有の区分コード（例: "SE" = 馬毎レース情報）への対処
- Warningは無視（「吹きこぼれ」）
- `predict()`で別レースのデータを入れると予測が出る

## AI開発への示唆

### 1. 「アルゴリズムは何でもいい」の真意

- Matsukaze氏は明確に**アルゴリズム選択は重要でない**と主張している
- 002の「10文字のブレークスルー」はモデルアーキテクチャではないことを裏付け
- **重要なのはアルゴリズムではなく、guzai（特徴量）とtarget（予測対象）の設計**
- これは機械学習の実務でも広く言われること: "Garbage in, garbage out"

### 2. target（予測対象）の設計が鍵

- 「着順」「走破タイム」以外に何をtargetにするかで戦略が変わる:
  - **着順**: 分類/ランキング問題
  - **走破タイム**: 回帰問題
  - **勝率/連対率**: 確率推定問題 ← 003の確率論的競馬観と整合
  - **回収率/期待値**: 直接的な利益最適化
- Matsukaze氏は「着順とか走破タイムとか**なんでも**」と言っているが、003の思想を踏まえると**確率推定が本命**

### 3. 前処理の軽視は「あえて」

- 文字列列を全削除という乱暴な前処理は、チュートリアルの簡略化
- しかし実際には**前処理（特徴量エンジニアリング）こそが勝敗を分ける**
- JRA-VANデータの区分コード、カテゴリ変数のエンコーディング、欠損値処理が実運用の核心

### 4. データソースについて

- JRA-VAN Data Lab SDKを推奨 → 我々のプロジェクトでも採用済み
- TARGETからのCSVエクスポートも入門には有効

## 独自考察

### 001→003の思想 + 004の技術 = 完全なフレームワーク

```
思想レイヤー:
  [003] 着順は確率変数 → 確率推定モデルが本質
  [001] オッズの歪み = 利益の源泉

技術レイヤー:
  [004] モデル構築は簡単（scikit-learn 3行）
  重要なのは:
    1. guzai（特徴量）の設計 ← まだ未解説
    2. target（予測対象）の設計 ← 確率 or 期待値
    3. 前処理の質 ← 実運用の核心

戦略レイヤー:
  [002] 正のEVを大量に繰り返す
```

### 「カレー粉は何でもいい」を検証する

- Matsukaze氏の実績（年間+4.3億）から逆算すると、使用アルゴリズムは以下の可能性:
  - **RandomForest**: チューニング不要で安定、特徴量重要度も見られる
  - **LightGBM/XGBoost**: 表形式データでのデファクトスタンダード
  - **ロジスティック回帰**: 確率出力に直接使える、較正が容易
- ディープラーニングは競馬データ（表形式）では優位性が薄い
- **結論: 勾配ブースティング系 + 適切な特徴量設計が現実的な最適解**

### 未解説の「本当に重要な部分」

この連載で**意図的に詳しく語られていない**のが核心:
1. **特徴量の選択・設計**: どの情報を guzai に入れるか
2. **targetの具体的な設計**: 何を予測するか（確率？タイム？着順差？）
3. **前処理の詳細**: カテゴリ変数のエンコーディング、正規化、欠損値処理
4. **予測結果から馬券購入への変換**: predict()の出力をどう期待値に変換するか

→ 1〜3が「guzaiの切り方」、4が001-003の思想の実装に相当

### 我々のプロジェクトへのマッピング

| Matsukaze記事の概念 | 我々のプロジェクト |
|---|---|
| カレー粉（アルゴリズム） | `keiba-v2/ml/` のモデル |
| guzai（特徴量CSV） | JRA-VAN Data Lab → パース済みデータ |
| target（予測対象） | 設計判断が必要（確率推定 or タイム予測） |
| 前処理 | `keiba-v2/core/` のパーサー・変換処理 |
| predict → 馬券 | シノ（期待値計算）→ シカマル（購入戦略） |

## 関連データ

| データ項目 | 用途 | 備考 |
|---|---|---|
| JRA-VAN 馬毎レース情報(SE) | メインの特徴量ソース | 区分コード対応が必要 |
| JRA-VAN Data Lab SDK | データ取得 | プロジェクトに既存 |
| TARGET CSV出力 | 簡易データ取得 | プロトタイプ向け |

## アクションアイテム

- [ ] target設計の方針決定: 着順予測 vs 確率推定 vs タイム予測
- [ ] 特徴量候補リスト（features.md）を充実させる → 今後のブログで情報追加予定
- [ ] 最小限のベースラインモデル（RandomForest + 基本特徴量）を構築してベンチマーク
- [ ] JRA-VANデータのカテゴリ変数エンコーディング方針を決定

## タグ

`#モデル` `#特徴量` `#前処理` `#データソース`

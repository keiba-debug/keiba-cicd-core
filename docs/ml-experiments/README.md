# ML実験ログ

ML実験の特徴量エンジニアリング・ハイパーパラメータ調整・モデル変更の記録。
何が効いて何が効かなかったかを振り返り、次の改善に活かす。

## 実験一覧

| バージョン | 日付 | 種別 | Model B AUC | VB gap>=3 ROI | 詳細 |
|-----------|------|------|-------------|---------------|------|
| [v2](v2_dual_model.md) | 2026-02-09 | アーキテクチャ変更 + 特徴量追加 | 0.7635 | 104.7% | デュアルモデル導入 |
| [v3.0](v3.0_jravan_native.md) | 2026-02-10 | データ基盤移行 | 0.7746 | 109.2% | JRA-VANネイティブ |
| [v3.1](v3.1_feature_engineering.md) | 2026-02-11 | 特徴量追加 + ハイパラ調整 | 0.7777 | 110.2% | 脚質/ローテ/ペース |
| [v3.3](v3.3_training_features.md) | 2026-02-11 | データ基盤 + 特徴量追加 | 0.7823 | 113.0% | 調教詳細統合 |
| [v3.4](v3.4_db_odds_integration.md) | 2026-02-14 | データ基盤 + リーク解消 | **0.7849** | 113.3% | DB事前オッズ + speed_features |

## 推移グラフ（テキスト）

```
Model B AUC:
v2    |==============================              | 0.7635
v3.0  |================================            | 0.7746
v3.1  |=================================           | 0.7777
v3.3  |===================================         | 0.7823
v3.4  |=====================================       | 0.7849

VB gap>=3 ROI:
v2    |==========                                  | 104.7%
v3.0  |==============                              | 109.2%
v3.1  |===============                             | 110.2%
v3.3  |===================                         | 113.0%
v3.4  |===================                         | 113.3%

VB gap>=5 ROI:
v2    |                                            |  99.9%
v3.0  |==============================              | 130.3%
v3.1  |============================                | 128.3%
v3.3  |=======================================     | 139.0%
v3.4  |=======================================     | 139.4%
```

## 分類ガイド

ML改善作業は以下のように分類して記録する。

| 分類 | 内容 | 例 |
|------|------|-----|
| **特徴量エンジニアリング** | モデルに与える入力を改善 | 脚質特徴量の追加 |
| **ハイパーパラメータ調整** | 学習方法の調整 | num_leaves, learning_rate変更 |
| **モデルアーキテクチャ** | アルゴリズムや構造の変更 | デュアルモデル導入 |
| **データ基盤** | データソース・カバレッジの変更 | JRA-VAN移行 |
| **特徴量選択** | 不要な特徴量の削除 | 重要度低の特徴量除去 |
| **検証方法** | 学習/テスト分割の改善 | Cross-validation導入 |

## 重要な学び（横断的）

### 効果が大きかったもの
1. **JRA-VAN IDでの100%マッチ** (v3.0): AUC +0.03は最大の改善
2. **デュアルモデル設計** (v2): Value Bet戦略の基盤
3. **prev_race_popularity** (v3.1): 凡走予測仮説を実証、Model B重要度3位
4. **調教詳細データ統合** (v3.3): Model B AUC +0.0046、VB全ギャップでROI向上
5. **事前オッズ統合** (v3.4): データリーク解消しつつAUC維持、単勝gap>=4で黒字(102.5%)

### 期待ほど効かなかったもの
1. **脚質特徴量**: corners正規化だけでは脚質の本質を捉えきれない
2. **consumption_flag**: 発火条件が厳しく（RPCI<=46 & 21日以内）、該当数が少ない
3. **ペース特徴量（個々）**: 単体では重要度低。ただし集団でAUCを底上げ
4. **個別調教特徴量**: 重要度は低いが、集団効果でModel B AUC +0.0046

### ハイパラの知見
- `feature_fraction`: 特徴量増加時は上げる（0.7→0.8）。各木が新特徴量を拾えるように
- Model B `num_leaves`: 市場系除外で情報量減のため、表現力を上げる（63→127）
- `min_child_samples`/`reg_lambda`: num_leaves増加時は過学習防止で上げる

### 調教データの知見 (v3.3)
- **追い切りタイムは正規化なしでも効果あり**: コース別・馬場別の補正で更に向上の余地
- **Model B iterが575に延伸**: 調教データが新しい学習シグナルを提供、過学習していない
- **cyokyo_detail構造**: sessions[], oikiri_summary, rest_period をkb_extに埋め込み

### 事前オッズ・データリークの知見 (v3.4)
- **確定→事前オッズ切替のコストは極小**: Model A AUC -0.0001のみ。リーク解消の恩恵が大きい
- **単勝ROIの閾値はgap>=4**: 複勝(128.5%)に加え、単勝(102.5%)も黒字。gap>=5なら単勝125.3%
- **mykeibadb時系列オッズは実用的**: テスト期間100%カバレッジ、フォールバック設計で堅牢
- **結果JSON完全化**: value_bet_picks + race_predictions出力でWebViewer分析タブが有効化

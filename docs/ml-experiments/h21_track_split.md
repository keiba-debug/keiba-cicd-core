# H-21: 芝/ダート モデル分離実験

**日付**: 2026-02-15
**種別**: モデルアーキテクチャ検証
**結論**: **統一モデルが優位。分離不要。**

---

## 仮説

芝とダートは馬場特性が根本的に異なるため、別々のモデルで学習した方が
各トラックの特徴を深く学習できるのではないか。

## 実験設計

### 統一モデル（ベースライン）
- 全データ（芝+ダート）で学習。track_type特徴量（0=芝, 1=ダート）を含む。
- Model A: 75特徴量, Model B: 69特徴量

### 分離モデル
- 芝データのみ / ダートデータのみ で別々に学習。
- track_type特徴量は除外（定数になるため）。
- それぞれ Model A/B × turf/dirt = 4モデル。

### 評価
- テストセット（2025-2026）をtrack_typeで分割し、対応するモデルで予測。
- AUC、VB Place ROI、VB Win ROI を比較。

## 結果

### AUC比較

| モデル | 芝 AUC | ダート AUC |
|--------|--------|-----------|
| 統一 Model A | **高い** | **高い** |
| 分離 Model A | 低い | 低い |
| 統一 Model B | **高い** | **高い** |
| 分離 Model B | 低い | 低い |

### VB ROI比較

統一モデルのVB ROIが全条件で分離モデルを上回った。

## 分析

1. **LightGBMはtree-basedモデル**であり、track_type=0の条件分岐を自動的に学習する。
   人間が明示的に分離する必要がない。
2. **データ分離 = サンプル半減**（芝:1,801レース, ダート:1,703レース → 各モデルの学習データが約半分）。
   学習データ量の減少がAUC低下につながった。
3. 芝/ダート間で共通する特徴（騎手能力、調教師能力、馬の基本能力）の
   学習が分離によって分断される。

## 教訓

- **LightGBMのtree-based構造はカテゴリ変数の交互作用を自然に学習する**
- データ分割は最後の手段。分割前に特徴量で表現できないか検討すべき
- 障害レースは既にデータから除外されており（steeplechase filter）、別対応不要

## 実装

`ml/experiment.py` に `--split-track` フラグと `run_track_split_experiment()` 関数を追加。
再現可能な形で保持。

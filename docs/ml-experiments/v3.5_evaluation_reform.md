# ML v3.5: 評価基盤改革 + ketto_numバグ修正

**日付**: 2026-02-14
**種別**: 検証方法 + バグ修正 + データ品質改善

---

## 概要

ML評価の信頼性を根本的に改善する3つの改革を実施。
(1) テスト/バリデーション分離による3-way split導入
(2) Brier Score / ECE による確率キャリブレーション評価
(3) LightGBM ネイティブNaN処理への移行

加えて、予測パイプラインの致命的バグ（ketto_num不一致）を修正し、
`predict.py` の当日予測品質を正常化。

## 変更内容

### 1. 3-way Split（テスト汚染の解消）

**問題**: v3.4以前は train(2020-2023) / test(2024-2026) の2分割で、
testセットが早期停止（early stopping）の判定にも使われていた。
テスト評価が楽観バイアスを持つ可能性があった。

**解決**: 3分割に変更。

```
train: 2020-2023  (175,669 samples)  — 学習データ
val:   2024       ( 43,116 samples)  — 早期停止の判定
test:  2025-2026  ( 49,509 samples)  — 純粋な評価用（学習に一切不使用）
```

**効果**: テストAUCは若干低下（v3.4比 A: -0.0005, B: -0.0040）だが、
これは楽観バイアスが除去された結果であり、報告される数値の信頼性が向上。

### 2. 確率キャリブレーション指標

| 新指標 | 説明 | 意義 |
|--------|------|------|
| Brier Score | 確率予測の平均二乗誤差 | 精度+キャリブレーションの総合評価 |
| ECE | 予測確率と実際の発生率のズレ | EV計算の正確性に直結 |
| AUC (val) | バリデーションセットのAUC | 過学習検出 |

ECE < 0.005 は「予測確率がそのまま実際の確率とほぼ一致」を意味し、
EV = pred_proba × odds の計算に高い信頼性を与える。

### 3. LightGBM ネイティブNaN処理

**問題**: `fillna(-1)` で欠損値を-1に置換していた。LightGBMは-1を
「実際の値が-1」と解釈し、欠損パターンの学習が不正確になる可能性。

**解決**: `fillna(-1)` を削除し、`np.nan` のまま渡す。LightGBMのネイティブ
NaN処理（各分岐点でNaN方向を最適化）を活用。`predict.py` も同様に修正。

### 4. ketto_numバグ修正（CRITICAL）

**問題**: `build_race_from_keibabook.py` が keibabook の7桁馬コード
（例: `0950311`）をそのまま `ketto_num` として出力していた。
JRA-VAN の10桁 ketto_num（例: `2022105559`）と不一致のため、
`predict.py` で horse_history_cache / trainer / jockey のルックアップが全失敗。

**影響**:
- 全539頭の過去走特徴量が `-1`（欠損）
- Model V 確率が 0.003（正常値 0.3-0.6 の100倍低い）
- EV が常に < 1.0 → Value Bet が一切検出されない

**修正内容**:
```
build_race_from_keibabook.py:
  + horse_name_index.json (203,178件) で 馬名→10桁ketto_num 変換
  + trainer_kb_index.json (351件) で 調教師名→5桁コード 変換
  + jockeys.json (329件) で 騎手名→5桁コード 変換
  + (地)/(外) プレフィックス除去対応
  + 栗/美プレフィックス + 省略名のファジーマッチング
```

**結果**: ID解決率 99.8%（538/539頭）。Model V 確率が正常化
（mean=0.0735, max=0.768）。

### 5. odds_db strict モード

`batch_get_pre_race_odds()` に `strict` パラメータを追加。
`strict=True` で確定オッズへのフォールバックを無効化し、
時系列オッズのみに限定可能に（将来のリーク調査用）。

## 結果

### 主要指標

| 指標 | v3.4 | v3.5 | 変化 | 評価 |
|------|------|------|------|------|
| Model A AUC | 0.8246 | 0.8241 | -0.0005 | 3way効果 |
| Model B AUC | 0.7849 | 0.7809 | -0.0040 | 3way効果 |
| Model A AUC (val) | - | 0.826 | 新規 | 良好 |
| Model B AUC (val) | - | 0.7857 | 新規 | 良好 |
| Model A Brier | - | 0.1277 | 新規 | 良好 |
| Model B Brier | - | 0.1392 | 新規 | 良好 |
| Model A ECE | - | **0.0041** | 新規 | 優秀 |
| Model B ECE | - | **0.0047** | 新規 | 優秀 |
| Model A Iter | 360 | 272 | -88 | val停止 |
| Model B Iter | 521 | 435 | -86 | val停止 |
| 特徴量数 A/B | 65/61 | 65/61 | - | 変更なし |
| Train size | 218,785 | 175,669 | -43,116 | 2024→val |
| Val size | - | 43,116 | 新規 | - |
| Test size | 49,509 | 49,509 | - | 変更なし |

**AUC低下の解釈**: val分離によりテストセットが学習に一切関与しなくなったため。
v3.4以前のAUCは「早期停止でtestに最適化された」数値だった可能性がある。
v3.5のAUCがより実運用に近い真の性能。

### Value Bet ROI（純粋テスト評価）

| ギャップ | ベット数 | 複勝ROI | v3.4比 | 単勝ROI | v3.4比 |
|---------|---------|---------|--------|---------|--------|
| gap>=2 | 2,823 | 104.5% | +1.2pt | 85.0% | -5.4pt |
| gap>=3 | 1,720 | **117.0%** | **+3.7pt** | 83.0% | -6.5pt |
| gap>=4 | 1,033 | 123.2% | -5.3pt | 98.6% | -3.9pt |
| gap>=5 | 591 | 137.4% | -2.0pt | **112.4%** | -12.9pt |

**分析**:
- 複勝 gap>=3 で **117.0%** は全バージョン最高値。中間ギャップ帯の精度向上
- 単勝ROIは低下。v3.4の数値にはテスト汚染の楽観バイアスがあった可能性
- gap>=5 単勝 112.4% は依然としてプラスROI — 高確信VBは有効

### 的中率

| モデル | Top1 | Top2 | Top3 |
|--------|------|------|------|
| Accuracy | 32.9% | 85.8% | 93.3% |
| Value | 27.3% | 81.5% | 90.3% |

### Model B 特徴量重要度 Top 10

| 順位 | 特徴量 | 重要度(gain) | v3.4比 |
|------|--------|-------------|--------|
| 1 | avg_finish_last3 | 94,141 | -22.7% |
| 2 | jockey_venue_top3_rate | 80,382 | -18.1% |
| 3 | prev_race_popularity | 62,992 | -20.6% |
| 4 | track_type_top3_rate | 39,772 | -18.6% |
| 5 | trainer_venue_top3_rate | 37,327 | -23.1% |
| 6 | recent_form_trend | 21,212 | -17.1% |
| 7 | entry_count | 19,010 | -22.5% |
| 8 | best_finish_last5 | 17,703 | -22.3% |
| 9 | entry_count_change | 16,008 | -19.8% |
| 10 | horse_weight | 14,922 | 新Top10入り |

**注**: 全特徴量で重要度が一様に低下。これは iteration 数の減少（521→435）と
train size 縮小（218K→175K）によるもので、ランキング自体はv3.4とほぼ同一。
horse_weightがdays_since_last_raceを僅差で逆転しTop10入り。

## 特徴量別の評価

### NaN処理の影響
- AUCの変化は微小（3-way split効果と混在するため単体評価は困難）
- LightGBMのNaN処理は各分岐で「NaN→左 or 右」を最適化するため、
  -1よりも欠損パターンの学習が理論的に正確
- consumption_flagの重要度が0のまま → NaN処理変更では改善せず（発火条件の問題）

### ketto_numバグ修正の影響（predict.py）
- 修正前: Model V 確率 mean=0.003, max≈0.01
- 修正後: Model V 確率 mean=0.0735, max=0.768
- EV > 1.0 の馬が正常に検出されるようになり、VBハイライトが機能

## 学び

1. **3-way splitは必須**: AUCは下がるが、報告値の信頼性が根本的に向上。v3.4以前の数値は楽観バイアスを含んでいた
2. **ECE < 0.005は優秀**: 確率予測の精度が高く、EV計算に信頼性がある。キャリブレーション不要の可能性
3. **NaN処理は理論的に正しい選択**: 実測効果は3-way splitと混在するが、LightGBMのネイティブ処理に任せるのがベストプラクティス
4. **ketto_numバグは致命的だった**: 予測パイプラインのID不一致は全特徴量を無効化する。マスタ突合は常に検証すべき
5. **複勝gap>=3が最高ROI(117%)**: 純粋テスト評価でも高い収益性。実運用の中核戦略として信頼できる

## ファイル

| ファイル | 変更 |
|---------|------|
| `ml/experiment_v3.py` | 修正: 3-way split + Brier/ECE + NaN処理 + --val-years引数 |
| `ml/predict.py` | 修正: np.nan化（-1→NaN） |
| `core/odds_db.py` | 修正: strict パラメータ追加 |
| `builders/build_race_from_keibabook.py` | 修正: ketto_num/trainer/jockey ID解決 |

# MLçµ±åˆè¨ˆç”»ï¼ˆv3.2ã€œv4.0ï¼‰

> **ç›®çš„**: æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸç«¶é¦¬äºˆæƒ³ã®ç²¾åº¦å‘ä¸Šã¨ã€å¥½èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºè¦‹

---

## ğŸ“Œ åŸºæœ¬æ–¹é‡

### MLæ´»ç”¨ã®ç›®çš„

1. **è©•ä¾¡æŒ‡æ•°ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**
   - æ—¢å­˜ã®æ‰‹å‹•ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹è©•ä¾¡ã‚’æ”¹å–„
   - éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªé‡ã¿ä»˜ã‘ã‚’å­¦ç¿’

2. **å¥½èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºè¦‹**
   - é¦¬å ´çŠ¶æ…‹ Ã— ãƒ¡ãƒ³ãƒãƒ¼æ§‹æˆ Ã— ãƒ©ãƒƒãƒ—å‚¾å‘
   - èª¿æ•™å¸«åˆ¥ã®å¥½èµ°èª¿æ•™ãƒ‘ã‚¿ãƒ¼ãƒ³
   - è¤‡é›‘ãªç›¸é–¢é–¢ä¿‚ã®ç™ºè¦‹

3. **å‰æ—¥äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ**
   - äº‹å‰ã«è¨ˆç®—ã—ãŸäºˆæƒ³ã‚’JSONä¿å­˜
   - WebViewerã§å‡ºèµ°è¡¨ã«è¡¨ç¤º

### é‡è¦ãªè¨­è¨ˆæ±ºå®š

âœ… **MLäºˆæ¸¬ã¯ãƒãƒƒãƒå‡¦ç†**ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¸è¦ï¼‰
- é‡‘æ›œå¤œã«é€±æœ«ãƒ¬ãƒ¼ã‚¹åˆ†ã‚’ä¸€æ‹¬äºˆæ¸¬
- çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
- WebViewerã¯èª­ã¿è¾¼ã‚€ã ã‘ï¼ˆé«˜é€Ÿï¼‰

âœ… **Backend APIåˆ†é›¢ã¯ä¸è¦**
- ç¾åœ¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆãƒãƒƒãƒ â†’ JSON â†’ Next.jsï¼‰ã§ååˆ†
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ãªã—

---

## ğŸ¯ æ®µéšçš„å®Ÿè£…è¨ˆç”»

### Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»è“„ç©ï¼ˆv3.2ï¼‰

**æœŸé–“**: 2026å¹´3æœˆ

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

**training_history.db**ï¼ˆSQLiteï¼‰:

```sql
-- ãƒ¬ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE races (
    race_id TEXT PRIMARY KEY,
    race_date TEXT NOT NULL,
    track_code TEXT NOT NULL,
    race_number INTEGER NOT NULL,
    distance INTEGER,
    track_condition TEXT,  -- è‰¯/ç¨é‡/é‡/ä¸è‰¯
    race_class TEXT,       -- G1/G2/G3/ã‚ªãƒ¼ãƒ—ãƒ³/1600ä¸‡/1000ä¸‡/500ä¸‡/æœªå‹åˆ©
    INDEX idx_race_date (race_date)
);

-- å‡ºèµ°é¦¬ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE race_entries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    race_id TEXT NOT NULL,
    horse_id TEXT NOT NULL,
    horse_name TEXT NOT NULL,
    finish_position INTEGER,  -- ç€é †
    odds REAL,                 -- ã‚ªãƒƒã‚º
    trainer_id TEXT,
    trainer_name TEXT,
    jockey_id TEXT,
    jockey_name TEXT,
    FOREIGN KEY (race_id) REFERENCES races(race_id),
    INDEX idx_horse_id (horse_id),
    INDEX idx_trainer_id (trainer_id)
);

-- èª¿æ•™å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE training_records (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    race_id TEXT NOT NULL,
    horse_id TEXT NOT NULL,
    training_date TEXT NOT NULL,
    center TEXT,           -- ç¾æµ¦/æ —æ±
    location TEXT,         -- å‚è·¯/ã‚³ãƒ¼ã‚¹/ã‚¦ãƒƒãƒ‰ç­‰
    time_4f REAL,          -- 4Fã‚¿ã‚¤ãƒ 
    lap_1 REAL,            -- ãƒ©ãƒƒãƒ—1
    speed_class TEXT,      -- S/A/B/C/D
    lap_class TEXT,        -- S+/A-/B=ç­‰
    upgraded_lap_class TEXT,  -- SS/S+/A-ç­‰
    is_good_time INTEGER,  -- å¥½ã‚¿ã‚¤ãƒ ï¼ˆ0/1ï¼‰
    FOREIGN KEY (race_id) REFERENCES races(race_id),
    INDEX idx_horse_training (horse_id, training_date)
);

-- ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆv3.3ã§ä½¿ç”¨ï¼‰
CREATE TABLE winning_patterns (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    pattern_type TEXT NOT NULL,  -- trainer_training/track_conditionç­‰
    pattern_name TEXT NOT NULL,
    conditions TEXT NOT NULL,    -- JSONå½¢å¼ã®æ¡ä»¶
    win_count INTEGER DEFAULT 0,
    total_count INTEGER DEFAULT 0,
    win_rate REAL,
    confidence REAL,
    last_updated TEXT
);
```

#### ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**scripts/collect_training_data.py**:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éå»ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆv3.2ï¼‰
JRA-VAN CK_DATA + SE_DATAï¼ˆæˆç¸¾ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’çµ±åˆã—ã¦DBã«æ ¼ç´
"""

import os
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
from parse_ck_data import parse_ck_file
# from parse_se_data import parse_se_file  # æˆç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆè¦å®Ÿè£…ï¼‰

DATA_DIR = Path(os.environ["KEIBA_DATA_ROOT_DIR"])
JV_DIR = Path(os.environ["JV_DATA_ROOT_DIR"])
DB_PATH = DATA_DIR / "training_history.db"

def init_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆä¸Šè¨˜SQLï¼‰
    cursor.executescript("""
        CREATE TABLE IF NOT EXISTS races (...);
        CREATE TABLE IF NOT EXISTS race_entries (...);
        CREATE TABLE IF NOT EXISTS training_records (...);
        CREATE TABLE IF NOT EXISTS winning_patterns (...);
    """)

    conn.commit()
    conn.close()

def collect_past_data(start_date: str, end_date: str):
    """
    æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    start_date, end_date: "YYYY-MM-DD"
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    current_date = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")

    while current_date <= end:
        date_str = current_date.strftime("%Y%m%d")
        print(f"ğŸ“… {date_str} ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")

        # 1. CK_DATAã‹ã‚‰èª¿æ•™ãƒ‡ãƒ¼ã‚¿å–å¾—
        ck_files = list((JV_DIR / "CK_DATA" / current_date.strftime("%Y/%Y%m")).glob(f"*{date_str}.DAT"))
        for ck_file in ck_files:
            training_records = parse_ck_file(ck_file)
            for record in training_records:
                cursor.execute("""
                    INSERT INTO training_records
                    (race_id, horse_id, training_date, center, location,
                     time_4f, lap_1, speed_class, lap_class, upgraded_lap_class, is_good_time)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    record.race_id, record.horse_id, record.date,
                    record.center, record.location, record.time_4f,
                    record.lap_1, record.speed_class, record.lap_class,
                    record.upgraded_lap_class, 1 if record.is_good_time else 0
                ))

        # 2. SE_DATAã‹ã‚‰ãƒ¬ãƒ¼ã‚¹çµæœå–å¾—ï¼ˆè¦å®Ÿè£…ï¼‰
        # ...

        conn.commit()
        current_date += timedelta(days=1)

    conn.close()
    print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")

if __name__ == "__main__":
    init_database()

    # éå»3å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿åé›†
    collect_past_data("2023-01-01", "2026-01-31")
```

**æˆæœç‰©**:
- `training_history.db`ï¼ˆç´„10-20GBï¼‰
- ãƒ‡ãƒ¼ã‚¿åé›†ãƒ­ã‚°

---

### Phase 2: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆv3.3ï¼‰

**æœŸé–“**: 2026å¹´4æœˆ

#### å¥½èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºè¦‹

**scripts/find_winning_patterns.py**:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¥½èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆv3.3ï¼‰
"""

import sqlite3
import json
from pathlib import Path
from collections import defaultdict

DB_PATH = Path(os.environ["KEIBA_DATA_ROOT_DIR"]) / "training_history.db"
PATTERNS_FILE = Path(os.environ["KEIBA_DATA_ROOT_DIR"]) / "patterns.json"

def find_trainer_training_patterns(min_sample_size=20):
    """èª¿æ•™å¸« Ã— èª¿æ•™è©•ä¾¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    query = """
        SELECT
            t.trainer_name,
            tr.center,
            tr.location,
            tr.upgraded_lap_class,
            COUNT(*) as total,
            SUM(CASE WHEN e.finish_position = 1 THEN 1 ELSE 0 END) as wins
        FROM training_records tr
        JOIN race_entries e ON tr.race_id = e.race_id AND tr.horse_id = e.horse_id
        JOIN races r ON tr.race_id = r.race_id
        WHERE tr.upgraded_lap_class IN ('SS', 'S+', 'S=', 'A+')
          AND e.finish_position IS NOT NULL
        GROUP BY t.trainer_name, tr.center, tr.location, tr.upgraded_lap_class
        HAVING COUNT(*) >= ?
        ORDER BY wins * 1.0 / total DESC
    """

    cursor.execute(query, (min_sample_size,))
    patterns = []

    for row in cursor.fetchall():
        trainer, center, location, lap_class, total, wins = row
        win_rate = wins / total

        if win_rate >= 0.20:  # å‹ç‡20%ä»¥ä¸Šã®ã¿
            pattern = {
                "type": "trainer_training_pattern",
                "name": f"{trainer}_{center}{location}_{lap_class}è©•ä¾¡",
                "description": f"{trainer}å©èˆã§{center}{location}{lap_class}è©•ä¾¡",
                "conditions": {
                    "trainer": trainer,
                    "center": center,
                    "location": location,
                    "lap_class": lap_class
                },
                "win_count": wins,
                "total_count": total,
                "win_rate": round(win_rate, 3),
                "confidence": calculate_confidence(wins, total)
            }
            patterns.append(pattern)

    conn.close()
    return patterns

def find_track_condition_patterns(min_sample_size=50):
    """é¦¬å ´ Ã— ãƒ©ãƒƒãƒ—å‚¾å‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # å®Ÿè£…çœç•¥ï¼ˆåŒæ§˜ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    # ...

    conn.close()
    return patterns

def calculate_confidence(wins, total):
    """ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # ãƒ™ã‚¤ã‚ºæ¨å®šç­‰ã§ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
    # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„
    if total < 20:
        return 0.5
    elif total < 50:
        return 0.7
    else:
        return 0.85

def save_patterns():
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    patterns = {
        "trainer_training_patterns": find_trainer_training_patterns(),
        "track_condition_patterns": find_track_condition_patterns(),
        # ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã‚‚è¿½åŠ 
    }

    with open(PATTERNS_FILE, 'w', encoding='utf-8') as f:
        json.dump(patterns, f, ensure_ascii=False, indent=2)

    print(f"âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿å­˜å®Œäº†: {PATTERNS_FILE}")

if __name__ == "__main__":
    save_patterns()
```

**ãƒ‘ã‚¿ãƒ¼ãƒ³å‡ºåŠ›ä¾‹ï¼ˆpatterns.jsonï¼‰**:

```json
{
  "trainer_training_patterns": [
    {
      "type": "trainer_training_pattern",
      "name": "è—¤æ²¢å’Œé›„_æ —æ±å‚è·¯_S+è©•ä¾¡",
      "description": "è—¤æ²¢å’Œé›„å©èˆã§æ —æ±å‚è·¯S+è©•ä¾¡",
      "conditions": {
        "trainer": "è—¤æ²¢å’Œé›„",
        "center": "æ —æ±",
        "location": "å‚è·¯",
        "lap_class": "S+"
      },
      "win_count": 12,
      "total_count": 45,
      "win_rate": 0.267,
      "confidence": 0.82
    },
    {
      "type": "trainer_training_pattern",
      "name": "çŸ¢ä½œèŠ³äºº_æ —æ±å‚è·¯_SSè©•ä¾¡",
      "description": "çŸ¢ä½œèŠ³äººå©èˆã§æ —æ±å‚è·¯SSè©•ä¾¡",
      "conditions": {
        "trainer": "çŸ¢ä½œèŠ³äºº",
        "center": "æ —æ±",
        "location": "å‚è·¯",
        "lap_class": "SS"
      },
      "win_count": 8,
      "total_count": 22,
      "win_rate": 0.364,
      "confidence": 0.75
    }
  ],
  "track_condition_patterns": [
    {
      "type": "track_condition_pattern",
      "name": "äº¬éƒ½ãƒ€1800m_è‰¯é¦¬å ´_ãƒã‚¤ãƒšãƒ¼ã‚¹_å·®ã—",
      "description": "äº¬éƒ½ãƒ€1800mãƒ»è‰¯é¦¬å ´ãƒ»ãƒã‚¤ãƒšãƒ¼ã‚¹æƒ³å®š â†’ å·®ã—è„šè³ªæœ‰åˆ©",
      "conditions": {
        "track": "äº¬éƒ½",
        "distance": 1800,
        "surface": "ãƒ€ãƒ¼ãƒˆ",
        "condition": "è‰¯",
        "pace": "ãƒã‚¤ãƒšãƒ¼ã‚¹",
        "running_style": "å·®ã—"
      },
      "win_count": 42,
      "total_count": 120,
      "win_rate": 0.35,
      "confidence": 0.88
    }
  ]
}
```

---

### Phase 3: MLäºˆæƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆv4.0ï¼‰

**æœŸé–“**: 2026å¹´5-6æœˆ

#### ç‰¹å¾´é‡è¨­è¨ˆ

**features.py**:

```python
def extract_features(horse_id: str, race_id: str) -> dict:
    """ç‰¹å¾´é‡æŠ½å‡º"""
    features = {}

    # 1. èª¿æ•™ãƒ‡ãƒ¼ã‚¿
    features['training_time_4f'] = get_latest_training(horse_id)['time_4f']
    features['training_lap_class_encoded'] = encode_lap_class(...)
    features['training_is_good_time'] = 1 or 0

    # 2. éå»æˆç¸¾
    features['recent_win_rate'] = calculate_recent_win_rate(horse_id, last_n=5)
    features['track_win_rate'] = calculate_track_win_rate(horse_id, track_code)

    # 3. èª¿æ•™å¸«ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ
    features['trainer_pattern_match'] = check_trainer_pattern(...)

    # 4. é¦¬å ´ãƒ»ãƒšãƒ¼ã‚¹
    features['track_condition_encoded'] = encode_track_condition(...)
    features['expected_pace_encoded'] = encode_pace(...)

    # 5. ãƒ¡ãƒ³ãƒãƒ¼æ§‹æˆ
    features['member_strength'] = calculate_member_strength(race_id)

    return features
```

#### MLãƒ¢ãƒ‡ãƒ«å®Ÿè£…

**ml/prediction_model.py**:

```python
import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

class RacePredictionModel:
    def __init__(self):
        self.model = None

    def train(self, X, y):
        """ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        train_data = lgb.Dataset(X_train, label=y_train)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

        params = {
            'objective': 'binary',  # å‹ã¡/è² ã‘ã®äºŒå€¤åˆ†é¡
            'metric': 'auc',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': 0
        }

        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=1000,
            valid_sets=[val_data],
            early_stopping_rounds=50
        )

    def predict(self, X):
        """äºˆæ¸¬ï¼ˆå‹ç‡ï¼‰"""
        return self.model.predict(X, num_iteration=self.model.best_iteration)

    def save(self, path):
        self.model.save_model(path)

    def load(self, path):
        self.model = lgb.Booster(model_file=path)
```

#### é€±æ¬¡äºˆæƒ³ç”Ÿæˆ

**scripts/generate_weekly_predictions.py**:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é€±æ¬¡äºˆæƒ³ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆv4.0ï¼‰
é‡‘æ›œå¤œã«å®Ÿè¡Œã—ã€é€±æœ«ãƒ¬ãƒ¼ã‚¹ã®äºˆæƒ³ã‚’ç”Ÿæˆ
"""

import os
import json
from pathlib import Path
from datetime import datetime
from ml.prediction_model import RacePredictionModel
from features import extract_features

DATA_DIR = Path(os.environ["KEIBA_DATA_ROOT_DIR"])
PREDICTIONS_DIR = DATA_DIR / "predictions"

def generate_race_prediction(race_id: str, entries: list) -> dict:
    """ãƒ¬ãƒ¼ã‚¹äºˆæƒ³ç”Ÿæˆ"""
    model = RacePredictionModel()
    model.load(DATA_DIR / "models" / "race_predictor_v1.0.txt")

    predictions = []

    for entry in entries:
        # ç‰¹å¾´é‡æŠ½å‡º
        features = extract_features(entry['horse_id'], race_id)
        X = pd.DataFrame([features])

        # äºˆæ¸¬
        win_prob = model.predict(X)[0]

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        patterns = find_matching_patterns(entry, race_id)

        # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆäºˆæ¸¬å‹ç‡ Ã— ãƒ‘ã‚¿ãƒ¼ãƒ³ä¿¡é ¼åº¦ï¼‰
        score = calculate_score(win_prob, patterns)

        predictions.append({
            "horse_id": entry['horse_id'],
            "horse_name": entry['horse_name'],
            "prediction": {
                "score": round(score, 1),
                "winning_probability": round(win_prob, 3),
                "rank": 0,  # å¾Œã§è¨­å®š
                "recommendation": "",  # å¾Œã§è¨­å®š
                "confidence": round(calculate_confidence(win_prob, patterns), 2)
            },
            "patterns": patterns
        })

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¨­å®š
    predictions.sort(key=lambda x: x['prediction']['score'], reverse=True)
    for i, pred in enumerate(predictions, 1):
        pred['prediction']['rank'] = i
        if i == 1:
            pred['prediction']['recommendation'] = "â—"
        elif i == 2:
            pred['prediction']['recommendation'] = "â—‹"
        elif i == 3:
            pred['prediction']['recommendation'] = "â–²"
        elif i <= 5:
            pred['prediction']['recommendation'] = "â–³"

    return {
        "race_id": race_id,
        "meta": {
            "predicted_at": datetime.now().isoformat(),
            "model_version": "v1.0",
            "confidence": round(np.mean([p['prediction']['confidence'] for p in predictions]), 2)
        },
        "horses": predictions
    }

def generate_weekend_predictions(target_date: str):
    """é€±æœ«ãƒ¬ãƒ¼ã‚¹åˆ†ã®äºˆæƒ³ã‚’ä¸€æ‹¬ç”Ÿæˆ"""
    # ãƒ¬ãƒ¼ã‚¹ä¸€è¦§å–å¾—ï¼ˆçœç•¥ï¼‰
    races = get_weekend_races(target_date)

    for race in races:
        prediction = generate_race_prediction(race['race_id'], race['entries'])

        # JSONä¿å­˜
        output_dir = PREDICTIONS_DIR / target_date[:4] / target_date[4:6] / target_date[6:8]
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"{race['race_id']}.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(prediction, f, ensure_ascii=False, indent=2)

        print(f"âœ… {race['race_name']}: {output_file}")

if __name__ == "__main__":
    # é‡‘æ›œå¤œã«å®Ÿè¡Œ
    generate_weekend_predictions("20260208")
```

**äºˆæƒ³ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ä¾‹**:

```json
{
  "race_id": "2026020806010208",
  "meta": {
    "predicted_at": "2026-02-07T22:00:00",
    "model_version": "v1.0",
    "confidence": 0.78
  },
  "horses": [
    {
      "horse_id": "2023103073",
      "horse_name": "ã‚«ã‚¼ãƒãƒã‚´ãƒ­ãƒ¢",
      "prediction": {
        "score": 85.3,
        "winning_probability": 0.23,
        "rank": 1,
        "recommendation": "â—",
        "confidence": 0.82
      },
      "patterns": [
        {
          "type": "trainer_training_pattern",
          "name": "è—¤æ²¢å’Œé›„_æ —æ±å‚è·¯_S+è©•ä¾¡",
          "win_rate": 0.267,
          "confidence": 0.82
        }
      ]
    }
  ]
}
```

---

## ğŸ–¥ï¸ WebViewerçµ±åˆ

### äºˆæƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ 

**src/components/race-v2/PredictionSection.tsx**:

```tsx
import { useMemo } from 'react';

interface PredictionData {
  race_id: string;
  horses: Array<{
    horse_name: string;
    prediction: {
      score: number;
      winning_probability: number;
      rank: number;
      recommendation: string;
      confidence: number;
    };
    patterns: Array<{
      type: string;
      name: string;
      win_rate: number;
    }>;
  }>;
}

export function PredictionSection({ raceId }: { raceId: string }) {
  const { data, error } = useSWR(`/api/predictions/${raceId}`, fetcher);

  if (!data) return <div>äºˆæƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...</div>;

  return (
    <section className="mb-6">
      <h3 className="text-lg font-bold mb-3">ğŸ”® AIäºˆæƒ³åˆ†æ</h3>

      <table className="w-full text-sm">
        <thead>
          <tr className="bg-gray-100 dark:bg-gray-800">
            <th>æ </th>
            <th>ç•ª</th>
            <th>é¦¬å</th>
            <th>äºˆæƒ³</th>
            <th>ã‚¹ã‚³ã‚¢</th>
            <th>å‹ç‡</th>
            <th>ãƒ‘ã‚¿ãƒ¼ãƒ³</th>
          </tr>
        </thead>
        <tbody>
          {data.horses.map((horse) => (
            <tr key={horse.horse_name}>
              <td>{/* æ ç•ª */}</td>
              <td>{/* é¦¬ç•ª */}</td>
              <td>{horse.horse_name}</td>
              <td>
                <span className={getRecommendationColor(horse.prediction.recommendation)}>
                  {horse.prediction.recommendation}
                </span>
              </td>
              <td className="font-bold">{horse.prediction.score}</td>
              <td>{(horse.prediction.winning_probability * 100).toFixed(1)}%</td>
              <td>
                <button onClick={() => showPatterns(horse.patterns)}>
                  {horse.patterns.length}ä»¶
                </button>
              </td>
            </tr>
          ))}
        </tbody>
      </table>
    </section>
  );
}
```

---

## ğŸ“Š è©•ä¾¡ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡

**scripts/evaluate_model.py**:

```python
def evaluate_predictions(start_date: str, end_date: str):
    """äºˆæƒ³ç²¾åº¦ã®è©•ä¾¡"""
    results = {
        "top1_accuracy": 0,  # æœ¬å‘½çš„ä¸­ç‡
        "top3_accuracy": 0,  # 3ç€ä»¥å†…çš„ä¸­ç‡
        "auc": 0,            # AUCã‚¹ã‚³ã‚¢
        "calibration": 0     # å‹ç‡äºˆæ¸¬ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    }

    # å®Ÿè£…çœç•¥

    return results
```

### é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ

æ¯é€±æœˆæ›œæ—¥ã«è‡ªå‹•ç”Ÿæˆï¼š

```
=== é€±æ¬¡äºˆæƒ³ãƒ¬ãƒãƒ¼ãƒˆï¼ˆ2026å¹´2æœˆç¬¬2é€±ï¼‰===

äºˆæƒ³ãƒ¬ãƒ¼ã‚¹æ•°: 48
æœ¬å‘½çš„ä¸­: 15 / 48 (31.3%)
3ç€ä»¥å†…çš„ä¸­: 38 / 48 (79.2%)

ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒçš„ä¸­ç‡:
- è—¤æ²¢å’Œé›„_æ —æ±å‚è·¯_S+è©•ä¾¡: 3 / 8 (37.5%)
- äº¬éƒ½ãƒ€1800m_è‰¯é¦¬å ´_å·®ã—: 5 / 12 (41.7%)

æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ:
- ä¸è‰¯é¦¬å ´ã§ã®äºˆæ¸¬ç²¾åº¦ãŒä½ã„ï¼ˆ20%ï¼‰
- ãƒ¡ãƒ³ãƒãƒ¼æ§‹æˆã®é‡ã¿èª¿æ•´ãŒå¿…è¦
```

---

**æœ€çµ‚æ›´æ–°**: 2026-02-07ï¼ˆã‚«ã‚«ã‚·ï¼‰
**æ‰¿èª**: ãµãã å›ï¼ˆä¿ç•™ä¸­ï¼‰

# ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´ã‚¬ã‚¤ãƒ‰

## ğŸ“Š æ¦‚è¦

æœ€é©åŒ–ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ãŸã‚ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

**æœ€çµ‚æ›´æ–°**: 2025å¹´8æœˆ9æ—¥  
**å¯¾è±¡**: OptimizedDataFetcherï¼ˆæœ€é©åŒ–ç‰ˆï¼‰  
**æ¨å¥¨ãƒ¬ãƒ™ãƒ«**: ä¸­ç´šè€…ã€œä¸Šç´šè€…

---

## ğŸš€ æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½æŒ‡æ¨™

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é©å‘½ã®å®Ÿç¸¾

| æŒ‡æ¨™ | å¾“æ¥ç‰ˆ | æœ€é©åŒ–ç‰ˆ | æ”¹å–„ç‡ |
|------|--------|----------|--------|
| **å‡¦ç†æ™‚é–“** | 60-90ç§’/12ãƒ¬ãƒ¼ã‚¹ | **8.6ç§’/12ãƒ¬ãƒ¼ã‚¹** | **7-10å€é«˜é€Ÿ** |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡** | 150-300MB | **50-100MB** | **60-70%å‰Šæ¸›** |
| **CPUä½¿ç”¨ç‡** | é«˜ï¼ˆChromeï¼‰ | **ä½ï¼ˆHTTPï¼‰** | **å¤§å¹…æ”¹å–„** |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹ç‡** | ä½ | **é«˜ï¼ˆä¸¦åˆ—ï¼‰** | **10-20å€å‘ä¸Š** |
| **ã‚¨ãƒ©ãƒ¼å›å¾©** | åŸºæœ¬ | **ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆ** | **å¤§å¹…å‘ä¸Š** |

---

## âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–

### 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–

#### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æãƒ„ãƒ¼ãƒ«
```python
# ãƒ¡ãƒ¢ãƒªåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆanalyze_memory.pyï¼‰
import psutil
import os

def analyze_system_memory():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªã®è©³ç´°åˆ†æ"""
    mem = psutil.virtual_memory()
    
    print("=== ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªåˆ†æ ===")
    print(f"ç·ãƒ¡ãƒ¢ãƒª: {mem.total // (1024**3)} GB")
    print(f"åˆ©ç”¨å¯èƒ½: {mem.available // (1024**3)} GB")
    print(f"ä½¿ç”¨ä¸­: {mem.used // (1024**3)} GB")
    print(f"ä½¿ç”¨ç‡: {mem.percent:.1f}%")
    
    # æ¨å¥¨è¨­å®šã®è¨ˆç®—
    available_gb = mem.available // (1024**3)
    
    if available_gb >= 8:
        rec_workers = 12
        rec_level = "é«˜æ€§èƒ½"
    elif available_gb >= 4:
        rec_workers = 8
        rec_level = "æ¨™æº–"
    elif available_gb >= 2:
        rec_workers = 5
        rec_level = "è»½é‡"
    else:
        rec_workers = 3
        rec_level = "æœ€å°"
    
    print(f"\n=== æ¨å¥¨è¨­å®š ({rec_level}) ===")
    print(f"MAX_WORKERS: {rec_workers}")
    print(f"æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º: {rec_workers * 4}")
    
    return rec_workers

if __name__ == "__main__":
    analyze_system_memory()
```

#### å‹•çš„ãƒ¡ãƒ¢ãƒªèª¿æ•´
```bash
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–ã—ãªãŒã‚‰å®Ÿè¡Œ
python -c "
import sys
sys.path.insert(0, 'src')
from keibabook.batch.optimized_data_fetcher import OptimizedDataFetcher
import psutil

# åˆæœŸãƒ¡ãƒ¢ãƒªç¢ºèª
initial_mem = psutil.virtual_memory().available // (1024**3)
print(f'åˆæœŸåˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {initial_mem} GB')

# å‹•çš„max-workersè¨­å®š
if initial_mem >= 8:
    max_workers = 12
elif initial_mem >= 4:
    max_workers = 8
else:
    max_workers = 5

print(f'å‹•çš„è¨­å®š: max_workers={max_workers}')

# æœ€é©åŒ–ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ä½¿ç”¨ä¾‹
fetcher = OptimizedDataFetcher(
    delay=0.5, 
    max_workers=max_workers, 
    max_retries=3
)
"
```

### 2. CPUä½¿ç”¨ç‡æœ€é©åŒ–

#### CPUåˆ†æãƒ»æœ€é©åŒ–
```python
# CPUæœ€é©åŒ–åˆ†æï¼ˆanalyze_cpu.pyï¼‰
import psutil
import os

def analyze_cpu_performance():
    """CPUæ€§èƒ½åˆ†æã¨æ¨å¥¨è¨­å®š"""
    cpu_count = os.cpu_count()
    cpu_percent = psutil.cpu_percent(interval=1)
    cpu_freq = psutil.cpu_freq()
    
    print("=== CPUæ€§èƒ½åˆ†æ ===")
    print(f"CPUæ•°: {cpu_count}")
    print(f"ç¾åœ¨ä½¿ç”¨ç‡: {cpu_percent:.1f}%")
    
    if cpu_freq:
        print(f"ç¾åœ¨å‘¨æ³¢æ•°: {cpu_freq.current:.0f} MHz")
        print(f"æœ€å¤§å‘¨æ³¢æ•°: {cpu_freq.max:.0f} MHz")
    
    # æ¨å¥¨ä¸¦åˆ—æ•°è¨ˆç®—
    if cpu_percent < 50:
        # CPUä½™è£•ã‚ã‚Š
        rec_workers = min(cpu_count * 2, 15)
        performance_level = "é«˜æ€§èƒ½"
    elif cpu_percent < 80:
        # CPUæ¨™æº–ä½¿ç”¨
        rec_workers = min(cpu_count, 10)
        performance_level = "æ¨™æº–"
    else:
        # CPUé«˜è² è·
        rec_workers = max(cpu_count // 2, 3)
        performance_level = "è»½é‡"
    
    print(f"\n=== CPUæœ€é©åŒ–æ¨å¥¨ ({performance_level}) ===")
    print(f"æ¨å¥¨max-workers: {rec_workers}")
    print(f"æ¨å¥¨delay: {0.3 if cpu_percent < 50 else 0.5}ç§’")
    
    return rec_workers

if __name__ == "__main__":
    analyze_cpu_performance()
```

---

## ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–

### 1. æ¥ç¶šé€Ÿåº¦æœ€é©åŒ–

#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½æ¸¬å®š
```python
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½æ¸¬å®šï¼ˆnetwork_bench.pyï¼‰
import requests
import time
import statistics

def benchmark_network_performance():
    """ç«¶é¦¬ãƒ–ãƒƒã‚¯ã‚µã‚¤ãƒˆã¸ã®æ¥ç¶šæ€§èƒ½æ¸¬å®š"""
    url = "https://p.keibabook.co.jp/"
    test_count = 10
    response_times = []
    
    print("=== ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½æ¸¬å®š ===")
    print(f"ãƒ†ã‚¹ãƒˆURL: {url}")
    print(f"æ¸¬å®šå›æ•°: {test_count}")
    
    for i in range(test_count):
        try:
            start_time = time.time()
            response = requests.get(url, timeout=10)
            end_time = time.time()
            
            response_time = end_time - start_time
            response_times.append(response_time)
            
            print(f"ãƒ†ã‚¹ãƒˆ {i+1}: {response_time:.3f}ç§’ (HTTP {response.status_code})")
            
        except Exception as e:
            print(f"ãƒ†ã‚¹ãƒˆ {i+1}: ã‚¨ãƒ©ãƒ¼ - {e}")
    
    if response_times:
        avg_time = statistics.mean(response_times)
        median_time = statistics.median(response_times)
        
        print(f"\n=== çµæœåˆ†æ ===")
        print(f"å¹³å‡å¿œç­”æ™‚é–“: {avg_time:.3f}ç§’")
        print(f"ä¸­å¤®å€¤: {median_time:.3f}ç§’")
        print(f"æœ€é€Ÿ: {min(response_times):.3f}ç§’")
        print(f"æœ€é…: {max(response_times):.3f}ç§’")
        
        # æ¨å¥¨è¨­å®šè¨ˆç®—
        if avg_time < 0.5:
            rec_delay = 0.3
            performance = "é«˜é€Ÿ"
        elif avg_time < 1.0:
            rec_delay = 0.5
            performance = "æ¨™æº–"
        elif avg_time < 2.0:
            rec_delay = 1.0
            performance = "ä½é€Ÿ"
        else:
            rec_delay = 2.0
            performance = "æ³¨æ„"
        
        print(f"\n=== æ¨å¥¨è¨­å®š ({performance}æ¥ç¶š) ===")
        print(f"æ¨å¥¨delay: {rec_delay}ç§’")
        print(f"æ¨å¥¨max-workers: {15 if avg_time < 0.5 else 10 if avg_time < 1.0 else 5}")

if __name__ == "__main__":
    benchmark_network_performance()
```

### 2. æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–

#### å‹•çš„æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
```python
# æœ€é©åŒ–ã•ã‚ŒãŸæ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šä¾‹
from keibabook.batch.optimized_data_fetcher import OptimizedDataFetcher

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½ã«åŸºã¥ãè‡ªå‹•è¨­å®š
def create_optimized_fetcher(network_speed="auto"):
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ã«å¿œã˜ãŸæœ€é©åŒ–ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ä½œæˆ"""
    
    if network_speed == "fast":
        # é«˜é€Ÿãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        return OptimizedDataFetcher(
            delay=0.3,
            max_workers=12,
            max_retries=3
        )
    elif network_speed == "standard":
        # æ¨™æº–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        return OptimizedDataFetcher(
            delay=0.5,
            max_workers=8,
            max_retries=3
        )
    elif network_speed == "slow":
        # ä½é€Ÿãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        return OptimizedDataFetcher(
            delay=1.0,
            max_workers=5,
            max_retries=5
        )
    else:
        # è‡ªå‹•åˆ¤å®š
        # network_bench.pyã®çµæœã«åŸºã¥ãè¨­å®š
        return OptimizedDataFetcher(
            delay=0.5,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            max_workers=8,
            max_retries=3
        )
```

---

## âš¡ ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–

### 1. ThreadPoolExecutoræœ€é©åŒ–

#### æœ€é©ãªä¸¦åˆ—æ•°ã®è¨ˆç®—
```python
# ä¸¦åˆ—æ•°æœ€é©åŒ–è¨ˆç®—ï¼ˆparallel_optimizer.pyï¼‰
import psutil
import os
import requests
import time

def calculate_optimal_workers():
    """ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã«åŸºã¥ãæœ€é©ä¸¦åˆ—æ•°è¨ˆç®—"""
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
    cpu_count = os.cpu_count()
    memory_gb = psutil.virtual_memory().total // (1024**3)
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    try:
        response = requests.get("https://p.keibabook.co.jp/", timeout=10)
        network_speed = time.time() - start_time
    except:
        network_speed = 2.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    print("=== ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹åˆ†æ ===")
    print(f"CPUæ•°: {cpu_count}")
    print(f"ãƒ¡ãƒ¢ãƒª: {memory_gb} GB")
    print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {network_speed:.2f}ç§’")
    
    # ä¸¦åˆ—æ•°è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    # CPUåˆ¶é™
    cpu_limit = cpu_count * 2
    
    # ãƒ¡ãƒ¢ãƒªåˆ¶é™ï¼ˆ1ä¸¦åˆ—ã‚ãŸã‚Šç´„10MBæƒ³å®šï¼‰
    memory_limit = min(memory_gb * 10, 20)
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™
    if network_speed < 0.5:
        network_limit = 15
    elif network_speed < 1.0:
        network_limit = 10
    else:
        network_limit = 5
    
    # æœ€é©å€¤è¨ˆç®—
    optimal_workers = min(cpu_limit, memory_limit, network_limit, 15)
    
    print(f"\n=== åˆ¶é™è¦å› åˆ†æ ===")
    print(f"CPUåˆ¶é™: {cpu_limit}")
    print(f"ãƒ¡ãƒ¢ãƒªåˆ¶é™: {memory_limit}")
    print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™: {network_limit}")
    print(f"æœ€çµ‚æ¨å¥¨å€¤: {optimal_workers}")
    
    return optimal_workers

if __name__ == "__main__":
    optimal = calculate_optimal_workers()
```

### 2. å‹•çš„è² è·èª¿æ•´

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–
```python
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–ï¼ˆperformance_monitor.pyï¼‰
import time
import psutil
from keibabook.batch.optimized_data_fetcher import OptimizedDataFetcher

class PerformanceMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.start_time = time.time()
        self.initial_memory = psutil.virtual_memory().percent
        self.initial_cpu = psutil.cpu_percent()
    
    def get_current_performance(self):
        """ç¾åœ¨ã®æ€§èƒ½æŒ‡æ¨™å–å¾—"""
        return {
            'memory_percent': psutil.virtual_memory().percent,
            'cpu_percent': psutil.cpu_percent(),
            'elapsed_time': time.time() - self.start_time
        }
    
    def should_adjust_workers(self, current_workers):
        """ä¸¦åˆ—æ•°èª¿æ•´ãŒå¿…è¦ã‹ã©ã†ã‹åˆ¤å®š"""
        perf = self.get_current_performance()
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒ80%ä»¥ä¸Š
        if perf['memory_percent'] > 80:
            return max(current_workers - 2, 3)
        
        # CPUä½¿ç”¨ç‡ãŒ90%ä»¥ä¸Š
        if perf['cpu_percent'] > 90:
            return max(current_workers - 1, 3)
        
        # ãƒªã‚½ãƒ¼ã‚¹ã«ä½™è£•ãŒã‚ã‚‹å ´åˆ
        if perf['memory_percent'] < 50 and perf['cpu_percent'] < 50:
            return min(current_workers + 1, 15)
        
        return current_workers

# ä½¿ç”¨ä¾‹
def adaptive_fetching(date_str, data_types):
    """é©å¿œçš„ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    monitor = PerformanceMonitor()
    initial_workers = 8
    
    fetcher = OptimizedDataFetcher(
        delay=0.5,
        max_workers=initial_workers,
        max_retries=3
    )
    
    # æ€§èƒ½ç›£è¦–ã—ãªãŒã‚‰å®Ÿè¡Œ
    # å®Ÿè£…ã¯ OptimizedDataFetcher å†…ã§è¡Œã†
    result = fetcher.fetch_all_race_data_parallel_fast(date_str, data_types)
    
    return result
```

---

## ğŸ“Š ã‚¨ãƒ©ãƒ¼ç‡ãƒ»å“è³ªæœ€é©åŒ–

### 1. ã‚¨ãƒ©ãƒ¼çµ±è¨ˆåˆ†æ

#### ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
```python
# ã‚¨ãƒ©ãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆerror_analyzer.pyï¼‰
from collections import defaultdict
import json

class ErrorAnalyzer:
    """ã‚¨ãƒ©ãƒ¼çµ±è¨ˆåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.error_patterns = defaultdict(int)
        self.error_details = []
    
    def analyze_error_log(self, log_file_path):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        # ãƒ­ã‚°åˆ†æå®Ÿè£…
        pass
    
    def get_optimization_recommendations(self):
        """ã‚¨ãƒ©ãƒ¼åˆ†æã«åŸºã¥ãæœ€é©åŒ–æ¨å¥¨"""
        recommendations = []
        
        # HTTPã‚¨ãƒ©ãƒ¼ãŒå¤šã„å ´åˆ
        if self.error_patterns['http_errors'] > 5:
            recommendations.append({
                'type': 'delay_increase',
                'current': 0.5,
                'recommended': 1.0,
                'reason': 'HTTP ã‚¨ãƒ©ãƒ¼å¤šç™ºã«ã‚ˆã‚‹ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›'
            })
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ãŒå¤šã„å ´åˆ
        if self.error_patterns['timeout_errors'] > 3:
            recommendations.append({
                'type': 'workers_decrease',
                'current': 8,
                'recommended': 5,
                'reason': 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè»½æ¸›ã®ãŸã‚ã®ä¸¦åˆ—æ•°å‰Šæ¸›'
            })
        
        return recommendations
```

### 2. å“è³ªã‚¹ã‚³ã‚¢æœ€é©åŒ–

#### è‡ªå‹•å“è³ªèª¿æ•´
```python
# å“è³ªè‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ ï¼ˆquality_optimizer.pyï¼‰

def optimize_for_quality_score(target_score=95.0):
    """å“è³ªã‚¹ã‚³ã‚¢é”æˆã®ãŸã‚ã®è‡ªå‹•æœ€é©åŒ–"""
    
    # åˆæœŸè¨­å®š
    settings = {
        'delay': 0.5,
        'max_workers': 8,
        'max_retries': 3
    }
    
    # å“è³ªã‚¹ã‚³ã‚¢æ¸¬å®šãƒ»èª¿æ•´ãƒ«ãƒ¼ãƒ—
    for attempt in range(5):  # æœ€å¤§5å›è©¦è¡Œ
        fetcher = OptimizedDataFetcher(**settings)
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå°è¦æ¨¡ï¼‰
        test_result = fetcher.fetch_single_race_data_fast("test_race", "seiseki")
        
        # å“è³ªã‚¹ã‚³ã‚¢ç¢ºèªï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯çµ±è¨ˆã‹ã‚‰å–å¾—ï¼‰
        quality_score = 98.5  # ã‚µãƒ³ãƒ—ãƒ«å€¤
        
        if quality_score >= target_score:
            print(f"âœ… å“è³ªç›®æ¨™é”æˆ: {quality_score:.1f}%")
            print(f"æœ€é©è¨­å®š: {settings}")
            return settings
        
        # è¨­å®šèª¿æ•´
        if quality_score < 90:
            # å¤§å¹…èª¿æ•´
            settings['delay'] *= 1.5
            settings['max_workers'] = max(settings['max_workers'] - 2, 3)
        else:
            # å¾®èª¿æ•´
            settings['delay'] *= 1.1
            settings['max_workers'] = max(settings['max_workers'] - 1, 3)
        
        print(f"èª¿æ•´å¾Œè¨­å®š: {settings} (å“è³ª: {quality_score:.1f}%)")
    
    return settings
```

---

## ğŸ”§ å®Ÿç”¨çš„ãªæœ€é©åŒ–è¨­å®š

### ç’°å¢ƒåˆ¥æ¨å¥¨è¨­å®š

#### é«˜æ€§èƒ½ç’°å¢ƒï¼ˆ16GB RAM, 8+ CPUï¼‰
```bash
# æœ€å¤§æ€§èƒ½è¨­å®š
python -m src.fast_batch_cli full \
  --start-date 2024/12/28 \
  --delay 0.3 \
  --max-workers 12 \
  --wait-between-phases 1.0
```

#### æ¨™æº–ç’°å¢ƒï¼ˆ8GB RAM, 4+ CPUï¼‰
```bash
# ãƒãƒ©ãƒ³ã‚¹è¨­å®š
python -m src.fast_batch_cli full \
  --start-date 2024/12/28 \
  --delay 0.5 \
  --max-workers 8 \
  --wait-between-phases 2.0
```

#### è»½é‡ç’°å¢ƒï¼ˆ4GB RAM, 2+ CPUï¼‰
```bash
# è»½é‡è¨­å®š
python -m src.fast_batch_cli full \
  --start-date 2024/12/28 \
  --delay 1.0 \
  --max-workers 5 \
  --wait-between-phases 3.0
```

### ç”¨é€”åˆ¥æœ€é©åŒ–

#### ãƒ‡ãƒ¼ã‚¿è£œå®Œç”¨ï¼ˆå¤§é‡å‡¦ç†ï¼‰
```bash
# å®‰å®šæ€§é‡è¦–ãƒ»é•·æ™‚é–“å®Ÿè¡Œ
python -m src.fast_batch_cli data \
  --start-date 2024/12/01 \
  --end-date 2024/12/31 \
  --data-types seiseki \
  --delay 1.0 \
  --max-workers 6
```

#### ç·Šæ€¥å–å¾—ç”¨ï¼ˆé«˜é€Ÿå‡¦ç†ï¼‰
```bash
# é€Ÿåº¦é‡è¦–ãƒ»çŸ­æ™‚é–“å®Ÿè¡Œ
python -m src.fast_batch_cli data \
  --start-date 2024/12/28 \
  --data-types seiseki \
  --delay 0.3 \
  --max-workers 10
```

---

## ğŸ“ˆ æ€§èƒ½ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚³ãƒãƒ³ãƒ‰

#### ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
```bash
# CPUãƒ»ãƒ¡ãƒ¢ãƒªç›£è¦–ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
watch -n 1 'echo "=== CPUä½¿ç”¨ç‡ ==="; top -bn1 | grep "Cpu(s)" | awk "{print \$2}" | awk -F"%" "{print \$1}"; echo "=== ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ ==="; free -h | grep "Mem:" | awk "{print \$3\"/\"\$2\" (\"\$3/\$2*100\"%)\"}"'
```

#### ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–
```bash
# Python ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–
watch -n 2 'ps aux | grep python | grep fast_batch_cli | head -5'
```

#### ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç›£è¦–
```bash
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ
watch -n 5 'ss -tuln | grep :443 | wc -l; echo "HTTPSæ¥ç¶šæ•°"'
```

---

## ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ

#### å°è¦æ¨¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆ12ãƒ¬ãƒ¼ã‚¹ï¼‰
```bash
time python -m src.fast_batch_cli full \
  --start-date 2024/12/28 \
  --delay 0.5 \
  --max-workers 8

# æœŸå¾…çµæœ: 15-25ç§’
```

#### ä¸­è¦æ¨¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆ48ãƒ¬ãƒ¼ã‚¹ï¼‰
```bash
time python -m src.fast_batch_cli full \
  --start-date 2024/12/28 \
  --end-date 2024/12/29 \
  --delay 0.5 \
  --max-workers 10

# æœŸå¾…çµæœ: 60-90ç§’
```

### æ€§èƒ½æŒ‡æ¨™ã®ç›®æ¨™å€¤

| æŒ‡æ¨™ | ç›®æ¨™å€¤ | å„ªç§€ | æ³¨æ„ |
|------|--------|------|------|
| **å“è³ªã‚¹ã‚³ã‚¢** | â‰¥95% | â‰¥98% | <90% |
| **å‡¦ç†é€Ÿåº¦** | â‰¥2ã‚¿ã‚¹ã‚¯/ç§’ | â‰¥4ã‚¿ã‚¹ã‚¯/ç§’ | <1ã‚¿ã‚¹ã‚¯/ç§’ |
| **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡** | <100MB | <80MB | >200MB |
| **ã‚¨ãƒ©ãƒ¼ç‡** | <5% | <2% | >10% |

---

**ğŸ“Š é©åˆ‡ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®çœŸã®æ€§èƒ½ã‚’å¼•ãå‡ºã—ã€åŠ¹ç‡çš„ã§å®‰å®šã—ãŸãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚ç’°å¢ƒã«å¿œã˜ãŸæœ€é©åŒ–è¨­å®šã§ã€æœ€å¤§é™ã®åŠ¹æœã‚’å¾—ã¾ã—ã‚‡ã†ï¼**
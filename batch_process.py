#!/usr/bin/env python3
"""
ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒãƒƒãƒå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®šã—ã¦ã€ãƒ¬ãƒ¼ã‚¹IDå–å¾—ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã¾ã§ã‚’è‡ªå‹•ã§å®Ÿè¡Œã—ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
    python batch_process.py --start-date 2025/6/14 --end-date 2025/6/15 --data-types shutsuba,seiseki,cyokyo --delay 3 --wait-time 5
"""

import argparse
import sys
import os
import time
from datetime import datetime, timedelta
from pathlib import Path

# KeibaCICD.keibabook/src ã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "KeibaCICD.keibabook" / "src"))

from main import scrape_and_parse
from utils.config import Config
from utils.logger import setup_logger


def parse_date(date_str):
    """æ—¥ä»˜æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹"""
    try:
        # YYYY/MM/DD ã¾ãŸã¯ YY/MM/DD å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆ
        if len(date_str.split('/')[0]) == 2:
            # YY/MM/DD å½¢å¼ã®å ´åˆã€20YYã«å¤‰æ›
            parts = date_str.split('/')
            year = int(parts[0])
            if year >= 0 and year <= 99:
                year = 2000 + year
            date_str = f"{year}/{parts[1]}/{parts[2]}"
        
        return datetime.strptime(date_str, '%Y/%m/%d').date()
    except ValueError:
        raise ValueError(f"ç„¡åŠ¹ãªæ—¥ä»˜å½¢å¼: {date_str}. YYYY/MM/DD ã¾ãŸã¯ YY/MM/DD å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


def generate_race_ids(start_date, end_date):
    """æŒ‡å®šæœŸé–“ã®ãƒ¬ãƒ¼ã‚¹IDã‚’ç”Ÿæˆ"""
    race_ids = []
    current_date = start_date
    
    # åŸºæœ¬çš„ãªç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆæ±äº¬ã€ä¸­å±±ã€é˜ªç¥ã€äº¬éƒ½ãªã©ï¼‰
    venue_codes = ['01', '02', '03', '04', '05', '06', '07', '08']
    
    while current_date <= end_date:
        date_str = current_date.strftime('%Y%m%d')
        
        # å„ç«¶é¦¬å ´ãƒ»å„é–‹å‚¬ãƒ»å„ãƒ¬ãƒ¼ã‚¹ã®IDã‚’ç”Ÿæˆ
        for venue in venue_codes:
            for kai in ['01', '02', '03']:  # é–‹å‚¬å›
                for race_num in range(1, 13):  # 1ã€œ12ãƒ¬ãƒ¼ã‚¹
                    race_id = f"{date_str}{venue}{kai}{race_num:02d}"
                    race_ids.append(race_id)
        
        current_date += timedelta(days=1)
    
    return race_ids


def batch_process(start_date, end_date, data_types, delay=3, wait_time=5):
    """ãƒãƒƒãƒå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    logger = setup_logger("batch_process", level="INFO")
    
    logger.info("ğŸ‡ ãƒãƒƒãƒå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    logger.info(f"ğŸ“… æœŸé–“: {start_date} ï½ {end_date}")
    logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {', '.join(data_types)}")
    logger.info(f"â±ï¸ é…å»¶: {delay}ç§’")
    logger.info(f"â¸ï¸ å¾…æ©Ÿæ™‚é–“: {wait_time}ç§’")
    
    try:
        # Phase 1: ãƒ¬ãƒ¼ã‚¹IDç”Ÿæˆ
        logger.info("=" * 50)
        logger.info("ğŸ”¢ Phase 1: ãƒ¬ãƒ¼ã‚¹IDç”Ÿæˆ")
        logger.info("=" * 50)
        
        race_ids = generate_race_ids(start_date, end_date)
        
        # ãƒ†ã‚¹ãƒˆç”¨ã«æœ€åˆã®æ•°ä»¶ã®ã¿å‡¦ç†
        test_race_ids = race_ids[:10]  # æœ€åˆã®10ä»¶ã§ãƒ†ã‚¹ãƒˆ
        
        logger.info(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹æ•°: {len(race_ids)}")
        logger.info(f"ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: æœ€åˆã® {len(test_race_ids)} ä»¶")
        
        # Phaseé–“å¾…æ©Ÿ
        logger.info(f"â¸ï¸ Phaseé–“å¾…æ©Ÿ: {wait_time}ç§’")
        time.sleep(wait_time)
        
        # Phase 2: ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info("=" * 50)
        logger.info("âš™ï¸ Phase 2: ãƒ‡ãƒ¼ã‚¿å–å¾—")
        logger.info("=" * 50)
        
        success_count = 0
        error_count = 0
        
        for i, race_id in enumerate(test_race_ids):
            logger.info(f"ğŸ‡ å‡¦ç†ä¸­ ({i+1}/{len(test_race_ids)}): {race_id}")
            
            try:
                # å„ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¯¾ã—ã¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
                for data_type in data_types:
                    if data_type == 'seiseki':
                        success = scrape_and_parse(race_id, save_html=True, use_requests=True)
                        if success:
                            success_count += 1
                        else:
                            error_count += 1
                    elif data_type == 'shutsuba':
                        # å‡ºé¦¬è¡¨ã¯multi_typeãƒ¢ãƒ¼ãƒ‰ã§å–å¾—
                        from main import scrape_and_parse_multi_type
                        success = scrape_and_parse_multi_type(race_id, ['syutuba'], save_html=True, use_requests=True)
                        if success:
                            success_count += 1
                        else:
                            error_count += 1
                    elif data_type == 'cyokyo':
                        # èª¿æ•™ã¯multi_typeãƒ¢ãƒ¼ãƒ‰ã§å–å¾—
                        from main import scrape_and_parse_multi_type
                        success = scrape_and_parse_multi_type(race_id, ['cyokyo'], save_html=True, use_requests=True)
                        if success:
                            success_count += 1
                        else:
                            error_count += 1
                
                # é…å»¶
                if i < len(test_race_ids) - 1:  # æœ€å¾Œä»¥å¤–ã¯å¾…æ©Ÿ
                    time.sleep(delay)
                    
            except Exception as e:
                logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {race_id} - {e}")
                error_count += 1
                continue
        
        # çµæœã‚µãƒãƒªãƒ¼
        logger.info("=" * 50)
        logger.info("ğŸ“Š ãƒãƒƒãƒå‡¦ç†å®Œäº†")
        logger.info("=" * 50)
        logger.info(f"âœ… æˆåŠŸ: {success_count}")
        logger.info(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_count}")
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {success_count/(success_count+error_count)*100:.1f}%" if (success_count + error_count) > 0 else "0%")
        
        return success_count > 0
        
    except Exception as e:
        logger.error(f"âŒ ãƒãƒƒãƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒãƒƒãƒå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    python batch_process.py --start-date 2025/6/14 --end-date 2025/6/15 --data-types shutsuba,seiseki,cyokyo --delay 3 --wait-time 5
    
    python batch_process.py --start-date 25/6/14 --data-types seiseki --delay 2
        """
    )
    
    parser.add_argument('--start-date', required=True, 
                       help='å–å¾—é–‹å§‹æ—¥ (YYYY/MM/DD or YY/MM/DDå½¢å¼)')
    parser.add_argument('--end-date', 
                       help='å–å¾—çµ‚äº†æ—¥ (YYYY/MM/DD or YY/MM/DDå½¢å¼ã€çœç•¥æ™‚ã¯é–‹å§‹æ—¥ã¨åŒã˜)')
    parser.add_argument('--data-types', default='seiseki',
                       help='å–å¾—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š) [shutsuba,seiseki,cyokyo] (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: seiseki)')
    parser.add_argument('--delay', type=int, default=3,
                       help='ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã®å¾…æ©Ÿæ™‚é–“(ç§’) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3)')
    parser.add_argument('--wait-time', type=int, default=5,
                       help='ãƒ¬ãƒ¼ã‚¹IDå–å¾—ã¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã®é–“ã®å¾…æ©Ÿæ™‚é–“(ç§’) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)')
    
    args = parser.parse_args()
    
    try:
        # æ—¥ä»˜ã‚’ãƒ‘ãƒ¼ã‚¹
        start_date = parse_date(args.start_date)
        end_date = parse_date(args.end_date) if args.end_date else start_date
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
        data_types = [dt.strip() for dt in args.data_types.split(',')]
        
        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‹ãƒã‚§ãƒƒã‚¯
        valid_types = ['shutsuba', 'seiseki', 'cyokyo']
        for dt in data_types:
            if dt not in valid_types:
                print(f"ã‚¨ãƒ©ãƒ¼: ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ— '{dt}'. æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ—: {', '.join(valid_types)}")
                return 1
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        success = batch_process(start_date, end_date, data_types, args.delay, args.wait_time)
        
        return 0 if success else 1
        
    except ValueError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    except Exception as e:
        print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main()) 